{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### importing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/onkars/Documents/AIProjects/Automated-Software-Refactoring-Commit-Classifier/myenv/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /Users/onkars/Documents/AIProjects/Automated-Software-Refactoring-Commit-Classifier/myenv/lib/python3.12/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/onkars/Documents/AIProjects/Automated-Software-Refactoring-Commit-Classifier/myenv/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/onkars/Documents/AIProjects/Automated-Software-Refactoring-Commit-Classifier/myenv/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/onkars/Documents/AIProjects/Automated-Software-Refactoring-Commit-Classifier/myenv/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/onkars/Documents/AIProjects/Automated-Software-Refactoring-Commit-Classifier/myenv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "# pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### creating a dataframe from imported dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "filePath = r\"../dataset/ESWA20_manualclassification.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Commit Message</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\tNIO Reads writes are completed in the caller thered;\\n\\t100% compatible with old interface and functionality.\\n\\tEach connection has an instance of this object to\\n\\treceive data for a message in multiple OP_READ events.\\n</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>* temporary fix for non-shared JArray objects\\n  * added generic unittests to check jcc/lucene/solr/montysolr functionality\\n  * wrote unittest for newseman (it does a complete processing from python side)\\n    - now what remains is to call it from java\\n    - decide on proper behaviour for cases when tokens are added/grouped\\n</td>\n",
       "      <td>bugfix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>* Java:\\n   * Added RCON functionality for Source servers:\\n     * Added steamcondenser.steam.packets.rcon package\\n     * Added RCONAuthRequestPacket\\n     * Added RCONAuthResponsePacket\\n     * Added RCONExecRequestPacket\\n     * Added RCONExecResponsePacket\\n     * Added RCONPacket\\n     * Added RCONNoAuthException\\n   * Split SteamSocket into QuerySocket and RCONSocket\\n   * Stub functionality for GoldSrc servers\\n     * GoldSrc uses UDP and needs a special implementation\\n   * Added tests\\n</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>- Merge changes from Pull-Request #6 \\t - Fix aggregation generation and cleanup dead code  - Update dependencies versions</td>\n",
       "      <td>code smell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bug 233643 -  API builder performance bad for incremental build</td>\n",
       "      <td>external</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1735</th>\n",
       "      <td>working on #339: introducing the getSpecialFeatureCollection Method as a more general way to get all the PrintTemplateFeatures. improve the numbering\\n</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1736</th>\n",
       "      <td>working on #339: next step. i\\n\\nmove all the calculation and handling into the PrintTemplateFeature to handle\\nmultiple templateprinting.\\n\\nThe creation is still very basic though\\n</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1737</th>\n",
       "      <td>working on #369: generalized the adjustMapForPrintingTemplates and ensureVisibilityOfPrintingTemplates method to adjustMapForSpecialFeatureClasses and ensureVisibilityOfSpecialFeatures\\n</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1738</th>\n",
       "      <td>working up test coverage; minor tweaks; removing dead code; fixing very minor bugs; adding tests</td>\n",
       "      <td>code smell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1739</th>\n",
       "      <td> changed render routine for text fields  added tabbing abilities to CustomScreen  various modifications on CustomScreen to match the new TextField requirements  changed size of PacketSky</td>\n",
       "      <td>internal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1740 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Commit Message  \\\n",
       "0                                                                                                                                                                                                                                                                                          \\tNIO Reads writes are completed in the caller thered;\\n\\t100% compatible with old interface and functionality.\\n\\tEach connection has an instance of this object to\\n\\treceive data for a message in multiple OP_READ events.\\n   \n",
       "1                                                                                                                                                                                 * temporary fix for non-shared JArray objects\\n  * added generic unittests to check jcc/lucene/solr/montysolr functionality\\n  * wrote unittest for newseman (it does a complete processing from python side)\\n    - now what remains is to call it from java\\n    - decide on proper behaviour for cases when tokens are added/grouped\\n   \n",
       "2      * Java:\\n   * Added RCON functionality for Source servers:\\n     * Added steamcondenser.steam.packets.rcon package\\n     * Added RCONAuthRequestPacket\\n     * Added RCONAuthResponsePacket\\n     * Added RCONExecRequestPacket\\n     * Added RCONExecResponsePacket\\n     * Added RCONPacket\\n     * Added RCONNoAuthException\\n   * Split SteamSocket into QuerySocket and RCONSocket\\n   * Stub functionality for GoldSrc servers\\n     * GoldSrc uses UDP and needs a special implementation\\n   * Added tests\\n   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                - Merge changes from Pull-Request #6 \\t - Fix aggregation generation and cleanup dead code  - Update dependencies versions   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                           Bug 233643 -  API builder performance bad for incremental build   \n",
       "...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     ...   \n",
       "1735                                                                                                                                                                                                                                                                                                                                                                working on #339: introducing the getSpecialFeatureCollection Method as a more general way to get all the PrintTemplateFeatures. improve the numbering\\n   \n",
       "1736                                                                                                                                                                                                                                                                                                                                working on #339: next step. i\\n\\nmove all the calculation and handling into the PrintTemplateFeature to handle\\nmultiple templateprinting.\\n\\nThe creation is still very basic though\\n   \n",
       "1737                                                                                                                                                                                                                                                                                                                             working on #369: generalized the adjustMapForPrintingTemplates and ensureVisibilityOfPrintingTemplates method to adjustMapForSpecialFeatureClasses and ensureVisibilityOfSpecialFeatures\\n   \n",
       "1738                                                                                                                                                                                                                                                                                                                                                                                                                       working up test coverage; minor tweaks; removing dead code; fixing very minor bugs; adding tests   \n",
       "1739                                                                                                                                                                                                                                                                                                                          changed render routine for text fields  added tabbing abilities to CustomScreen  various modifications on CustomScreen to match the new TextField requirements  changed size of PacketSky   \n",
       "\n",
       "        Category  \n",
       "0     functional  \n",
       "1         bugfix  \n",
       "2     functional  \n",
       "3     code smell  \n",
       "4       external  \n",
       "...          ...  \n",
       "1735  functional  \n",
       "1736  functional  \n",
       "1737  functional  \n",
       "1738  code smell  \n",
       "1739    internal  \n",
       "\n",
       "[1740 rows x 2 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(filePath, encoding='ISO-8859-1')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>commit_message</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\tNIO Reads writes are completed in the caller thered;\\n\\t100% compatible with old interface and functionality.\\n\\tEach connection has an instance of this object to\\n\\treceive data for a message in multiple OP_READ events.\\n</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>* temporary fix for non-shared JArray objects\\n  * added generic unittests to check jcc/lucene/solr/montysolr functionality\\n  * wrote unittest for newseman (it does a complete processing from python side)\\n    - now what remains is to call it from java\\n    - decide on proper behaviour for cases when tokens are added/grouped\\n</td>\n",
       "      <td>bugfix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>* Java:\\n   * Added RCON functionality for Source servers:\\n     * Added steamcondenser.steam.packets.rcon package\\n     * Added RCONAuthRequestPacket\\n     * Added RCONAuthResponsePacket\\n     * Added RCONExecRequestPacket\\n     * Added RCONExecResponsePacket\\n     * Added RCONPacket\\n     * Added RCONNoAuthException\\n   * Split SteamSocket into QuerySocket and RCONSocket\\n   * Stub functionality for GoldSrc servers\\n     * GoldSrc uses UDP and needs a special implementation\\n   * Added tests\\n</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>- Merge changes from Pull-Request #6 \\t - Fix aggregation generation and cleanup dead code  - Update dependencies versions</td>\n",
       "      <td>code smell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bug 233643 -  API builder performance bad for incremental build</td>\n",
       "      <td>external</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1735</th>\n",
       "      <td>working on #339: introducing the getSpecialFeatureCollection Method as a more general way to get all the PrintTemplateFeatures. improve the numbering\\n</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1736</th>\n",
       "      <td>working on #339: next step. i\\n\\nmove all the calculation and handling into the PrintTemplateFeature to handle\\nmultiple templateprinting.\\n\\nThe creation is still very basic though\\n</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1737</th>\n",
       "      <td>working on #369: generalized the adjustMapForPrintingTemplates and ensureVisibilityOfPrintingTemplates method to adjustMapForSpecialFeatureClasses and ensureVisibilityOfSpecialFeatures\\n</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1738</th>\n",
       "      <td>working up test coverage; minor tweaks; removing dead code; fixing very minor bugs; adding tests</td>\n",
       "      <td>code smell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1739</th>\n",
       "      <td> changed render routine for text fields  added tabbing abilities to CustomScreen  various modifications on CustomScreen to match the new TextField requirements  changed size of PacketSky</td>\n",
       "      <td>internal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1740 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             commit_message  \\\n",
       "0                                                                                                                                                                                                                                                                                          \\tNIO Reads writes are completed in the caller thered;\\n\\t100% compatible with old interface and functionality.\\n\\tEach connection has an instance of this object to\\n\\treceive data for a message in multiple OP_READ events.\\n   \n",
       "1                                                                                                                                                                                 * temporary fix for non-shared JArray objects\\n  * added generic unittests to check jcc/lucene/solr/montysolr functionality\\n  * wrote unittest for newseman (it does a complete processing from python side)\\n    - now what remains is to call it from java\\n    - decide on proper behaviour for cases when tokens are added/grouped\\n   \n",
       "2      * Java:\\n   * Added RCON functionality for Source servers:\\n     * Added steamcondenser.steam.packets.rcon package\\n     * Added RCONAuthRequestPacket\\n     * Added RCONAuthResponsePacket\\n     * Added RCONExecRequestPacket\\n     * Added RCONExecResponsePacket\\n     * Added RCONPacket\\n     * Added RCONNoAuthException\\n   * Split SteamSocket into QuerySocket and RCONSocket\\n   * Stub functionality for GoldSrc servers\\n     * GoldSrc uses UDP and needs a special implementation\\n   * Added tests\\n   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                - Merge changes from Pull-Request #6 \\t - Fix aggregation generation and cleanup dead code  - Update dependencies versions   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                           Bug 233643 -  API builder performance bad for incremental build   \n",
       "...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     ...   \n",
       "1735                                                                                                                                                                                                                                                                                                                                                                working on #339: introducing the getSpecialFeatureCollection Method as a more general way to get all the PrintTemplateFeatures. improve the numbering\\n   \n",
       "1736                                                                                                                                                                                                                                                                                                                                working on #339: next step. i\\n\\nmove all the calculation and handling into the PrintTemplateFeature to handle\\nmultiple templateprinting.\\n\\nThe creation is still very basic though\\n   \n",
       "1737                                                                                                                                                                                                                                                                                                                             working on #369: generalized the adjustMapForPrintingTemplates and ensureVisibilityOfPrintingTemplates method to adjustMapForSpecialFeatureClasses and ensureVisibilityOfSpecialFeatures\\n   \n",
       "1738                                                                                                                                                                                                                                                                                                                                                                                                                       working up test coverage; minor tweaks; removing dead code; fixing very minor bugs; adding tests   \n",
       "1739                                                                                                                                                                                                                                                                                                                          changed render routine for text fields  added tabbing abilities to CustomScreen  various modifications on CustomScreen to match the new TextField requirements  changed size of PacketSky   \n",
       "\n",
       "        category  \n",
       "0     functional  \n",
       "1         bugfix  \n",
       "2     functional  \n",
       "3     code smell  \n",
       "4       external  \n",
       "...          ...  \n",
       "1735  functional  \n",
       "1736  functional  \n",
       "1737  functional  \n",
       "1738  code smell  \n",
       "1739    internal  \n",
       "\n",
       "[1740 rows x 2 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['commit_message'] = df['Commit Message']\n",
    "del df['Commit Message']\n",
    "\n",
    "df['category'] = df['Category']\n",
    "del df['Category']\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### understanding the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1740, 2)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 1740 records and 2 features in the dataset (including the target feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "commit_message    object\n",
       "category          object\n",
       "dtype: object"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "both the features have object as a data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>commit_message</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\tNIO Reads writes are completed in the caller thered;\\n\\t100% compatible with old interface and functionality.\\n\\tEach connection has an instance of this object to\\n\\treceive data for a message in multiple OP_READ events.\\n</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>* temporary fix for non-shared JArray objects\\n  * added generic unittests to check jcc/lucene/solr/montysolr functionality\\n  * wrote unittest for newseman (it does a complete processing from python side)\\n    - now what remains is to call it from java\\n    - decide on proper behaviour for cases when tokens are added/grouped\\n</td>\n",
       "      <td>bugfix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>* Java:\\n   * Added RCON functionality for Source servers:\\n     * Added steamcondenser.steam.packets.rcon package\\n     * Added RCONAuthRequestPacket\\n     * Added RCONAuthResponsePacket\\n     * Added RCONExecRequestPacket\\n     * Added RCONExecResponsePacket\\n     * Added RCONPacket\\n     * Added RCONNoAuthException\\n   * Split SteamSocket into QuerySocket and RCONSocket\\n   * Stub functionality for GoldSrc servers\\n     * GoldSrc uses UDP and needs a special implementation\\n   * Added tests\\n</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>- Merge changes from Pull-Request #6 \\t - Fix aggregation generation and cleanup dead code  - Update dependencies versions</td>\n",
       "      <td>code smell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bug 233643 -  API builder performance bad for incremental build</td>\n",
       "      <td>external</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          commit_message  \\\n",
       "0                                                                                                                                                                                                                                                                                       \\tNIO Reads writes are completed in the caller thered;\\n\\t100% compatible with old interface and functionality.\\n\\tEach connection has an instance of this object to\\n\\treceive data for a message in multiple OP_READ events.\\n   \n",
       "1                                                                                                                                                                              * temporary fix for non-shared JArray objects\\n  * added generic unittests to check jcc/lucene/solr/montysolr functionality\\n  * wrote unittest for newseman (it does a complete processing from python side)\\n    - now what remains is to call it from java\\n    - decide on proper behaviour for cases when tokens are added/grouped\\n   \n",
       "2   * Java:\\n   * Added RCON functionality for Source servers:\\n     * Added steamcondenser.steam.packets.rcon package\\n     * Added RCONAuthRequestPacket\\n     * Added RCONAuthResponsePacket\\n     * Added RCONExecRequestPacket\\n     * Added RCONExecResponsePacket\\n     * Added RCONPacket\\n     * Added RCONNoAuthException\\n   * Split SteamSocket into QuerySocket and RCONSocket\\n   * Stub functionality for GoldSrc servers\\n     * GoldSrc uses UDP and needs a special implementation\\n   * Added tests\\n   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                             - Merge changes from Pull-Request #6 \\t - Fix aggregation generation and cleanup dead code  - Update dependencies versions   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                        Bug 233643 -  API builder performance bad for incremental build   \n",
       "\n",
       "     category  \n",
       "0  functional  \n",
       "1      bugfix  \n",
       "2  functional  \n",
       "3  code smell  \n",
       "4    external  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>commit_message</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1735</th>\n",
       "      <td>working on #339: introducing the getSpecialFeatureCollection Method as a more general way to get all the PrintTemplateFeatures. improve the numbering\\n</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1736</th>\n",
       "      <td>working on #339: next step. i\\n\\nmove all the calculation and handling into the PrintTemplateFeature to handle\\nmultiple templateprinting.\\n\\nThe creation is still very basic though\\n</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1737</th>\n",
       "      <td>working on #369: generalized the adjustMapForPrintingTemplates and ensureVisibilityOfPrintingTemplates method to adjustMapForSpecialFeatureClasses and ensureVisibilityOfSpecialFeatures\\n</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1738</th>\n",
       "      <td>working up test coverage; minor tweaks; removing dead code; fixing very minor bugs; adding tests</td>\n",
       "      <td>code smell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1739</th>\n",
       "      <td> changed render routine for text fields  added tabbing abilities to CustomScreen  various modifications on CustomScreen to match the new TextField requirements  changed size of PacketSky</td>\n",
       "      <td>internal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                      commit_message  \\\n",
       "1735                                         working on #339: introducing the getSpecialFeatureCollection Method as a more general way to get all the PrintTemplateFeatures. improve the numbering\\n   \n",
       "1736         working on #339: next step. i\\n\\nmove all the calculation and handling into the PrintTemplateFeature to handle\\nmultiple templateprinting.\\n\\nThe creation is still very basic though\\n   \n",
       "1737      working on #369: generalized the adjustMapForPrintingTemplates and ensureVisibilityOfPrintingTemplates method to adjustMapForSpecialFeatureClasses and ensureVisibilityOfSpecialFeatures\\n   \n",
       "1738                                                                                                working up test coverage; minor tweaks; removing dead code; fixing very minor bugs; adding tests   \n",
       "1739   changed render routine for text fields  added tabbing abilities to CustomScreen  various modifications on CustomScreen to match the new TextField requirements  changed size of PacketSky   \n",
       "\n",
       "        category  \n",
       "1735  functional  \n",
       "1736  functional  \n",
       "1737  functional  \n",
       "1738  code smell  \n",
       "1739    internal  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>commit_message</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1228</th>\n",
       "      <td>Splits a long method into multiple shorter methods.</td>\n",
       "      <td>code smell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>Added some features for EventFrame and FontFrame\\n\\nEventFrame:\\n * Buttons now display it, rather than toggling it\\n * GmObjectFrame has a button to summon it\\n * Right click selects and adds an event\\n * Clicking or Right Clicking on a branch expands/collapses the branch\\n   * Functionality similar to GmObjectFrame.EventTree\\n * Disabled double-middle-mouse click for event adding\\n * Had to resize it to make room for \"double click\" etc. label\\n\\nFontFrame:\\n * Added a text field for what text to preview\\n * Had to resize to make room\\n\\nDisabled bold text throughout the UI. See LGM line 251.\\n * This may cause some components to display incorrectly\\n\\ngit-svn-id: https://lateralgm.svn.sourceforge.net/svnroot/lateralgm@233 8f422083-7f27-0410-bc82-93e204be8cd2\\n</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>Fixed #17 - made toggling Vrapper instant and global\\n  * I kind-of abused WeakReferences in the process\\n    - I thought keeping old editor alive by Vrapper may be the cause of #28\\n      - they may be; it needs further investigation\\n    - weak maps are good idea for observers, anyway\\n      - http://blog.kamil.dworakowski.name/2008/01/anti-pattern-static-subject-to-observer.html\\n</td>\n",
       "      <td>bugfix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>Fix performance regresssion introduced by using InetSocketAddress\\ngetHostName()\\nPatch provided by Scott Harrington, improved upon by Kris Jurka\\n</td>\n",
       "      <td>bugfix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>I hate Java. I hate everything about the Java ecosystem. I have moved this project to Maven with no small amount of difficutly. Honestly most of the pom.xml file is just magic to me. I understand parts   but like most things in java I have no idea how its doing most of what its doing. Its a large cryptic XML document with very little human readable meaning. I mean Makefiles were considered arcaic  however you can find a dozen or so simple introductions on how to construct a Makefile that doesn't depend on magic to build your project. Not so with Maven. The only official Documentation is a 100+ line document that has no coorliation to what is actually happening to build your file. Take for example the fact that i know have a whole target folder that has lots of stuff in it. At no place in my pom.xml did I say create a target folder  nor did I say run javac. The closest I came to either of those was set my \"source\" tag to 1.5 ( I only knew to do this because Bukkit does it ). Furthermore the comand to compile the project into a jar ( again no mention of a jar file in the pom.xml ) is to issue a mvn install command. That clearly makes sense. mvn build anyone mvn package  nope mvn install. Its like java heads have a fetish for complexity.</td>\n",
       "      <td>external</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              commit_message  \\\n",
       "1228                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Splits a long method into multiple shorter methods.   \n",
       "238                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Added some features for EventFrame and FontFrame\\n\\nEventFrame:\\n * Buttons now display it, rather than toggling it\\n * GmObjectFrame has a button to summon it\\n * Right click selects and adds an event\\n * Clicking or Right Clicking on a branch expands/collapses the branch\\n   * Functionality similar to GmObjectFrame.EventTree\\n * Disabled double-middle-mouse click for event adding\\n * Had to resize it to make room for \"double click\" etc. label\\n\\nFontFrame:\\n * Added a text field for what text to preview\\n * Had to resize to make room\\n\\nDisabled bold text throughout the UI. See LGM line 251.\\n * This may cause some components to display incorrectly\\n\\ngit-svn-id: https://lateralgm.svn.sourceforge.net/svnroot/lateralgm@233 8f422083-7f27-0410-bc82-93e204be8cd2\\n   \n",
       "595                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Fixed #17 - made toggling Vrapper instant and global\\n  * I kind-of abused WeakReferences in the process\\n    - I thought keeping old editor alive by Vrapper may be the cause of #28\\n      - they may be; it needs further investigation\\n    - weak maps are good idea for observers, anyway\\n      - http://blog.kamil.dworakowski.name/2008/01/anti-pattern-static-subject-to-observer.html\\n   \n",
       "577                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Fix performance regresssion introduced by using InetSocketAddress\\ngetHostName()\\nPatch provided by Scott Harrington, improved upon by Kris Jurka\\n   \n",
       "714   I hate Java. I hate everything about the Java ecosystem. I have moved this project to Maven with no small amount of difficutly. Honestly most of the pom.xml file is just magic to me. I understand parts   but like most things in java I have no idea how its doing most of what its doing. Its a large cryptic XML document with very little human readable meaning. I mean Makefiles were considered arcaic  however you can find a dozen or so simple introductions on how to construct a Makefile that doesn't depend on magic to build your project. Not so with Maven. The only official Documentation is a 100+ line document that has no coorliation to what is actually happening to build your file. Take for example the fact that i know have a whole target folder that has lots of stuff in it. At no place in my pom.xml did I say create a target folder  nor did I say run javac. The closest I came to either of those was set my \"source\" tag to 1.5 ( I only knew to do this because Bukkit does it ). Furthermore the comand to compile the project into a jar ( again no mention of a jar file in the pom.xml ) is to issue a mvn install command. That clearly makes sense. mvn build anyone mvn package  nope mvn install. Its like java heads have a fetish for complexity.   \n",
       "\n",
       "        category  \n",
       "1228  code smell  \n",
       "238   functional  \n",
       "595       bugfix  \n",
       "577       bugfix  \n",
       "714     external  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1740 entries, 0 to 1739\n",
      "Data columns (total 2 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   commit_message  1740 non-null   object\n",
      " 1   category        1740 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 27.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>commit_message</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1740</td>\n",
       "      <td>1740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1716</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Removed duplicate code and added outlines for how to add version to the start log entry.</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>3</td>\n",
       "      <td>348</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                  commit_message  \\\n",
       "count                                                                                       1740   \n",
       "unique                                                                                      1716   \n",
       "top     Removed duplicate code and added outlines for how to add version to the start log entry.   \n",
       "freq                                                                                           3   \n",
       "\n",
       "          category  \n",
       "count         1740  \n",
       "unique           5  \n",
       "top     functional  \n",
       "freq           348  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['functional', 'bugfix', 'code smell', 'external', 'internal'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.category.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in /Users/onkars/Documents/AIProjects/Automated-Software-Refactoring-Commit-Classifier/myenv/lib/python3.12/site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /Users/onkars/Documents/AIProjects/Automated-Software-Refactoring-Commit-Classifier/myenv/lib/python3.12/site-packages (from seaborn) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.2 in /Users/onkars/Documents/AIProjects/Automated-Software-Refactoring-Commit-Classifier/myenv/lib/python3.12/site-packages (from seaborn) (2.2.2)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /Users/onkars/Documents/AIProjects/Automated-Software-Refactoring-Commit-Classifier/myenv/lib/python3.12/site-packages (from seaborn) (3.8.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/onkars/Documents/AIProjects/Automated-Software-Refactoring-Commit-Classifier/myenv/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/onkars/Documents/AIProjects/Automated-Software-Refactoring-Commit-Classifier/myenv/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/onkars/Documents/AIProjects/Automated-Software-Refactoring-Commit-Classifier/myenv/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/onkars/Documents/AIProjects/Automated-Software-Refactoring-Commit-Classifier/myenv/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/onkars/Documents/AIProjects/Automated-Software-Refactoring-Commit-Classifier/myenv/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.0)\n",
      "Requirement already satisfied: pillow>=8 in /Users/onkars/Documents/AIProjects/Automated-Software-Refactoring-Commit-Classifier/myenv/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/onkars/Documents/AIProjects/Automated-Software-Refactoring-Commit-Classifier/myenv/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/onkars/Documents/AIProjects/Automated-Software-Refactoring-Commit-Classifier/myenv/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/onkars/Documents/AIProjects/Automated-Software-Refactoring-Commit-Classifier/myenv/lib/python3.12/site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/onkars/Documents/AIProjects/Automated-Software-Refactoring-Commit-Classifier/myenv/lib/python3.12/site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/onkars/Documents/AIProjects/Automated-Software-Refactoring-Commit-Classifier/myenv/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_style(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.countplot(x=df.category, data=df, palette='coolwarm', hue=df.category, legend=False)\n",
    "\n",
    "plt.title('Count of Categories')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlabel('Categories')\n",
    "\n",
    "# annotate each bar with the number of occurences\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f'{int(p.get_height())}', # The number to annotate\n",
    "        (p.get_x() + p.get_width() / 2., p.get_height()), # Position\n",
    "        ha = 'center', # center horizontally\n",
    "        va = 'center', # center vertically\n",
    "        xytext = (0, 9), # Text offset\n",
    "        textcoords = 'offset points')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sum of duplicate records is \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"The sum of duplicate records is \")\n",
    "df.duplicated().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "commit_message    1721\n",
       "category          1721\n",
       "dtype: int64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removing the duplicates\n",
    "\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "commit_message    0\n",
       "category          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking for null values\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "commit_message    0\n",
       "category          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking for NaN values\n",
    "\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking for records with only spaces in the commit_message columns\n",
    "\n",
    "only_spaces_count = df['commit_message'].apply(lambda x: x.isspace() if pd.notnull(x) else False).sum()\n",
    "\n",
    "only_spaces_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(commit_message    1721\n",
       " category          1721\n",
       " dtype: int64,\n",
       " commit_message    1716\n",
       " category             5\n",
       " dtype: int64)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count(), df.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### found out the data descrepancy\n",
    "\n",
    "the total records are 1721 and the unique records are 1716 and 5 in columns commit_messages and categories, respectively\n",
    "\n",
    "I have done the root-cause analysis of this issue, to determine whether to keep the record or remove it completely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>commit_message</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>Enhanced tool palette composition functionality. Added Morph Activity/Gateway features.</td>\n",
       "      <td>internal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>Enhanced tool palette composition functionality. Added Morph Activity/Gateway features.</td>\n",
       "      <td>external</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>Issue 176: size can now test compatibility with images; refactored vcloud config logic; updated to support latest bluelock</td>\n",
       "      <td>internal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>Issue 176: size can now test compatibility with images; refactored vcloud config logic; updated to support latest bluelock</td>\n",
       "      <td>external</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>Make bitcoinSerialize() return a copy by default  provide an unsafeBitcoinSerialize() method for high performance applications that are willing to deal with the extra API complexity.</td>\n",
       "      <td>internal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>Make bitcoinSerialize() return a copy by default  provide an unsafeBitcoinSerialize() method for high performance applications that are willing to deal with the extra API complexity.</td>\n",
       "      <td>external</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1241</th>\n",
       "      <td>StewartSingularValueDecomposition: re-factor monolithic code and ugly switch statement into multiple methods</td>\n",
       "      <td>internal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1242</th>\n",
       "      <td>StewartSingularValueDecomposition: re-factor monolithic code and ugly switch statement into multiple methods</td>\n",
       "      <td>code smell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1346</th>\n",
       "      <td>[BACKLOG-4709] - Small changes in platform to improve performance - UserSettingService    - replace keySet() + get() combination with entrySet()    - remove useless object instantiation    - remove useless explicit map.remove() - AbstractSpringPentahoObjectFactory    - add logger.isDebugEnabled()    - remove useless non-null validation - OrderedApplicationEventMulticaster    - replace ArrayList with array for faster sorting    - extract stateless Comparator to a final field to avoid useless instantiation    - replace new Integer.compareTo() with Integer.compare()    - add tests - RoleAuthorizationPolicy    - create ArrayLists of exact size - JcrRepositoryFileAclUtils    - iterate through List  not Set - DefaultPermissionConversionHelper    - replace indexOf(\":\") with indexOf(':') as it is more effective - AuditConnection    - change the order: first try to obtain a connection and only then sleep</td>\n",
       "      <td>internal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1347</th>\n",
       "      <td>[BACKLOG-4709] - Small changes in platform to improve performance - UserSettingService    - replace keySet() + get() combination with entrySet()    - remove useless object instantiation    - remove useless explicit map.remove() - AbstractSpringPentahoObjectFactory    - add logger.isDebugEnabled()    - remove useless non-null validation - OrderedApplicationEventMulticaster    - replace ArrayList with array for faster sorting    - extract stateless Comparator to a final field to avoid useless instantiation    - replace new Integer.compareTo() with Integer.compare()    - add tests - RoleAuthorizationPolicy    - create ArrayLists of exact size - JcrRepositoryFileAclUtils    - iterate through List  not Set - DefaultPermissionConversionHelper    - replace indexOf(\":\") with indexOf(':') as it is more effective - AuditConnection    - change the order: first try to obtain a connection and only then sleep</td>\n",
       "      <td>external</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    commit_message  \\\n",
       "508                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Enhanced tool palette composition functionality. Added Morph Activity/Gateway features.   \n",
       "509                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Enhanced tool palette composition functionality. Added Morph Activity/Gateway features.   \n",
       "796                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Issue 176: size can now test compatibility with images; refactored vcloud config logic; updated to support latest bluelock   \n",
       "797                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Issue 176: size can now test compatibility with images; refactored vcloud config logic; updated to support latest bluelock   \n",
       "862                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Make bitcoinSerialize() return a copy by default  provide an unsafeBitcoinSerialize() method for high performance applications that are willing to deal with the extra API complexity.   \n",
       "863                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Make bitcoinSerialize() return a copy by default  provide an unsafeBitcoinSerialize() method for high performance applications that are willing to deal with the extra API complexity.   \n",
       "1241                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  StewartSingularValueDecomposition: re-factor monolithic code and ugly switch statement into multiple methods   \n",
       "1242                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  StewartSingularValueDecomposition: re-factor monolithic code and ugly switch statement into multiple methods   \n",
       "1346  [BACKLOG-4709] - Small changes in platform to improve performance - UserSettingService    - replace keySet() + get() combination with entrySet()    - remove useless object instantiation    - remove useless explicit map.remove() - AbstractSpringPentahoObjectFactory    - add logger.isDebugEnabled()    - remove useless non-null validation - OrderedApplicationEventMulticaster    - replace ArrayList with array for faster sorting    - extract stateless Comparator to a final field to avoid useless instantiation    - replace new Integer.compareTo() with Integer.compare()    - add tests - RoleAuthorizationPolicy    - create ArrayLists of exact size - JcrRepositoryFileAclUtils    - iterate through List  not Set - DefaultPermissionConversionHelper    - replace indexOf(\":\") with indexOf(':') as it is more effective - AuditConnection    - change the order: first try to obtain a connection and only then sleep   \n",
       "1347  [BACKLOG-4709] - Small changes in platform to improve performance - UserSettingService    - replace keySet() + get() combination with entrySet()    - remove useless object instantiation    - remove useless explicit map.remove() - AbstractSpringPentahoObjectFactory    - add logger.isDebugEnabled()    - remove useless non-null validation - OrderedApplicationEventMulticaster    - replace ArrayList with array for faster sorting    - extract stateless Comparator to a final field to avoid useless instantiation    - replace new Integer.compareTo() with Integer.compare()    - add tests - RoleAuthorizationPolicy    - create ArrayLists of exact size - JcrRepositoryFileAclUtils    - iterate through List  not Set - DefaultPermissionConversionHelper    - replace indexOf(\":\") with indexOf(':') as it is more effective - AuditConnection    - change the order: first try to obtain a connection and only then sleep   \n",
       "\n",
       "        category  \n",
       "508     internal  \n",
       "509     external  \n",
       "796     internal  \n",
       "797     external  \n",
       "862     internal  \n",
       "863     external  \n",
       "1241    internal  \n",
       "1242  code smell  \n",
       "1346    internal  \n",
       "1347    external  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "duplicate_records = df[df['commit_message'].duplicated(keep=False)]\n",
    "\n",
    "duplicate_records\n",
    "\n",
    "# 508, 796, 862, 1242, 1346"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**508, 509**: maybe new functionality, thus **internal** seems correct as it does not specifically mention fixing bugs or issues.\n",
    "\n",
    "**796, 797**: seems like internal enhancements and updates to existing systems, so **internal** \n",
    "\n",
    "**862, 863**: change in functionality to enhance performance and security, so **internal**\n",
    "\n",
    "**1241, 1242**: This is clearly a code maintenance task, thats why the **code smell** category\n",
    "\n",
    "**1346, 1347**: If \"external\" refers to changes that affect end-users or outside systems, and \"internal\" refers to changes within the codebase that do not affect external interfaces, then it's likely that both should be categorized as **internal**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(labels=[509, 797, 863, 1241, 1347], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Row Index: 400\n",
      "commit_message    Changes based on Keith's review.  A few tweaks to EdgeSet to help tracking edge\\nremoval\\n\\n\\tmodified:   src/edu/ucla/sspace/common/Similarity.java\\n\\n- Updated to use VectorMath.dotProduct for the Tanimoto coefficient\\n\\n\\tdeleted:    src/edu/ucla/sspace/common/WordComparator.java\\n\\n- Moved to SimpleNearestNeighborFinder\\n\\n\\tmodified:   src/edu/ucla/sspace/dependency/SimpleDependencyPath.java\\n\\n- Removed println\\n\\n\\tmodified:   src/edu/ucla/sspace/graph/AbstractGraph.java\\n\\n- Added missing implementation to Subgraph class so now all the unit tests pass\\n\\n\\tmodified:   src/edu/ucla/sspace/graph/DirectedMultigraph.java\\n\\n- Added missing implementation to Subgraph class so now all the unit tests pass\\n\\n- Fixed bug for reporting the correct edge types after removal\\n\\n- Removed dead code\\n\\n\\tmodified:   src/edu/ucla/sspace/graph/EdgeSet.java\\n\\n- Updated so that disconnect() now returns the number of edges that were removed\\n\\n\\tmodified:   src/edu/ucla/sspace/graph/GenericEdgeSet.java\\n\\tmodified:   src/edu/ucla/sspace/graph/SparseDirectedEdgeSet.java\\n\\tmodified:   src/edu/ucla/sspace/graph/SparseDirectedTypedEdgeSet.java\\n\\tmodified:   src/edu/ucla/sspace/graph/SparseTypedEdgeSet.java\\n\\tmodified:   src/edu/ucla/sspace/graph/SparseUndirectedEdgeSet.java\\n\\tmodified:   src/edu/ucla/sspace/graph/SparseWeightedEdgeSet.java\\n\\n- Updated to support EdgeSet interface change\\n\\n\\tdeleted:    src/edu/ucla/sspace/graph/GraphRandomizer.java\\n\\n- Removed dead class (functionality is in Graphs.java)\\n\\n\\tmodified:   src/edu/ucla/sspace/graph/SimpleWeightedEdge.java\\n\\n- Fixed hashCode()\\n\\n\\tdeleted:    src/edu/ucla/sspace/graph/SparseSymmetricEdgeSet.java\\n\\n- Removed dead class\\n\\n\\tmodified:   src/edu/ucla/sspace/graph/UndirectedMultigraph.java\\n\\n- Added missing implementation to Subgraph class so now all the unit tests pass\\n\\n- Fixed bug for reporting the correct edge types after removal\\n\\n- Removed dead code\\n\\n\\tmodified:   src/edu/ucla/sspace/mains/FixedDurationTemporalRandomIndexingMain.java\\n\\n- Updated to replace WordComparator with SimpleNearestNeighborFinder\\n\\n\\tmodified:   src/edu/ucla/sspace/mains/LexSubWordsiMain.java\\n\\n- Updated to replace WordComparator with SimpleNearestNeighborFinder\\n\\n\\tmodified:   src/edu/ucla/sspace/text/LabeledParsedStringDocument.java\\n\\n- Updated for new ParsedDocument interface\\n\\n\\tmodified:   src/edu/ucla/sspace/text/ParsedDocument.java\\n\\n- Updated to specify the format of text() as the tokens with white space delimiters.\\n\\n- Added a new prettyPrintText() which is the attempt to nicely format the tokens\\n  as they would have been originally.\\n\\n\\tmodified:   src/edu/ucla/sspace/text/PukWaCDocumentIterator.java\\n\\n- Fixed javadoc\\n\\n\\tmodified:   src/edu/ucla/sspace/text/UkWaCDocumentIterator.java\\n\\n- Added more class javadoc\\n\\n\\tmodified:   src/edu/ucla/sspace/tools/NearestNeighborFinderTool.java\\n\\n- Updated to use the class instances instead of the interface\\n\\n\\tmodified:   src/edu/ucla/sspace/tools/SemanticSpaceExplorer.java\\n\\n- Updated to replace WordComparator with PartitioningNearestNeighborFinder\\n\\n\\tmodified:   src/edu/ucla/sspace/tools/SimilarityListGenerator.java\\n\\n- Updated to replace WordComparator with PartitioningNearestNeighborFinder\\n\\n\\tmodified:   src/edu/ucla/sspace/util/HashIndexer.java\\n\\n- Fixed javadoc\\n\\n\\tmodified:   src/edu/ucla/sspace/util/PairCounter.java\\n\\n- Fixed javadoc\\n\\n\\trenamed:    src/edu/ucla/sspace/util/NearestNeighborFinder.java -> src/edu/ucla/sspace/util/PartitioningNearestNeighborFinder.java\\n\\n- Moved so that NearestNeighborFinder can be an interface\\n\\n\\tmodified:   src/edu/ucla/sspace/util/ReflectionUtil.java\\n\\n- Removed dead code\\n\\n\\tmodified:   src/edu/ucla/sspace/util/primitive/IntIntHashMultiMap.java\\n\\n- Added javadoc\\n\\n\\tmodified:   src/edu/ucla/sspace/util/primitive/IntIntMultiMap.java\\n\\n- Added javadoc\\n\\n\\tmodified:   test/edu/ucla/sspace/graph/DirectedMultigraphTests.java\\n\\n- Uncommented out unit tests\\n\\n\\tmodified:   test/edu/ucla/sspace/dependency/BreadthFirstPathIteratorTest.java\\n\\tmodified:   test/edu/ucla/sspace/dependency/CoNLLDependencyExtractorTest.java\\n\\tmodified:   test/edu/ucla/sspace/dependency/WaCKyDependencyExtractorTest.java\\n\\tmodified:   test/edu/ucla/sspace/text/corpora/PukWacDependencyCorpusReaderTest.java\\n\\tmodified:   test/edu/ucla/sspace/wordsi/DependencyContextExtractorTest.java\\n\\tmodified:   test/edu/ucla/sspace/wordsi/OccurrenceDependencyContextGeneratorTest.java\\n\\tmodified:   test/edu/ucla/sspace/wordsi/OrderingDependencyContextGeneratorTest.java\\n\\tmodified:   test/edu/ucla/sspace/wordsi/PartOfSpeechDependencyContextGeneratorTest.java\\n\\tmodified:   test/edu/ucla/sspace/wordsi/psd/PseudoWordDependencyContextExtractorTest.java\\n\\tmodified:   test/edu/ucla/sspace/wordsi/semeval/SemEvalDependencyContextExtractorTest.java\\n\\n- Fixed unit tests to support proper tab-delimiting of the CoNLL format\\n\n",
      "category                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          bugfix\n",
      "Name: 400, dtype: object\n",
      "Length: 4753\n",
      "\n",
      "Row Index: 833\n",
      "commit_message    Lots and lots of bug fixes with a few minor functionality enhancements.\\n\\n\\tmodified:   src/main/java/edu/ucla/sspace/common/Similarity.java\\n\\n- Added warnings for invalid KL-divergence computations\\n\\n- Added Kruskal-Goodman Gamma\\n\\n- Discovered Spearman's rho and Kendall's tau are both wrong (not fixed)  :(\\n\\n\\tmodified:   src/main/java/edu/ucla/sspace/common/statistics/LogLikelihoodTest.java\\n\\n- Fixed implementation\\n\\n\\tnew file:   src/main/java/edu/ucla/sspace/graph/ChineseWhispersClustering.java\\n\\n- Added CW clustering, but it doesn't appear to produce the same results as the\\n  existing code (needs investigation)\\n\\n\\tmodified:   src/main/java/edu/ucla/sspace/graph/GraphIO.java\\n\\n- Tweaked logging\\n\\n\\tmodified:   src/main/java/edu/ucla/sspace/graph/LinkClustering.java\\n\\n- Made thread count based on processors instead of fixed\\n\\n\\tnew file:   src/main/java/edu/ucla/sspace/graph/SimpleWeightedDirectedTypedEdge.java\\n\\tnew file:   src/main/java/edu/ucla/sspace/graph/SimpleWeightedTypedEdge.java\\n\\tnew file:   src/main/java/edu/ucla/sspace/graph/SparseWeightedDirectedEdgeSet.java\\n\\tnew file:   src/main/java/edu/ucla/sspace/graph/SparseWeightedDirectedTypedEdgeSet.java\\n\\tnew file:   src/main/java/edu/ucla/sspace/graph/WeightedDirectedMultigraph.java\\n\\tmodified:   src/main/java/edu/ucla/sspace/graph/WeightedDirectedTypedEdge.java\\n\\n- Added partial support for weighted multigraphs.  More features are probably needed eventually\\n\\n\\tmodified:   src/main/java/edu/ucla/sspace/graph/io/EdgeListReader.java\\n\\n- Added better logging instead of printf\\n\\n\\tnew file:   src/main/java/edu/ucla/sspace/graph/io/GraphMLReader.java\\n\\n- Added initial GraphML implementation for reading large GraphML files.  Only partial support is in place\\n\\n\\tmodified:   src/main/java/edu/ucla/sspace/index/DefaultPermutationFunction.java\\n\\n- Fixed outstanding bug.  Not sure how the bug was there in the first place, as\\n  the code was currently very broken in an odd way.\\n\\n\\tnew file:   src/main/java/edu/ucla/sspace/text/AnnotatedDocument.java\\n\\n- Added support for a new document that has a creation date and a label\\n\\n\\tnew file:   src/main/java/edu/ucla/sspace/text/BufferedFileListDocumentIterator.java\\n\\n- Added a new iterator that pre-caches the contents of files in a file list\\n  using a separate thread to cut down on disk I/O\\n\\n\\tmodified:   src/main/java/edu/ucla/sspace/text/FileDocument.java\\n\\n- Added support for a document back by a file whose contents are loaded into memory on demand\\n\\n\\tnew file:   src/main/java/edu/ucla/sspace/tools/IterativeBigramExtractor.java\\n\\n- Added a tool for finding statistical associations between terms in an\\n  iterative pair-wise manner\\n\\n\\tnew file:   src/main/java/edu/ucla/sspace/tools/LinkClusteringTool.java\\n\\n- Copied over code from the SVN branch for running link clustering from a jar\\n\\n\\tmodified:   src/main/java/edu/ucla/sspace/util/CombinedIterator.java\\n\\n- Corrected the Exception to be thrown in remove()\\n\\n\\tmodified:   src/main/java/edu/ucla/sspace/util/HashMultiMap.java\\n\\n- Correct a few errors in removing keys during iterator\\n\\n- Fixed a bug where null was returned instead of the empty set\\n\\n\\tnew file:   src/main/java/edu/ucla/sspace/util/KrippendorffsAlpha.java\\n\\n- Added a partial implementation of Krippendorff's alpha for ordinal-valued data\\n\\n\\tmodified:   src/main/java/edu/ucla/sspace/util/MultiMap.java\\n\\n- Clarified the javadoc\\n\\n\\tmodified:   src/main/java/edu/ucla/sspace/util/ObjectCounter.java\\n\\n- Implemented max() and min()\\n\\n\\tmodified:   src/main/java/edu/ucla/sspace/util/Pair.java\\n\\n- Made Serializable\\n\\n\\tmodified:   src/main/java/edu/ucla/sspace/util/SetDecorator.java\\n\\n- Clarified javadoc\\n\\n\\tnew file:   src/test/java/edu/ucla/sspace/graph/ChineseWhispersTest.java\\n\\tnew file:   src/test/java/edu/ucla/sspace/graph/SparseWeightedDirectedTypedEdgeSetTest.java\\n\\tnew file:   src/test/java/edu/ucla/sspace/graph/WeightedDirectedMultigraphTest.java\\n\\n- More unit tests\\n\\n\\tmodified:   src/test/java/edu/ucla/sspace/index/DefaultPermutationFunctionTest.java\\n\\n- Added some debugging output\\n\n",
      "category                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           bugfix\n",
      "Name: 833, dtype: object\n",
      "Length: 3995\n",
      "\n",
      "Row Index: 243\n",
      "commit_message    Added support for JDBC3.  The driver will now build under JDBC3 (i.e. Java 1.4).\\nThis concludes my changes that restructured the code to support JDBC3.\\nThe jdbc unit tests were also resturctured to allow different tests between\\njdbc2 and jdbc3, although currently make check (aka ant test) for JDBC3 just\\nruns the JDBC2 tests.  Of special note the largeobject/PGblob and PGclob\\nclasses have been moved under the jdbc2/jdbc3 specific directories as they\\nnow differ by jdbc version.  Also note that this checkin removes the\\nPostgresqlDataSource and files in the xa directory.  A recent checkin has\\nadded new datasource support that replaces the functionality provided by these\\nclasses.\\n\\n Modified Files:\\n \\tjdbc/build.xml\\n \\tjdbc/org/postgresql/jdbc1/AbstractJdbc1DatabaseMetaData.java\\n \\tjdbc/org/postgresql/jdbc1/AbstractJdbc1ResultSet.java\\n \\tjdbc/org/postgresql/jdbc1/AbstractJdbc1ResultSetMetaData.java\\n \\tjdbc/org/postgresql/jdbc1/AbstractJdbc1Statement.java\\n \\tjdbc/org/postgresql/jdbc2/AbstractJdbc2Connection.java\\n \\tjdbc/org/postgresql/jdbc2/AbstractJdbc2DatabaseMetaData.java\\n \\tjdbc/org/postgresql/jdbc2/AbstractJdbc2ResultSet.java\\n \\tjdbc/org/postgresql/jdbc2/AbstractJdbc2ResultSetMetaData.java\\n \\tjdbc/org/postgresql/jdbc2/AbstractJdbc2Statement.java\\n \\tjdbc/org/postgresql/jdbc2/Array.java\\n \\tjdbc/org/postgresql/jdbc2/Jdbc2CallableStatement.java\\n \\tjdbc/org/postgresql/jdbc2/Jdbc2Connection.java\\n \\tjdbc/org/postgresql/jdbc2/Jdbc2DatabaseMetaData.java\\n \\tjdbc/org/postgresql/jdbc2/Jdbc2PreparedStatement.java\\n \\tjdbc/org/postgresql/jdbc2/Jdbc2ResultSet.java\\n \\tjdbc/org/postgresql/jdbc2/Jdbc2ResultSetMetaData.java\\n \\tjdbc/org/postgresql/jdbc2/Jdbc2Statement.java\\n \\tjdbc/org/postgresql/test/jdbc2/BatchExecuteTest.java\\n \\tjdbc/org/postgresql/test/jdbc2/BlobTest.java\\n \\tjdbc/org/postgresql/test/jdbc2/CallableStmtTest.java\\n \\tjdbc/org/postgresql/test/jdbc2/ConnectionTest.java\\n \\tjdbc/org/postgresql/test/jdbc2/DatabaseMetaDataTest.java\\n \\tjdbc/org/postgresql/test/jdbc2/DateTest.java\\n \\tjdbc/org/postgresql/test/jdbc2/DriverTest.java\\n \\tjdbc/org/postgresql/test/jdbc2/JBuilderTest.java\\n \\tjdbc/org/postgresql/test/jdbc2/MiscTest.java\\n \\tjdbc/org/postgresql/test/jdbc2/ResultSetTest.java\\n \\tjdbc/org/postgresql/test/jdbc2/TimeTest.java\\n \\tjdbc/org/postgresql/test/jdbc2/TimestampTest.java\\n \\tjdbc/org/postgresql/test/jdbc2/UpdateableResultTest.java\\n Added Files:\\n \\tjdbc/org/postgresql/jdbc2/AbstractJdbc2Blob.java\\n \\tjdbc/org/postgresql/jdbc2/AbstractJdbc2Clob.java\\n \\tjdbc/org/postgresql/jdbc2/Jdbc2Blob.java\\n \\tjdbc/org/postgresql/jdbc2/Jdbc2Clob.java\\n \\tjdbc/org/postgresql/jdbc3/AbstractJdbc3Blob.java\\n \\tjdbc/org/postgresql/jdbc3/AbstractJdbc3Clob.java\\n \\tjdbc/org/postgresql/jdbc3/AbstractJdbc3Connection.java\\n \\tjdbc/org/postgresql/jdbc3/AbstractJdbc3DatabaseMetaData.java\\n \\tjdbc/org/postgresql/jdbc3/AbstractJdbc3ResultSet.java\\n \\tjdbc/org/postgresql/jdbc3/AbstractJdbc3Statement.java\\n \\tjdbc/org/postgresql/jdbc3/Jdbc3Blob.java\\n \\tjdbc/org/postgresql/jdbc3/Jdbc3CallableStatement.java\\n \\tjdbc/org/postgresql/jdbc3/Jdbc3Clob.java\\n \\tjdbc/org/postgresql/jdbc3/Jdbc3Connection.java\\n \\tjdbc/org/postgresql/jdbc3/Jdbc3DatabaseMetaData.java\\n \\tjdbc/org/postgresql/jdbc3/Jdbc3PreparedStatement.java\\n \\tjdbc/org/postgresql/jdbc3/Jdbc3ResultSet.java\\n \\tjdbc/org/postgresql/jdbc3/Jdbc3ResultSetMetaData.java\\n \\tjdbc/org/postgresql/jdbc3/Jdbc3Statement.java\\n \\tjdbc/org/postgresql/test/TestUtil.java\\n \\tjdbc/org/postgresql/test/jdbc2/Jdbc2TestSuite.java\\n \\tjdbc/org/postgresql/test/jdbc3/Jdbc3TestSuite.java\\n Removed Files:\\n \\tjdbc/org/postgresql/PostgresqlDataSource.java\\n \\tjdbc/org/postgresql/largeobject/PGblob.java\\n \\tjdbc/org/postgresql/largeobject/PGclob.java\\n \\tjdbc/org/postgresql/test/JDBC2Tests.java\\n \\tjdbc/org/postgresql/xa/ClientConnection.java\\n \\tjdbc/org/postgresql/xa/TwoPhaseConnection.java\\n \\tjdbc/org/postgresql/xa/TxConnection.java\\n \\tjdbc/org/postgresql/xa/XAConnectionImpl.java\\n \\tjdbc/org/postgresql/xa/XADataSourceImpl.java\\n\n",
      "category                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         functional\n",
      "Name: 243, dtype: object\n",
      "Length: 3903\n",
      "\n",
      "Row Index: 878\n",
      "commit_message    Merged revisions 391-416 via svnmerge from \\nhttps://svn.parabola.me.uk/svn/mkgmap/branches/filters\\n\\n........\\n  r391 | steve | 2007-12-01 17:22:34 +0000 (Sat, 01 Dec 2007) | 1 line\\n  \\n  Broke out the splitting of lines a little.\\n........\\n  r392 | steve | 2007-12-01 17:28:23 +0000 (Sat, 01 Dec 2007) | 1 line\\n  \\n  Remove the inline line splitting code.\\n........\\n  r393 | steve | 2007-12-01 20:29:03 +0000 (Sat, 01 Dec 2007) | 1 line\\n  \\n  Create filter infrastructure.\\n........\\n  r394 | steve | 2007-12-02 14:35:27 +0000 (Sun, 02 Dec 2007) | 2 lines\\n  \\n  A working implementation, although there is more to break out into filters and then we need to add some\\n  more functionality.\\n........\\n  r395 | steve | 2007-12-02 22:12:43 +0000 (Sun, 02 Dec 2007) | 1 line\\n  \\n  rename filter chain\\n........\\n  r396 | steve | 2007-12-02 22:13:25 +0000 (Sun, 02 Dec 2007) | 1 line\\n  \\n  rename line splitting filter\\n........\\n  r397 | steve | 2007-12-03 09:00:24 +0000 (Mon, 03 Dec 2007) | 1 line\\n  \\n  rename line splitting filter, add polygon splitter\\n........\\n  r398 | steve | 2007-12-03 10:28:16 +0000 (Mon, 03 Dec 2007) | 1 line\\n  \\n  Make sure that lines are always copied before changing their points as this would change them for all levels.\\n........\\n  r399 | steve | 2007-12-03 10:29:17 +0000 (Mon, 03 Dec 2007) | 1 line\\n  \\n  Add the copy constructors to the MapShape class too.\\n........\\n  r400 | steve | 2007-12-03 11:03:36 +0000 (Mon, 03 Dec 2007) | 1 line\\n  \\n  Add filtering for polygons and only add the line filter for lines and the polygon filters for polygons...\\n........\\n  r401 | steve | 2007-12-03 11:22:18 +0000 (Mon, 03 Dec 2007) | 1 line\\n  \\n  Some tidying\\n........\\n  r402 | steve | 2007-12-03 12:07:22 +0000 (Mon, 03 Dec 2007) | 1 line\\n  \\n  Split out files from the general package that do the actual general-->garmin conversion.\\n........\\n  r405 | steve | 2007-12-03 17:23:48 +0000 (Mon, 03 Dec 2007) | 1 line\\n  \\n  Useful amount of smothing applied.\\n........\\n  r406 | steve | 2007-12-03 20:58:29 +0000 (Mon, 03 Dec 2007) | 1 line\\n  \\n  Fix where was not returning after chaining the filter.\\n........\\n  r407 | steve | 2007-12-03 20:59:07 +0000 (Mon, 03 Dec 2007) | 1 line\\n  \\n  Now we have a polygon splitter.  Polygons that have too many points will be split.\\n........\\n  r408 | steve | 2007-12-03 21:16:07 +0000 (Mon, 03 Dec 2007) | 2 lines\\n  \\n  Remove println's\\n........\\n  r409 | steve | 2007-12-03 21:23:57 +0000 (Mon, 03 Dec 2007) | 1 line\\n  \\n  Now that the smoothing is in a filter, remove the old code to remove duplicate points.\\n........\\n\\n\\ngit-svn-id: http://svn.mkgmap.org.uk/mkgmap/trunk@417 25d90789-57f7-4ee0-8453-03a3dfeeeb22\\n\n",
      "category                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           bugfix\n",
      "Name: 878, dtype: object\n",
      "Length: 2635\n",
      "\n",
      "Row Index: 50\n",
      "commit_message    - Added target for the nearest neighbor finder tool\\n- Reduced the default timeout for long-running tests\\n\\n- Added a jaccardIndex overload for two sets of elements\\n\\n- Fixed javadoc\\n\\n- Made class serializable\\n\\n- Added support for maximum path length\\n\\n- Reworked to use the new SimpleDependencyPath class\\n\\n- Revised error message for clarity\\n\\n- Updated to use new SimpleDependencyPath features\\n\\n- Updated to use new SimpleDependencyPath features\\n\\n- Major rewrite for clarity\\n\\n- Fixed toString()\\n\\n- Added static methods for testing the category of particular POS tag\\n\\n- Implemented missing methods\\n\\n- Added more imports (not sure why...)\\n\\n- Added logging\\n\\n- Added support for shuffling the edges of a graph using a fixed Random for reproducability\\n\\n- Multithreaded the edge similarity comparison\\n\\n- Probably some bug fixes too\\n\\n- Updated to use IntPair instead of Pair<Integer>\\n\\n- Updated to use IntSet\\n\\n- Major overhaul to bring performance in line with the earlier primitive\\n  collection enhancements\\n\\n- Probably needs a lot of clean up still\\n\\n- Updates to use new primitive collections\\n\\n- Updates to use new primitive collections\\n\\n- Added support for clustering to a fixed number of clusters\\n\\n- Added (limited) support for writing in GEXF format\\n\\n- Added (limited) support for writing in Pajek format\\n\\n- Made default output verbose\\n\\n- Remove extra temporary file that was just hanging around unneeded\\n\\n- Added support for getting the String that backs the document\\n\\n- Added a new class for testing the association between two terms, which is\\n  already partially supported by the BigramExtractor, but this class supports\\n  limiting the number of items being associated which enables better scaling\\n  through iterative association testing.\\n\\n- This class needs a lot of work.\\n\\n- Added an iterator for the documents in WaCkypedia\\n\\n- Fixed HTML bug in javadoc\\n\\n- Added new tool for running the NearestNeighborFinder from the command line\\n\\n- Fixed javadoc\\n\\n- Added support for changing the loging level of any logger namespace\\n\\n- Added new tool for speeding up repeated nearest-neighbor computations by\\n  partitioning a SemanticSpace into clusters (using K-means) and then only\\n  searching a subset.\\n\\n- Added support for reading and writing to streams and byte[] arrays\\n\\n- Updated to be an IntSet\\n\\n- Added Pair implementation\\n\\n- Fixed iterator remove bug\\n\\n- Added more extensive real-world unit tests\\n\\n- Added unit test details that match the example in the Ahn et al. paper\\n\\n- Added more tests\\n\n",
      "category                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            bugfix\n",
      "Name: 50, dtype: object\n",
      "Length: 2488\n"
     ]
    }
   ],
   "source": [
    "# Find the top 5 rows with the maximum lengths in 'col1' (sorted by descending length)\n",
    "top_5_max_lengths = df['commit_message'].str.len().sort_values(ascending=False).head(5)\n",
    "\n",
    "# Print the top 5 rows with corresponding lengths\n",
    "for index, length in top_5_max_lengths.items():\n",
    "  print(f\"\\nRow Index: {index}\")\n",
    "  print(df.loc[index])\n",
    "  print(f\"Length: {length}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: contractions in /Users/onkars/Documents/AIProjects/Automated-Software-Refactoring-Commit-Classifier/myenv/lib/python3.12/site-packages (0.1.73)\n",
      "Requirement already satisfied: textsearch>=0.0.21 in /Users/onkars/Documents/AIProjects/Automated-Software-Refactoring-Commit-Classifier/myenv/lib/python3.12/site-packages (from contractions) (0.0.24)\n",
      "Requirement already satisfied: anyascii in /Users/onkars/Documents/AIProjects/Automated-Software-Refactoring-Commit-Classifier/myenv/lib/python3.12/site-packages (from textsearch>=0.0.21->contractions) (0.3.2)\n",
      "Requirement already satisfied: pyahocorasick in /Users/onkars/Documents/AIProjects/Automated-Software-Refactoring-Commit-Classifier/myenv/lib/python3.12/site-packages (from textsearch>=0.0.21->contractions) (2.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /Users/onkars/Documents/AIProjects/Automated-Software-Refactoring-Commit-Classifier/myenv/lib/python3.12/site-packages (3.8.1)\n",
      "Requirement already satisfied: click in /Users/onkars/Documents/AIProjects/Automated-Software-Refactoring-Commit-Classifier/myenv/lib/python3.12/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /Users/onkars/Documents/AIProjects/Automated-Software-Refactoring-Commit-Classifier/myenv/lib/python3.12/site-packages (from nltk) (1.4.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/onkars/Documents/AIProjects/Automated-Software-Refactoring-Commit-Classifier/myenv/lib/python3.12/site-packages (from nltk) (2024.4.16)\n",
      "Requirement already satisfied: tqdm in /Users/onkars/Documents/AIProjects/Automated-Software-Refactoring-Commit-Classifier/myenv/lib/python3.12/site-packages (from nltk) (4.66.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/onkars/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/onkars/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/onkars/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to /Users/onkars/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "# import ssl\n",
    "# try:\n",
    "#    _create_unverified_https_context = ssl._create_unverified_context\n",
    "# except AttributeError:\n",
    "#    pass\n",
    "# else:\n",
    "#    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: unidecode in /Users/onkars/Documents/AIProjects/Automated-Software-Refactoring-Commit-Classifier/myenv/lib/python3.12/site-packages (1.3.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import contractions\n",
    "import unidecode\n",
    "\n",
    "def clean_text(text):\n",
    "    # Lowercase the text\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Expand contractions\n",
    "    text = contractions.fix(text)\n",
    "    \n",
    "    # Normalize accents and special characters\n",
    "    text = unidecode.unidecode(text)\n",
    "    \n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    \n",
    "    # Remove single-character tokens (mostly punctuation)\n",
    "    text = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', text)\n",
    "    \n",
    "    # Remove single characters from the start\n",
    "    text = re.sub(r'\\^[a-zA-Z]\\s+', ' ', text)\n",
    "    \n",
    "    # Substitute multiple spaces with single space\n",
    "    text = re.sub(r'\\s+', ' ', text, flags=re.I)\n",
    "    \n",
    "    # Remove prefixed 'b'\n",
    "    text = re.sub(r'^b\\s+', '', text)\n",
    "    \n",
    "    # Remove numbers\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    \n",
    "    # Remove non-alphabetic characters\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    \n",
    "    # Trim leading and trailing whitespace\n",
    "    text = text.strip()\n",
    "    \n",
    "    return text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# custom_stop_words = ['git', 'svn', 'refactor', 'gitsvnid', 'signedoffby', 'reviewedon', 'testedby', 'us', 'id', 'changeid', 'lot', 'small', 'thing', 'way']  # Add more custom words here --- lots\n",
    "# stop_words.update(custom_stop_words)\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    word_tokens = word_tokenize(text)\n",
    "    filtered_text = [word for word in word_tokens if word.lower() not in stop_words]\n",
    "    return ' '.join(filtered_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['commit_message_clean'] = df['commit_message'].apply(clean_text)\n",
    "df['commit_message_clean'] = df['commit_message_clean'].apply(remove_stopwords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>commit_message</th>\n",
       "      <th>category</th>\n",
       "      <th>commit_message_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>Changes based on Keith's review.  A few tweaks to EdgeSet to help tracking edge\\nremoval\\n\\n\\tmodified:   src/edu/ucla/sspace/common/Similarity.java\\n\\n- Updated to use VectorMath.dotProduct for the Tanimoto coefficient\\n\\n\\tdeleted:    src/edu/ucla/sspace/common/WordComparator.java\\n\\n- Moved to SimpleNearestNeighborFinder\\n\\n\\tmodified:   src/edu/ucla/sspace/dependency/SimpleDependencyPath.java\\n\\n- Removed println\\n\\n\\tmodified:   src/edu/ucla/sspace/graph/AbstractGraph.java\\n\\n- Added missing implementation to Subgraph class so now all the unit tests pass\\n\\n\\tmodified:   src/edu/ucla/sspace/graph/DirectedMultigraph.java\\n\\n- Added missing implementation to Subgraph class so now all the unit tests pass\\n\\n- Fixed bug for reporting the correct edge types after removal\\n\\n- Removed dead code\\n\\n\\tmodified:   src/edu/ucla/sspace/graph/EdgeSet.java\\n\\n- Updated so that disconnect() now returns the number of edges that were removed\\n\\n\\tmodified:   src/edu/ucla/sspace/graph/GenericEdgeSet.java\\n\\tmodified:   src/edu/ucla/sspace/graph/SparseDirectedEdgeSet.java\\n\\tmodified:   src/edu/ucla/sspace/graph/SparseDirectedTypedEdgeSet.java\\n\\tmodified:   src/edu/ucla/sspace/graph/SparseTypedEdgeSet.java\\n\\tmodified:   src/edu/ucla/sspace/graph/SparseUndirectedEdgeSet.java\\n\\tmodified:   src/edu/ucla/sspace/graph/SparseWeightedEdgeSet.java\\n\\n- Updated to support EdgeSet interface change\\n\\n\\tdeleted:    src/edu/ucla/sspace/graph/GraphRandomizer.java\\n\\n- Removed dead class (functionality is in Graphs.java)\\n\\n\\tmodified:   src/edu/ucla/sspace/graph/SimpleWeightedEdge.java\\n\\n- Fixed hashCode()\\n\\n\\tdeleted:    src/edu/ucla/sspace/graph/SparseSymmetricEdgeSet.java\\n\\n- Removed dead class\\n\\n\\tmodified:   src/edu/ucla/sspace/graph/UndirectedMultigraph.java\\n\\n- Added missing implementation to Subgraph class so now all the unit tests pass\\n\\n- Fixed bug for reporting the correct edge types after removal\\n\\n- Removed dead code\\n\\n\\tmodified:   src/edu/ucla/sspace/mains/FixedDurationTemporalRandomIndexingMain.java\\n\\n- Updated to replace WordComparator with SimpleNearestNeighborFinder\\n\\n\\tmodified:   src/edu/ucla/sspace/mains/LexSubWordsiMain.java\\n\\n- Updated to replace WordComparator with SimpleNearestNeighborFinder\\n\\n\\tmodified:   src/edu/ucla/sspace/text/LabeledParsedStringDocument.java\\n\\n- Updated for new ParsedDocument interface\\n\\n\\tmodified:   src/edu/ucla/sspace/text/ParsedDocument.java\\n\\n- Updated to specify the format of text() as the tokens with white space delimiters.\\n\\n- Added a new prettyPrintText() which is the attempt to nicely format the tokens\\n  as they would have been originally.\\n\\n\\tmodified:   src/edu/ucla/sspace/text/PukWaCDocumentIterator.java\\n\\n- Fixed javadoc\\n\\n\\tmodified:   src/edu/ucla/sspace/text/UkWaCDocumentIterator.java\\n\\n- Added more class javadoc\\n\\n\\tmodified:   src/edu/ucla/sspace/tools/NearestNeighborFinderTool.java\\n\\n- Updated to use the class instances instead of the interface\\n\\n\\tmodified:   src/edu/ucla/sspace/tools/SemanticSpaceExplorer.java\\n\\n- Updated to replace WordComparator with PartitioningNearestNeighborFinder\\n\\n\\tmodified:   src/edu/ucla/sspace/tools/SimilarityListGenerator.java\\n\\n- Updated to replace WordComparator with PartitioningNearestNeighborFinder\\n\\n\\tmodified:   src/edu/ucla/sspace/util/HashIndexer.java\\n\\n- Fixed javadoc\\n\\n\\tmodified:   src/edu/ucla/sspace/util/PairCounter.java\\n\\n- Fixed javadoc\\n\\n\\trenamed:    src/edu/ucla/sspace/util/NearestNeighborFinder.java -&gt; src/edu/ucla/sspace/util/PartitioningNearestNeighborFinder.java\\n\\n- Moved so that NearestNeighborFinder can be an interface\\n\\n\\tmodified:   src/edu/ucla/sspace/util/ReflectionUtil.java\\n\\n- Removed dead code\\n\\n\\tmodified:   src/edu/ucla/sspace/util/primitive/IntIntHashMultiMap.java\\n\\n- Added javadoc\\n\\n\\tmodified:   src/edu/ucla/sspace/util/primitive/IntIntMultiMap.java\\n\\n- Added javadoc\\n\\n\\tmodified:   test/edu/ucla/sspace/graph/DirectedMultigraphTests.java\\n\\n- Uncommented out unit tests\\n\\n\\tmodified:   test/edu/ucla/sspace/dependency/BreadthFirstPathIteratorTest.java\\n\\tmodified:   test/edu/ucla/sspace/dependency/CoNLLDependencyExtractorTest.java\\n\\tmodified:   test/edu/ucla/sspace/dependency/WaCKyDependencyExtractorTest.java\\n\\tmodified:   test/edu/ucla/sspace/text/corpora/PukWacDependencyCorpusReaderTest.java\\n\\tmodified:   test/edu/ucla/sspace/wordsi/DependencyContextExtractorTest.java\\n\\tmodified:   test/edu/ucla/sspace/wordsi/OccurrenceDependencyContextGeneratorTest.java\\n\\tmodified:   test/edu/ucla/sspace/wordsi/OrderingDependencyContextGeneratorTest.java\\n\\tmodified:   test/edu/ucla/sspace/wordsi/PartOfSpeechDependencyContextGeneratorTest.java\\n\\tmodified:   test/edu/ucla/sspace/wordsi/psd/PseudoWordDependencyContextExtractorTest.java\\n\\tmodified:   test/edu/ucla/sspace/wordsi/semeval/SemEvalDependencyContextExtractorTest.java\\n\\n- Fixed unit tests to support proper tab-delimiting of the CoNLL format\\n</td>\n",
       "      <td>bugfix</td>\n",
       "      <td>changes based keiths review tweaks edgeset help tracking edge removal modified srceduuclasspacecommonsimilarityjava updated use vectormathdotproduct tanimoto coefficient deleted srceduuclasspacecommonwordcomparatorjava moved simplenearestneighborfinder modified srceduuclasspacedependencysimpledependencypathjava removed println modified srceduuclasspacegraphabstractgraphjava added missing implementation subgraph class unit tests pass modified srceduuclasspacegraphdirectedmultigraphjava added missing implementation subgraph class unit tests pass fixed bug reporting correct edge types removal removed dead code modified srceduuclasspacegraphedgesetjava updated disconnect returns number edges removed modified srceduuclasspacegraphgenericedgesetjava modified srceduuclasspacegraphsparsedirectededgesetjava modified srceduuclasspacegraphsparsedirectedtypededgesetjava modified srceduuclasspacegraphsparsetypededgesetjava modified srceduuclasspacegraphsparseundirectededgesetjava modified srceduuclasspacegraphsparseweightededgesetjava updated support edgeset interface change deleted srceduuclasspacegraphgraphrandomizerjava removed dead class functionality graphsjava modified srceduuclasspacegraphsimpleweightededgejava fixed hashcode deleted srceduuclasspacegraphsparsesymmetricedgesetjava removed dead class modified srceduuclasspacegraphundirectedmultigraphjava added missing implementation subgraph class unit tests pass fixed bug reporting correct edge types removal removed dead code modified srceduuclasspacemainsfixeddurationtemporalrandomindexingmainjava updated replace wordcomparator simplenearestneighborfinder modified srceduuclasspacemainslexsubwordsimainjava updated replace wordcomparator simplenearestneighborfinder modified srceduuclasspacetextlabeledparsedstringdocumentjava updated new parseddocument interface modified srceduuclasspacetextparseddocumentjava updated specify format text tokens white space delimiters added new prettyprinttext attempt nicely format tokens would originally modified srceduuclasspacetextpukwacdocumentiteratorjava fixed javadoc modified srceduuclasspacetextukwacdocumentiteratorjava added class javadoc modified srceduuclasspacetoolsnearestneighborfindertooljava updated use class instances instead interface modified srceduuclasspacetoolssemanticspaceexplorerjava updated replace wordcomparator partitioningnearestneighborfinder modified srceduuclasspacetoolssimilaritylistgeneratorjava updated replace wordcomparator partitioningnearestneighborfinder modified srceduuclasspaceutilhashindexerjava fixed javadoc modified srceduuclasspaceutilpaircounterjava fixed javadoc renamed srceduuclasspaceutilnearestneighborfinderjava srceduuclasspaceutilpartitioningnearestneighborfinderjava moved nearestneighborfinder interface modified srceduuclasspaceutilreflectionutiljava removed dead code modified srceduuclasspaceutilprimitiveintinthashmultimapjava added javadoc modified srceduuclasspaceutilprimitiveintintmultimapjava added javadoc modified testeduuclasspacegraphdirectedmultigraphtestsjava uncommented unit tests modified testeduuclasspacedependencybreadthfirstpathiteratortestjava modified testeduuclasspacedependencyconlldependencyextractortestjava modified testeduuclasspacedependencywackydependencyextractortestjava modified testeduuclasspacetextcorporapukwacdependencycorpusreadertestjava modified testeduuclasspacewordsidependencycontextextractortestjava modified testeduuclasspacewordsioccurrencedependencycontextgeneratortestjava modified testeduuclasspacewordsiorderingdependencycontextgeneratortestjava modified testeduuclasspacewordsipartofspeechdependencycontextgeneratortestjava modified testeduuclasspacewordsipsdpseudoworddependencycontextextractortestjava modified testeduuclasspacewordsisemevalsemevaldependencycontextextractortestjava fixed unit tests support proper tabdelimiting conll format</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>833</th>\n",
       "      <td>Lots and lots of bug fixes with a few minor functionality enhancements.\\n\\n\\tmodified:   src/main/java/edu/ucla/sspace/common/Similarity.java\\n\\n- Added warnings for invalid KL-divergence computations\\n\\n- Added Kruskal-Goodman Gamma\\n\\n- Discovered Spearman's rho and Kendall's tau are both wrong (not fixed)  :(\\n\\n\\tmodified:   src/main/java/edu/ucla/sspace/common/statistics/LogLikelihoodTest.java\\n\\n- Fixed implementation\\n\\n\\tnew file:   src/main/java/edu/ucla/sspace/graph/ChineseWhispersClustering.java\\n\\n- Added CW clustering, but it doesn't appear to produce the same results as the\\n  existing code (needs investigation)\\n\\n\\tmodified:   src/main/java/edu/ucla/sspace/graph/GraphIO.java\\n\\n- Tweaked logging\\n\\n\\tmodified:   src/main/java/edu/ucla/sspace/graph/LinkClustering.java\\n\\n- Made thread count based on processors instead of fixed\\n\\n\\tnew file:   src/main/java/edu/ucla/sspace/graph/SimpleWeightedDirectedTypedEdge.java\\n\\tnew file:   src/main/java/edu/ucla/sspace/graph/SimpleWeightedTypedEdge.java\\n\\tnew file:   src/main/java/edu/ucla/sspace/graph/SparseWeightedDirectedEdgeSet.java\\n\\tnew file:   src/main/java/edu/ucla/sspace/graph/SparseWeightedDirectedTypedEdgeSet.java\\n\\tnew file:   src/main/java/edu/ucla/sspace/graph/WeightedDirectedMultigraph.java\\n\\tmodified:   src/main/java/edu/ucla/sspace/graph/WeightedDirectedTypedEdge.java\\n\\n- Added partial support for weighted multigraphs.  More features are probably needed eventually\\n\\n\\tmodified:   src/main/java/edu/ucla/sspace/graph/io/EdgeListReader.java\\n\\n- Added better logging instead of printf\\n\\n\\tnew file:   src/main/java/edu/ucla/sspace/graph/io/GraphMLReader.java\\n\\n- Added initial GraphML implementation for reading large GraphML files.  Only partial support is in place\\n\\n\\tmodified:   src/main/java/edu/ucla/sspace/index/DefaultPermutationFunction.java\\n\\n- Fixed outstanding bug.  Not sure how the bug was there in the first place, as\\n  the code was currently very broken in an odd way.\\n\\n\\tnew file:   src/main/java/edu/ucla/sspace/text/AnnotatedDocument.java\\n\\n- Added support for a new document that has a creation date and a label\\n\\n\\tnew file:   src/main/java/edu/ucla/sspace/text/BufferedFileListDocumentIterator.java\\n\\n- Added a new iterator that pre-caches the contents of files in a file list\\n  using a separate thread to cut down on disk I/O\\n\\n\\tmodified:   src/main/java/edu/ucla/sspace/text/FileDocument.java\\n\\n- Added support for a document back by a file whose contents are loaded into memory on demand\\n\\n\\tnew file:   src/main/java/edu/ucla/sspace/tools/IterativeBigramExtractor.java\\n\\n- Added a tool for finding statistical associations between terms in an\\n  iterative pair-wise manner\\n\\n\\tnew file:   src/main/java/edu/ucla/sspace/tools/LinkClusteringTool.java\\n\\n- Copied over code from the SVN branch for running link clustering from a jar\\n\\n\\tmodified:   src/main/java/edu/ucla/sspace/util/CombinedIterator.java\\n\\n- Corrected the Exception to be thrown in remove()\\n\\n\\tmodified:   src/main/java/edu/ucla/sspace/util/HashMultiMap.java\\n\\n- Correct a few errors in removing keys during iterator\\n\\n- Fixed a bug where null was returned instead of the empty set\\n\\n\\tnew file:   src/main/java/edu/ucla/sspace/util/KrippendorffsAlpha.java\\n\\n- Added a partial implementation of Krippendorff's alpha for ordinal-valued data\\n\\n\\tmodified:   src/main/java/edu/ucla/sspace/util/MultiMap.java\\n\\n- Clarified the javadoc\\n\\n\\tmodified:   src/main/java/edu/ucla/sspace/util/ObjectCounter.java\\n\\n- Implemented max() and min()\\n\\n\\tmodified:   src/main/java/edu/ucla/sspace/util/Pair.java\\n\\n- Made Serializable\\n\\n\\tmodified:   src/main/java/edu/ucla/sspace/util/SetDecorator.java\\n\\n- Clarified javadoc\\n\\n\\tnew file:   src/test/java/edu/ucla/sspace/graph/ChineseWhispersTest.java\\n\\tnew file:   src/test/java/edu/ucla/sspace/graph/SparseWeightedDirectedTypedEdgeSetTest.java\\n\\tnew file:   src/test/java/edu/ucla/sspace/graph/WeightedDirectedMultigraphTest.java\\n\\n- More unit tests\\n\\n\\tmodified:   src/test/java/edu/ucla/sspace/index/DefaultPermutationFunctionTest.java\\n\\n- Added some debugging output\\n</td>\n",
       "      <td>bugfix</td>\n",
       "      <td>lots lots bug fixes minor functionality enhancements modified srcmainjavaeduuclasspacecommonsimilarityjava added warnings invalid kldivergence computations added kruskalgoodman gamma discovered spearmans rho kendalls tau wrong fixed modified srcmainjavaeduuclasspacecommonstatisticsloglikelihoodtestjava fixed implementation new file srcmainjavaeduuclasspacegraphchinesewhispersclusteringjava added cw clustering appear produce results existing code needs investigation modified srcmainjavaeduuclasspacegraphgraphiojava tweaked logging modified srcmainjavaeduuclasspacegraphlinkclusteringjava made thread count based processors instead fixed new file srcmainjavaeduuclasspacegraphsimpleweighteddirectedtypededgejava new file srcmainjavaeduuclasspacegraphsimpleweightedtypededgejava new file srcmainjavaeduuclasspacegraphsparseweighteddirectededgesetjava new file srcmainjavaeduuclasspacegraphsparseweighteddirectedtypededgesetjava new file srcmainjavaeduuclasspacegraphweighteddirectedmultigraphjava modified srcmainjavaeduuclasspacegraphweighteddirectedtypededgejava added partial support weighted multigraphs features probably needed eventually modified srcmainjavaeduuclasspacegraphioedgelistreaderjava added better logging instead printf new file srcmainjavaeduuclasspacegraphiographmlreaderjava added initial graphml implementation reading large graphml files partial support place modified srcmainjavaeduuclasspaceindexdefaultpermutationfunctionjava fixed outstanding bug sure bug first place code currently broken odd way new file srcmainjavaeduuclasspacetextannotateddocumentjava added support new document creation date label new file srcmainjavaeduuclasspacetextbufferedfilelistdocumentiteratorjava added new iterator precaches contents files file list using separate thread cut disk io modified srcmainjavaeduuclasspacetextfiledocumentjava added support document back file whose contents loaded memory demand new file srcmainjavaeduuclasspacetoolsiterativebigramextractorjava added tool finding statistical associations terms iterative pairwise manner new file srcmainjavaeduuclasspacetoolslinkclusteringtooljava copied code svn branch running link clustering jar modified srcmainjavaeduuclasspaceutilcombinediteratorjava corrected exception thrown remove modified srcmainjavaeduuclasspaceutilhashmultimapjava correct errors removing keys iterator fixed bug null returned instead empty set new file srcmainjavaeduuclasspaceutilkrippendorffsalphajava added partial implementation krippendorffs alpha ordinalvalued data modified srcmainjavaeduuclasspaceutilmultimapjava clarified javadoc modified srcmainjavaeduuclasspaceutilobjectcounterjava implemented max min modified srcmainjavaeduuclasspaceutilpairjava made serializable modified srcmainjavaeduuclasspaceutilsetdecoratorjava clarified javadoc new file srctestjavaeduuclasspacegraphchinesewhisperstestjava new file srctestjavaeduuclasspacegraphsparseweighteddirectedtypededgesettestjava new file srctestjavaeduuclasspacegraphweighteddirectedmultigraphtestjava unit tests modified srctestjavaeduuclasspaceindexdefaultpermutationfunctiontestjava added debugging output</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>Added support for JDBC3.  The driver will now build under JDBC3 (i.e. Java 1.4).\\nThis concludes my changes that restructured the code to support JDBC3.\\nThe jdbc unit tests were also resturctured to allow different tests between\\njdbc2 and jdbc3, although currently make check (aka ant test) for JDBC3 just\\nruns the JDBC2 tests.  Of special note the largeobject/PGblob and PGclob\\nclasses have been moved under the jdbc2/jdbc3 specific directories as they\\nnow differ by jdbc version.  Also note that this checkin removes the\\nPostgresqlDataSource and files in the xa directory.  A recent checkin has\\nadded new datasource support that replaces the functionality provided by these\\nclasses.\\n\\n Modified Files:\\n \\tjdbc/build.xml\\n \\tjdbc/org/postgresql/jdbc1/AbstractJdbc1DatabaseMetaData.java\\n \\tjdbc/org/postgresql/jdbc1/AbstractJdbc1ResultSet.java\\n \\tjdbc/org/postgresql/jdbc1/AbstractJdbc1ResultSetMetaData.java\\n \\tjdbc/org/postgresql/jdbc1/AbstractJdbc1Statement.java\\n \\tjdbc/org/postgresql/jdbc2/AbstractJdbc2Connection.java\\n \\tjdbc/org/postgresql/jdbc2/AbstractJdbc2DatabaseMetaData.java\\n \\tjdbc/org/postgresql/jdbc2/AbstractJdbc2ResultSet.java\\n \\tjdbc/org/postgresql/jdbc2/AbstractJdbc2ResultSetMetaData.java\\n \\tjdbc/org/postgresql/jdbc2/AbstractJdbc2Statement.java\\n \\tjdbc/org/postgresql/jdbc2/Array.java\\n \\tjdbc/org/postgresql/jdbc2/Jdbc2CallableStatement.java\\n \\tjdbc/org/postgresql/jdbc2/Jdbc2Connection.java\\n \\tjdbc/org/postgresql/jdbc2/Jdbc2DatabaseMetaData.java\\n \\tjdbc/org/postgresql/jdbc2/Jdbc2PreparedStatement.java\\n \\tjdbc/org/postgresql/jdbc2/Jdbc2ResultSet.java\\n \\tjdbc/org/postgresql/jdbc2/Jdbc2ResultSetMetaData.java\\n \\tjdbc/org/postgresql/jdbc2/Jdbc2Statement.java\\n \\tjdbc/org/postgresql/test/jdbc2/BatchExecuteTest.java\\n \\tjdbc/org/postgresql/test/jdbc2/BlobTest.java\\n \\tjdbc/org/postgresql/test/jdbc2/CallableStmtTest.java\\n \\tjdbc/org/postgresql/test/jdbc2/ConnectionTest.java\\n \\tjdbc/org/postgresql/test/jdbc2/DatabaseMetaDataTest.java\\n \\tjdbc/org/postgresql/test/jdbc2/DateTest.java\\n \\tjdbc/org/postgresql/test/jdbc2/DriverTest.java\\n \\tjdbc/org/postgresql/test/jdbc2/JBuilderTest.java\\n \\tjdbc/org/postgresql/test/jdbc2/MiscTest.java\\n \\tjdbc/org/postgresql/test/jdbc2/ResultSetTest.java\\n \\tjdbc/org/postgresql/test/jdbc2/TimeTest.java\\n \\tjdbc/org/postgresql/test/jdbc2/TimestampTest.java\\n \\tjdbc/org/postgresql/test/jdbc2/UpdateableResultTest.java\\n Added Files:\\n \\tjdbc/org/postgresql/jdbc2/AbstractJdbc2Blob.java\\n \\tjdbc/org/postgresql/jdbc2/AbstractJdbc2Clob.java\\n \\tjdbc/org/postgresql/jdbc2/Jdbc2Blob.java\\n \\tjdbc/org/postgresql/jdbc2/Jdbc2Clob.java\\n \\tjdbc/org/postgresql/jdbc3/AbstractJdbc3Blob.java\\n \\tjdbc/org/postgresql/jdbc3/AbstractJdbc3Clob.java\\n \\tjdbc/org/postgresql/jdbc3/AbstractJdbc3Connection.java\\n \\tjdbc/org/postgresql/jdbc3/AbstractJdbc3DatabaseMetaData.java\\n \\tjdbc/org/postgresql/jdbc3/AbstractJdbc3ResultSet.java\\n \\tjdbc/org/postgresql/jdbc3/AbstractJdbc3Statement.java\\n \\tjdbc/org/postgresql/jdbc3/Jdbc3Blob.java\\n \\tjdbc/org/postgresql/jdbc3/Jdbc3CallableStatement.java\\n \\tjdbc/org/postgresql/jdbc3/Jdbc3Clob.java\\n \\tjdbc/org/postgresql/jdbc3/Jdbc3Connection.java\\n \\tjdbc/org/postgresql/jdbc3/Jdbc3DatabaseMetaData.java\\n \\tjdbc/org/postgresql/jdbc3/Jdbc3PreparedStatement.java\\n \\tjdbc/org/postgresql/jdbc3/Jdbc3ResultSet.java\\n \\tjdbc/org/postgresql/jdbc3/Jdbc3ResultSetMetaData.java\\n \\tjdbc/org/postgresql/jdbc3/Jdbc3Statement.java\\n \\tjdbc/org/postgresql/test/TestUtil.java\\n \\tjdbc/org/postgresql/test/jdbc2/Jdbc2TestSuite.java\\n \\tjdbc/org/postgresql/test/jdbc3/Jdbc3TestSuite.java\\n Removed Files:\\n \\tjdbc/org/postgresql/PostgresqlDataSource.java\\n \\tjdbc/org/postgresql/largeobject/PGblob.java\\n \\tjdbc/org/postgresql/largeobject/PGclob.java\\n \\tjdbc/org/postgresql/test/JDBC2Tests.java\\n \\tjdbc/org/postgresql/xa/ClientConnection.java\\n \\tjdbc/org/postgresql/xa/TwoPhaseConnection.java\\n \\tjdbc/org/postgresql/xa/TxConnection.java\\n \\tjdbc/org/postgresql/xa/XAConnectionImpl.java\\n \\tjdbc/org/postgresql/xa/XADataSourceImpl.java\\n</td>\n",
       "      <td>functional</td>\n",
       "      <td>added support jdbc driver build jdbc ie java concludes changes restructured code support jdbc jdbc unit tests also resturctured allow different tests jdbc jdbc although currently make check aka ant test jdbc runs jdbc tests special note largeobjectpgblob pgclob classes moved jdbcjdbc specific directories differ jdbc version also note checkin removes postgresqldatasource files xa directory recent checkin added new datasource support replaces functionality provided classes modified files jdbcbuildxml jdbcorgpostgresqljdbcabstractjdbcdatabasemetadatajava jdbcorgpostgresqljdbcabstractjdbcresultsetjava jdbcorgpostgresqljdbcabstractjdbcresultsetmetadatajava jdbcorgpostgresqljdbcabstractjdbcstatementjava jdbcorgpostgresqljdbcabstractjdbcconnectionjava jdbcorgpostgresqljdbcabstractjdbcdatabasemetadatajava jdbcorgpostgresqljdbcabstractjdbcresultsetjava jdbcorgpostgresqljdbcabstractjdbcresultsetmetadatajava jdbcorgpostgresqljdbcabstractjdbcstatementjava jdbcorgpostgresqljdbcarrayjava jdbcorgpostgresqljdbcjdbccallablestatementjava jdbcorgpostgresqljdbcjdbcconnectionjava jdbcorgpostgresqljdbcjdbcdatabasemetadatajava jdbcorgpostgresqljdbcjdbcpreparedstatementjava jdbcorgpostgresqljdbcjdbcresultsetjava jdbcorgpostgresqljdbcjdbcresultsetmetadatajava jdbcorgpostgresqljdbcjdbcstatementjava jdbcorgpostgresqltestjdbcbatchexecutetestjava jdbcorgpostgresqltestjdbcblobtestjava jdbcorgpostgresqltestjdbccallablestmttestjava jdbcorgpostgresqltestjdbcconnectiontestjava jdbcorgpostgresqltestjdbcdatabasemetadatatestjava jdbcorgpostgresqltestjdbcdatetestjava jdbcorgpostgresqltestjdbcdrivertestjava jdbcorgpostgresqltestjdbcjbuildertestjava jdbcorgpostgresqltestjdbcmisctestjava jdbcorgpostgresqltestjdbcresultsettestjava jdbcorgpostgresqltestjdbctimetestjava jdbcorgpostgresqltestjdbctimestamptestjava jdbcorgpostgresqltestjdbcupdateableresulttestjava added files jdbcorgpostgresqljdbcabstractjdbcblobjava jdbcorgpostgresqljdbcabstractjdbcclobjava jdbcorgpostgresqljdbcjdbcblobjava jdbcorgpostgresqljdbcjdbcclobjava jdbcorgpostgresqljdbcabstractjdbcblobjava jdbcorgpostgresqljdbcabstractjdbcclobjava jdbcorgpostgresqljdbcabstractjdbcconnectionjava jdbcorgpostgresqljdbcabstractjdbcdatabasemetadatajava jdbcorgpostgresqljdbcabstractjdbcresultsetjava jdbcorgpostgresqljdbcabstractjdbcstatementjava jdbcorgpostgresqljdbcjdbcblobjava jdbcorgpostgresqljdbcjdbccallablestatementjava jdbcorgpostgresqljdbcjdbcclobjava jdbcorgpostgresqljdbcjdbcconnectionjava jdbcorgpostgresqljdbcjdbcdatabasemetadatajava jdbcorgpostgresqljdbcjdbcpreparedstatementjava jdbcorgpostgresqljdbcjdbcresultsetjava jdbcorgpostgresqljdbcjdbcresultsetmetadatajava jdbcorgpostgresqljdbcjdbcstatementjava jdbcorgpostgresqltesttestutiljava jdbcorgpostgresqltestjdbcjdbctestsuitejava jdbcorgpostgresqltestjdbcjdbctestsuitejava removed files jdbcorgpostgresqlpostgresqldatasourcejava jdbcorgpostgresqllargeobjectpgblobjava jdbcorgpostgresqllargeobjectpgclobjava jdbcorgpostgresqltestjdbctestsjava jdbcorgpostgresqlxaclientconnectionjava jdbcorgpostgresqlxatwophaseconnectionjava jdbcorgpostgresqlxatxconnectionjava jdbcorgpostgresqlxaxaconnectionimpljava jdbcorgpostgresqlxaxadatasourceimpljava</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>Merged revisions 391-416 via svnmerge from \\nhttps://svn.parabola.me.uk/svn/mkgmap/branches/filters\\n\\n........\\n  r391 | steve | 2007-12-01 17:22:34 +0000 (Sat, 01 Dec 2007) | 1 line\\n  \\n  Broke out the splitting of lines a little.\\n........\\n  r392 | steve | 2007-12-01 17:28:23 +0000 (Sat, 01 Dec 2007) | 1 line\\n  \\n  Remove the inline line splitting code.\\n........\\n  r393 | steve | 2007-12-01 20:29:03 +0000 (Sat, 01 Dec 2007) | 1 line\\n  \\n  Create filter infrastructure.\\n........\\n  r394 | steve | 2007-12-02 14:35:27 +0000 (Sun, 02 Dec 2007) | 2 lines\\n  \\n  A working implementation, although there is more to break out into filters and then we need to add some\\n  more functionality.\\n........\\n  r395 | steve | 2007-12-02 22:12:43 +0000 (Sun, 02 Dec 2007) | 1 line\\n  \\n  rename filter chain\\n........\\n  r396 | steve | 2007-12-02 22:13:25 +0000 (Sun, 02 Dec 2007) | 1 line\\n  \\n  rename line splitting filter\\n........\\n  r397 | steve | 2007-12-03 09:00:24 +0000 (Mon, 03 Dec 2007) | 1 line\\n  \\n  rename line splitting filter, add polygon splitter\\n........\\n  r398 | steve | 2007-12-03 10:28:16 +0000 (Mon, 03 Dec 2007) | 1 line\\n  \\n  Make sure that lines are always copied before changing their points as this would change them for all levels.\\n........\\n  r399 | steve | 2007-12-03 10:29:17 +0000 (Mon, 03 Dec 2007) | 1 line\\n  \\n  Add the copy constructors to the MapShape class too.\\n........\\n  r400 | steve | 2007-12-03 11:03:36 +0000 (Mon, 03 Dec 2007) | 1 line\\n  \\n  Add filtering for polygons and only add the line filter for lines and the polygon filters for polygons...\\n........\\n  r401 | steve | 2007-12-03 11:22:18 +0000 (Mon, 03 Dec 2007) | 1 line\\n  \\n  Some tidying\\n........\\n  r402 | steve | 2007-12-03 12:07:22 +0000 (Mon, 03 Dec 2007) | 1 line\\n  \\n  Split out files from the general package that do the actual general--&gt;garmin conversion.\\n........\\n  r405 | steve | 2007-12-03 17:23:48 +0000 (Mon, 03 Dec 2007) | 1 line\\n  \\n  Useful amount of smothing applied.\\n........\\n  r406 | steve | 2007-12-03 20:58:29 +0000 (Mon, 03 Dec 2007) | 1 line\\n  \\n  Fix where was not returning after chaining the filter.\\n........\\n  r407 | steve | 2007-12-03 20:59:07 +0000 (Mon, 03 Dec 2007) | 1 line\\n  \\n  Now we have a polygon splitter.  Polygons that have too many points will be split.\\n........\\n  r408 | steve | 2007-12-03 21:16:07 +0000 (Mon, 03 Dec 2007) | 2 lines\\n  \\n  Remove println's\\n........\\n  r409 | steve | 2007-12-03 21:23:57 +0000 (Mon, 03 Dec 2007) | 1 line\\n  \\n  Now that the smoothing is in a filter, remove the old code to remove duplicate points.\\n........\\n\\n\\ngit-svn-id: http://svn.mkgmap.org.uk/mkgmap/trunk@417 25d90789-57f7-4ee0-8453-03a3dfeeeb22\\n</td>\n",
       "      <td>bugfix</td>\n",
       "      <td>merged revisions via svnmerge r steve sat dec line broke splitting lines little r steve sat dec line remove inline line splitting code r steve sat dec line create filter infrastructure r steve sun dec lines working implementation although break filters need add functionality r steve sun dec line rename filter chain r steve sun dec line rename line splitting filter r steve mon dec line rename line splitting filter add polygon splitter r steve mon dec line make sure lines always copied changing points would change levels r steve mon dec line add copy constructors mapshape class r steve mon dec line add filtering polygons add line filter lines polygon filters polygons r steve mon dec line tidying r steve mon dec line split files general package actual generalgarmin conversion r steve mon dec line useful amount smothing applied r steve mon dec line fix returning chaining filter r steve mon dec line polygon splitter polygons many points split r steve mon dec lines remove printlns r steve mon dec line smoothing filter remove old code remove duplicate points gitsvnid dfeeadfeeeb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>- Added target for the nearest neighbor finder tool\\n- Reduced the default timeout for long-running tests\\n\\n- Added a jaccardIndex overload for two sets of elements\\n\\n- Fixed javadoc\\n\\n- Made class serializable\\n\\n- Added support for maximum path length\\n\\n- Reworked to use the new SimpleDependencyPath class\\n\\n- Revised error message for clarity\\n\\n- Updated to use new SimpleDependencyPath features\\n\\n- Updated to use new SimpleDependencyPath features\\n\\n- Major rewrite for clarity\\n\\n- Fixed toString()\\n\\n- Added static methods for testing the category of particular POS tag\\n\\n- Implemented missing methods\\n\\n- Added more imports (not sure why...)\\n\\n- Added logging\\n\\n- Added support for shuffling the edges of a graph using a fixed Random for reproducability\\n\\n- Multithreaded the edge similarity comparison\\n\\n- Probably some bug fixes too\\n\\n- Updated to use IntPair instead of Pair&lt;Integer&gt;\\n\\n- Updated to use IntSet\\n\\n- Major overhaul to bring performance in line with the earlier primitive\\n  collection enhancements\\n\\n- Probably needs a lot of clean up still\\n\\n- Updates to use new primitive collections\\n\\n- Updates to use new primitive collections\\n\\n- Added support for clustering to a fixed number of clusters\\n\\n- Added (limited) support for writing in GEXF format\\n\\n- Added (limited) support for writing in Pajek format\\n\\n- Made default output verbose\\n\\n- Remove extra temporary file that was just hanging around unneeded\\n\\n- Added support for getting the String that backs the document\\n\\n- Added a new class for testing the association between two terms, which is\\n  already partially supported by the BigramExtractor, but this class supports\\n  limiting the number of items being associated which enables better scaling\\n  through iterative association testing.\\n\\n- This class needs a lot of work.\\n\\n- Added an iterator for the documents in WaCkypedia\\n\\n- Fixed HTML bug in javadoc\\n\\n- Added new tool for running the NearestNeighborFinder from the command line\\n\\n- Fixed javadoc\\n\\n- Added support for changing the loging level of any logger namespace\\n\\n- Added new tool for speeding up repeated nearest-neighbor computations by\\n  partitioning a SemanticSpace into clusters (using K-means) and then only\\n  searching a subset.\\n\\n- Added support for reading and writing to streams and byte[] arrays\\n\\n- Updated to be an IntSet\\n\\n- Added Pair implementation\\n\\n- Fixed iterator remove bug\\n\\n- Added more extensive real-world unit tests\\n\\n- Added unit test details that match the example in the Ahn et al. paper\\n\\n- Added more tests\\n</td>\n",
       "      <td>bugfix</td>\n",
       "      <td>added target nearest neighbor finder tool reduced default timeout longrunning tests added jaccardindex overload two sets elements fixed javadoc made class serializable added support maximum path length reworked use new simpledependencypath class revised error message clarity updated use new simpledependencypath features updated use new simpledependencypath features major rewrite clarity fixed tostring added static methods testing category particular pos tag implemented missing methods added imports sure added logging added support shuffling edges graph using fixed random reproducability multithreaded edge similarity comparison probably bug fixes updated use intpair instead pairinteger updated use intset major overhaul bring performance line earlier primitive collection enhancements probably needs lot clean still updates use new primitive collections updates use new primitive collections added support clustering fixed number clusters added limited support writing gexf format added limited support writing pajek format made default output verbose remove extra temporary file hanging around unneeded added support getting string backs document added new class testing association two terms already partially supported bigramextractor class supports limiting number items associated enables better scaling iterative association testing class needs lot work added iterator documents wackypedia fixed html bug javadoc added new tool running nearestneighborfinder command line fixed javadoc added support changing loging level logger namespace added new tool speeding repeated nearestneighbor computations partitioning semanticspace clusters using kmeans searching subset added support reading writing streams byte arrays updated intset added pair implementation fixed iterator remove bug added extensive realworld unit tests added unit test details match example ahn et al paper added tests</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             commit_message  \\\n",
       "400  Changes based on Keith's review.  A few tweaks to EdgeSet to help tracking edge\\nremoval\\n\\n\\tmodified:   src/edu/ucla/sspace/common/Similarity.java\\n\\n- Updated to use VectorMath.dotProduct for the Tanimoto coefficient\\n\\n\\tdeleted:    src/edu/ucla/sspace/common/WordComparator.java\\n\\n- Moved to SimpleNearestNeighborFinder\\n\\n\\tmodified:   src/edu/ucla/sspace/dependency/SimpleDependencyPath.java\\n\\n- Removed println\\n\\n\\tmodified:   src/edu/ucla/sspace/graph/AbstractGraph.java\\n\\n- Added missing implementation to Subgraph class so now all the unit tests pass\\n\\n\\tmodified:   src/edu/ucla/sspace/graph/DirectedMultigraph.java\\n\\n- Added missing implementation to Subgraph class so now all the unit tests pass\\n\\n- Fixed bug for reporting the correct edge types after removal\\n\\n- Removed dead code\\n\\n\\tmodified:   src/edu/ucla/sspace/graph/EdgeSet.java\\n\\n- Updated so that disconnect() now returns the number of edges that were removed\\n\\n\\tmodified:   src/edu/ucla/sspace/graph/GenericEdgeSet.java\\n\\tmodified:   src/edu/ucla/sspace/graph/SparseDirectedEdgeSet.java\\n\\tmodified:   src/edu/ucla/sspace/graph/SparseDirectedTypedEdgeSet.java\\n\\tmodified:   src/edu/ucla/sspace/graph/SparseTypedEdgeSet.java\\n\\tmodified:   src/edu/ucla/sspace/graph/SparseUndirectedEdgeSet.java\\n\\tmodified:   src/edu/ucla/sspace/graph/SparseWeightedEdgeSet.java\\n\\n- Updated to support EdgeSet interface change\\n\\n\\tdeleted:    src/edu/ucla/sspace/graph/GraphRandomizer.java\\n\\n- Removed dead class (functionality is in Graphs.java)\\n\\n\\tmodified:   src/edu/ucla/sspace/graph/SimpleWeightedEdge.java\\n\\n- Fixed hashCode()\\n\\n\\tdeleted:    src/edu/ucla/sspace/graph/SparseSymmetricEdgeSet.java\\n\\n- Removed dead class\\n\\n\\tmodified:   src/edu/ucla/sspace/graph/UndirectedMultigraph.java\\n\\n- Added missing implementation to Subgraph class so now all the unit tests pass\\n\\n- Fixed bug for reporting the correct edge types after removal\\n\\n- Removed dead code\\n\\n\\tmodified:   src/edu/ucla/sspace/mains/FixedDurationTemporalRandomIndexingMain.java\\n\\n- Updated to replace WordComparator with SimpleNearestNeighborFinder\\n\\n\\tmodified:   src/edu/ucla/sspace/mains/LexSubWordsiMain.java\\n\\n- Updated to replace WordComparator with SimpleNearestNeighborFinder\\n\\n\\tmodified:   src/edu/ucla/sspace/text/LabeledParsedStringDocument.java\\n\\n- Updated for new ParsedDocument interface\\n\\n\\tmodified:   src/edu/ucla/sspace/text/ParsedDocument.java\\n\\n- Updated to specify the format of text() as the tokens with white space delimiters.\\n\\n- Added a new prettyPrintText() which is the attempt to nicely format the tokens\\n  as they would have been originally.\\n\\n\\tmodified:   src/edu/ucla/sspace/text/PukWaCDocumentIterator.java\\n\\n- Fixed javadoc\\n\\n\\tmodified:   src/edu/ucla/sspace/text/UkWaCDocumentIterator.java\\n\\n- Added more class javadoc\\n\\n\\tmodified:   src/edu/ucla/sspace/tools/NearestNeighborFinderTool.java\\n\\n- Updated to use the class instances instead of the interface\\n\\n\\tmodified:   src/edu/ucla/sspace/tools/SemanticSpaceExplorer.java\\n\\n- Updated to replace WordComparator with PartitioningNearestNeighborFinder\\n\\n\\tmodified:   src/edu/ucla/sspace/tools/SimilarityListGenerator.java\\n\\n- Updated to replace WordComparator with PartitioningNearestNeighborFinder\\n\\n\\tmodified:   src/edu/ucla/sspace/util/HashIndexer.java\\n\\n- Fixed javadoc\\n\\n\\tmodified:   src/edu/ucla/sspace/util/PairCounter.java\\n\\n- Fixed javadoc\\n\\n\\trenamed:    src/edu/ucla/sspace/util/NearestNeighborFinder.java -> src/edu/ucla/sspace/util/PartitioningNearestNeighborFinder.java\\n\\n- Moved so that NearestNeighborFinder can be an interface\\n\\n\\tmodified:   src/edu/ucla/sspace/util/ReflectionUtil.java\\n\\n- Removed dead code\\n\\n\\tmodified:   src/edu/ucla/sspace/util/primitive/IntIntHashMultiMap.java\\n\\n- Added javadoc\\n\\n\\tmodified:   src/edu/ucla/sspace/util/primitive/IntIntMultiMap.java\\n\\n- Added javadoc\\n\\n\\tmodified:   test/edu/ucla/sspace/graph/DirectedMultigraphTests.java\\n\\n- Uncommented out unit tests\\n\\n\\tmodified:   test/edu/ucla/sspace/dependency/BreadthFirstPathIteratorTest.java\\n\\tmodified:   test/edu/ucla/sspace/dependency/CoNLLDependencyExtractorTest.java\\n\\tmodified:   test/edu/ucla/sspace/dependency/WaCKyDependencyExtractorTest.java\\n\\tmodified:   test/edu/ucla/sspace/text/corpora/PukWacDependencyCorpusReaderTest.java\\n\\tmodified:   test/edu/ucla/sspace/wordsi/DependencyContextExtractorTest.java\\n\\tmodified:   test/edu/ucla/sspace/wordsi/OccurrenceDependencyContextGeneratorTest.java\\n\\tmodified:   test/edu/ucla/sspace/wordsi/OrderingDependencyContextGeneratorTest.java\\n\\tmodified:   test/edu/ucla/sspace/wordsi/PartOfSpeechDependencyContextGeneratorTest.java\\n\\tmodified:   test/edu/ucla/sspace/wordsi/psd/PseudoWordDependencyContextExtractorTest.java\\n\\tmodified:   test/edu/ucla/sspace/wordsi/semeval/SemEvalDependencyContextExtractorTest.java\\n\\n- Fixed unit tests to support proper tab-delimiting of the CoNLL format\\n   \n",
       "833                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Lots and lots of bug fixes with a few minor functionality enhancements.\\n\\n\\tmodified:   src/main/java/edu/ucla/sspace/common/Similarity.java\\n\\n- Added warnings for invalid KL-divergence computations\\n\\n- Added Kruskal-Goodman Gamma\\n\\n- Discovered Spearman's rho and Kendall's tau are both wrong (not fixed)  :(\\n\\n\\tmodified:   src/main/java/edu/ucla/sspace/common/statistics/LogLikelihoodTest.java\\n\\n- Fixed implementation\\n\\n\\tnew file:   src/main/java/edu/ucla/sspace/graph/ChineseWhispersClustering.java\\n\\n- Added CW clustering, but it doesn't appear to produce the same results as the\\n  existing code (needs investigation)\\n\\n\\tmodified:   src/main/java/edu/ucla/sspace/graph/GraphIO.java\\n\\n- Tweaked logging\\n\\n\\tmodified:   src/main/java/edu/ucla/sspace/graph/LinkClustering.java\\n\\n- Made thread count based on processors instead of fixed\\n\\n\\tnew file:   src/main/java/edu/ucla/sspace/graph/SimpleWeightedDirectedTypedEdge.java\\n\\tnew file:   src/main/java/edu/ucla/sspace/graph/SimpleWeightedTypedEdge.java\\n\\tnew file:   src/main/java/edu/ucla/sspace/graph/SparseWeightedDirectedEdgeSet.java\\n\\tnew file:   src/main/java/edu/ucla/sspace/graph/SparseWeightedDirectedTypedEdgeSet.java\\n\\tnew file:   src/main/java/edu/ucla/sspace/graph/WeightedDirectedMultigraph.java\\n\\tmodified:   src/main/java/edu/ucla/sspace/graph/WeightedDirectedTypedEdge.java\\n\\n- Added partial support for weighted multigraphs.  More features are probably needed eventually\\n\\n\\tmodified:   src/main/java/edu/ucla/sspace/graph/io/EdgeListReader.java\\n\\n- Added better logging instead of printf\\n\\n\\tnew file:   src/main/java/edu/ucla/sspace/graph/io/GraphMLReader.java\\n\\n- Added initial GraphML implementation for reading large GraphML files.  Only partial support is in place\\n\\n\\tmodified:   src/main/java/edu/ucla/sspace/index/DefaultPermutationFunction.java\\n\\n- Fixed outstanding bug.  Not sure how the bug was there in the first place, as\\n  the code was currently very broken in an odd way.\\n\\n\\tnew file:   src/main/java/edu/ucla/sspace/text/AnnotatedDocument.java\\n\\n- Added support for a new document that has a creation date and a label\\n\\n\\tnew file:   src/main/java/edu/ucla/sspace/text/BufferedFileListDocumentIterator.java\\n\\n- Added a new iterator that pre-caches the contents of files in a file list\\n  using a separate thread to cut down on disk I/O\\n\\n\\tmodified:   src/main/java/edu/ucla/sspace/text/FileDocument.java\\n\\n- Added support for a document back by a file whose contents are loaded into memory on demand\\n\\n\\tnew file:   src/main/java/edu/ucla/sspace/tools/IterativeBigramExtractor.java\\n\\n- Added a tool for finding statistical associations between terms in an\\n  iterative pair-wise manner\\n\\n\\tnew file:   src/main/java/edu/ucla/sspace/tools/LinkClusteringTool.java\\n\\n- Copied over code from the SVN branch for running link clustering from a jar\\n\\n\\tmodified:   src/main/java/edu/ucla/sspace/util/CombinedIterator.java\\n\\n- Corrected the Exception to be thrown in remove()\\n\\n\\tmodified:   src/main/java/edu/ucla/sspace/util/HashMultiMap.java\\n\\n- Correct a few errors in removing keys during iterator\\n\\n- Fixed a bug where null was returned instead of the empty set\\n\\n\\tnew file:   src/main/java/edu/ucla/sspace/util/KrippendorffsAlpha.java\\n\\n- Added a partial implementation of Krippendorff's alpha for ordinal-valued data\\n\\n\\tmodified:   src/main/java/edu/ucla/sspace/util/MultiMap.java\\n\\n- Clarified the javadoc\\n\\n\\tmodified:   src/main/java/edu/ucla/sspace/util/ObjectCounter.java\\n\\n- Implemented max() and min()\\n\\n\\tmodified:   src/main/java/edu/ucla/sspace/util/Pair.java\\n\\n- Made Serializable\\n\\n\\tmodified:   src/main/java/edu/ucla/sspace/util/SetDecorator.java\\n\\n- Clarified javadoc\\n\\n\\tnew file:   src/test/java/edu/ucla/sspace/graph/ChineseWhispersTest.java\\n\\tnew file:   src/test/java/edu/ucla/sspace/graph/SparseWeightedDirectedTypedEdgeSetTest.java\\n\\tnew file:   src/test/java/edu/ucla/sspace/graph/WeightedDirectedMultigraphTest.java\\n\\n- More unit tests\\n\\n\\tmodified:   src/test/java/edu/ucla/sspace/index/DefaultPermutationFunctionTest.java\\n\\n- Added some debugging output\\n   \n",
       "243                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Added support for JDBC3.  The driver will now build under JDBC3 (i.e. Java 1.4).\\nThis concludes my changes that restructured the code to support JDBC3.\\nThe jdbc unit tests were also resturctured to allow different tests between\\njdbc2 and jdbc3, although currently make check (aka ant test) for JDBC3 just\\nruns the JDBC2 tests.  Of special note the largeobject/PGblob and PGclob\\nclasses have been moved under the jdbc2/jdbc3 specific directories as they\\nnow differ by jdbc version.  Also note that this checkin removes the\\nPostgresqlDataSource and files in the xa directory.  A recent checkin has\\nadded new datasource support that replaces the functionality provided by these\\nclasses.\\n\\n Modified Files:\\n \\tjdbc/build.xml\\n \\tjdbc/org/postgresql/jdbc1/AbstractJdbc1DatabaseMetaData.java\\n \\tjdbc/org/postgresql/jdbc1/AbstractJdbc1ResultSet.java\\n \\tjdbc/org/postgresql/jdbc1/AbstractJdbc1ResultSetMetaData.java\\n \\tjdbc/org/postgresql/jdbc1/AbstractJdbc1Statement.java\\n \\tjdbc/org/postgresql/jdbc2/AbstractJdbc2Connection.java\\n \\tjdbc/org/postgresql/jdbc2/AbstractJdbc2DatabaseMetaData.java\\n \\tjdbc/org/postgresql/jdbc2/AbstractJdbc2ResultSet.java\\n \\tjdbc/org/postgresql/jdbc2/AbstractJdbc2ResultSetMetaData.java\\n \\tjdbc/org/postgresql/jdbc2/AbstractJdbc2Statement.java\\n \\tjdbc/org/postgresql/jdbc2/Array.java\\n \\tjdbc/org/postgresql/jdbc2/Jdbc2CallableStatement.java\\n \\tjdbc/org/postgresql/jdbc2/Jdbc2Connection.java\\n \\tjdbc/org/postgresql/jdbc2/Jdbc2DatabaseMetaData.java\\n \\tjdbc/org/postgresql/jdbc2/Jdbc2PreparedStatement.java\\n \\tjdbc/org/postgresql/jdbc2/Jdbc2ResultSet.java\\n \\tjdbc/org/postgresql/jdbc2/Jdbc2ResultSetMetaData.java\\n \\tjdbc/org/postgresql/jdbc2/Jdbc2Statement.java\\n \\tjdbc/org/postgresql/test/jdbc2/BatchExecuteTest.java\\n \\tjdbc/org/postgresql/test/jdbc2/BlobTest.java\\n \\tjdbc/org/postgresql/test/jdbc2/CallableStmtTest.java\\n \\tjdbc/org/postgresql/test/jdbc2/ConnectionTest.java\\n \\tjdbc/org/postgresql/test/jdbc2/DatabaseMetaDataTest.java\\n \\tjdbc/org/postgresql/test/jdbc2/DateTest.java\\n \\tjdbc/org/postgresql/test/jdbc2/DriverTest.java\\n \\tjdbc/org/postgresql/test/jdbc2/JBuilderTest.java\\n \\tjdbc/org/postgresql/test/jdbc2/MiscTest.java\\n \\tjdbc/org/postgresql/test/jdbc2/ResultSetTest.java\\n \\tjdbc/org/postgresql/test/jdbc2/TimeTest.java\\n \\tjdbc/org/postgresql/test/jdbc2/TimestampTest.java\\n \\tjdbc/org/postgresql/test/jdbc2/UpdateableResultTest.java\\n Added Files:\\n \\tjdbc/org/postgresql/jdbc2/AbstractJdbc2Blob.java\\n \\tjdbc/org/postgresql/jdbc2/AbstractJdbc2Clob.java\\n \\tjdbc/org/postgresql/jdbc2/Jdbc2Blob.java\\n \\tjdbc/org/postgresql/jdbc2/Jdbc2Clob.java\\n \\tjdbc/org/postgresql/jdbc3/AbstractJdbc3Blob.java\\n \\tjdbc/org/postgresql/jdbc3/AbstractJdbc3Clob.java\\n \\tjdbc/org/postgresql/jdbc3/AbstractJdbc3Connection.java\\n \\tjdbc/org/postgresql/jdbc3/AbstractJdbc3DatabaseMetaData.java\\n \\tjdbc/org/postgresql/jdbc3/AbstractJdbc3ResultSet.java\\n \\tjdbc/org/postgresql/jdbc3/AbstractJdbc3Statement.java\\n \\tjdbc/org/postgresql/jdbc3/Jdbc3Blob.java\\n \\tjdbc/org/postgresql/jdbc3/Jdbc3CallableStatement.java\\n \\tjdbc/org/postgresql/jdbc3/Jdbc3Clob.java\\n \\tjdbc/org/postgresql/jdbc3/Jdbc3Connection.java\\n \\tjdbc/org/postgresql/jdbc3/Jdbc3DatabaseMetaData.java\\n \\tjdbc/org/postgresql/jdbc3/Jdbc3PreparedStatement.java\\n \\tjdbc/org/postgresql/jdbc3/Jdbc3ResultSet.java\\n \\tjdbc/org/postgresql/jdbc3/Jdbc3ResultSetMetaData.java\\n \\tjdbc/org/postgresql/jdbc3/Jdbc3Statement.java\\n \\tjdbc/org/postgresql/test/TestUtil.java\\n \\tjdbc/org/postgresql/test/jdbc2/Jdbc2TestSuite.java\\n \\tjdbc/org/postgresql/test/jdbc3/Jdbc3TestSuite.java\\n Removed Files:\\n \\tjdbc/org/postgresql/PostgresqlDataSource.java\\n \\tjdbc/org/postgresql/largeobject/PGblob.java\\n \\tjdbc/org/postgresql/largeobject/PGclob.java\\n \\tjdbc/org/postgresql/test/JDBC2Tests.java\\n \\tjdbc/org/postgresql/xa/ClientConnection.java\\n \\tjdbc/org/postgresql/xa/TwoPhaseConnection.java\\n \\tjdbc/org/postgresql/xa/TxConnection.java\\n \\tjdbc/org/postgresql/xa/XAConnectionImpl.java\\n \\tjdbc/org/postgresql/xa/XADataSourceImpl.java\\n   \n",
       "878                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Merged revisions 391-416 via svnmerge from \\nhttps://svn.parabola.me.uk/svn/mkgmap/branches/filters\\n\\n........\\n  r391 | steve | 2007-12-01 17:22:34 +0000 (Sat, 01 Dec 2007) | 1 line\\n  \\n  Broke out the splitting of lines a little.\\n........\\n  r392 | steve | 2007-12-01 17:28:23 +0000 (Sat, 01 Dec 2007) | 1 line\\n  \\n  Remove the inline line splitting code.\\n........\\n  r393 | steve | 2007-12-01 20:29:03 +0000 (Sat, 01 Dec 2007) | 1 line\\n  \\n  Create filter infrastructure.\\n........\\n  r394 | steve | 2007-12-02 14:35:27 +0000 (Sun, 02 Dec 2007) | 2 lines\\n  \\n  A working implementation, although there is more to break out into filters and then we need to add some\\n  more functionality.\\n........\\n  r395 | steve | 2007-12-02 22:12:43 +0000 (Sun, 02 Dec 2007) | 1 line\\n  \\n  rename filter chain\\n........\\n  r396 | steve | 2007-12-02 22:13:25 +0000 (Sun, 02 Dec 2007) | 1 line\\n  \\n  rename line splitting filter\\n........\\n  r397 | steve | 2007-12-03 09:00:24 +0000 (Mon, 03 Dec 2007) | 1 line\\n  \\n  rename line splitting filter, add polygon splitter\\n........\\n  r398 | steve | 2007-12-03 10:28:16 +0000 (Mon, 03 Dec 2007) | 1 line\\n  \\n  Make sure that lines are always copied before changing their points as this would change them for all levels.\\n........\\n  r399 | steve | 2007-12-03 10:29:17 +0000 (Mon, 03 Dec 2007) | 1 line\\n  \\n  Add the copy constructors to the MapShape class too.\\n........\\n  r400 | steve | 2007-12-03 11:03:36 +0000 (Mon, 03 Dec 2007) | 1 line\\n  \\n  Add filtering for polygons and only add the line filter for lines and the polygon filters for polygons...\\n........\\n  r401 | steve | 2007-12-03 11:22:18 +0000 (Mon, 03 Dec 2007) | 1 line\\n  \\n  Some tidying\\n........\\n  r402 | steve | 2007-12-03 12:07:22 +0000 (Mon, 03 Dec 2007) | 1 line\\n  \\n  Split out files from the general package that do the actual general-->garmin conversion.\\n........\\n  r405 | steve | 2007-12-03 17:23:48 +0000 (Mon, 03 Dec 2007) | 1 line\\n  \\n  Useful amount of smothing applied.\\n........\\n  r406 | steve | 2007-12-03 20:58:29 +0000 (Mon, 03 Dec 2007) | 1 line\\n  \\n  Fix where was not returning after chaining the filter.\\n........\\n  r407 | steve | 2007-12-03 20:59:07 +0000 (Mon, 03 Dec 2007) | 1 line\\n  \\n  Now we have a polygon splitter.  Polygons that have too many points will be split.\\n........\\n  r408 | steve | 2007-12-03 21:16:07 +0000 (Mon, 03 Dec 2007) | 2 lines\\n  \\n  Remove println's\\n........\\n  r409 | steve | 2007-12-03 21:23:57 +0000 (Mon, 03 Dec 2007) | 1 line\\n  \\n  Now that the smoothing is in a filter, remove the old code to remove duplicate points.\\n........\\n\\n\\ngit-svn-id: http://svn.mkgmap.org.uk/mkgmap/trunk@417 25d90789-57f7-4ee0-8453-03a3dfeeeb22\\n   \n",
       "50                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 - Added target for the nearest neighbor finder tool\\n- Reduced the default timeout for long-running tests\\n\\n- Added a jaccardIndex overload for two sets of elements\\n\\n- Fixed javadoc\\n\\n- Made class serializable\\n\\n- Added support for maximum path length\\n\\n- Reworked to use the new SimpleDependencyPath class\\n\\n- Revised error message for clarity\\n\\n- Updated to use new SimpleDependencyPath features\\n\\n- Updated to use new SimpleDependencyPath features\\n\\n- Major rewrite for clarity\\n\\n- Fixed toString()\\n\\n- Added static methods for testing the category of particular POS tag\\n\\n- Implemented missing methods\\n\\n- Added more imports (not sure why...)\\n\\n- Added logging\\n\\n- Added support for shuffling the edges of a graph using a fixed Random for reproducability\\n\\n- Multithreaded the edge similarity comparison\\n\\n- Probably some bug fixes too\\n\\n- Updated to use IntPair instead of Pair<Integer>\\n\\n- Updated to use IntSet\\n\\n- Major overhaul to bring performance in line with the earlier primitive\\n  collection enhancements\\n\\n- Probably needs a lot of clean up still\\n\\n- Updates to use new primitive collections\\n\\n- Updates to use new primitive collections\\n\\n- Added support for clustering to a fixed number of clusters\\n\\n- Added (limited) support for writing in GEXF format\\n\\n- Added (limited) support for writing in Pajek format\\n\\n- Made default output verbose\\n\\n- Remove extra temporary file that was just hanging around unneeded\\n\\n- Added support for getting the String that backs the document\\n\\n- Added a new class for testing the association between two terms, which is\\n  already partially supported by the BigramExtractor, but this class supports\\n  limiting the number of items being associated which enables better scaling\\n  through iterative association testing.\\n\\n- This class needs a lot of work.\\n\\n- Added an iterator for the documents in WaCkypedia\\n\\n- Fixed HTML bug in javadoc\\n\\n- Added new tool for running the NearestNeighborFinder from the command line\\n\\n- Fixed javadoc\\n\\n- Added support for changing the loging level of any logger namespace\\n\\n- Added new tool for speeding up repeated nearest-neighbor computations by\\n  partitioning a SemanticSpace into clusters (using K-means) and then only\\n  searching a subset.\\n\\n- Added support for reading and writing to streams and byte[] arrays\\n\\n- Updated to be an IntSet\\n\\n- Added Pair implementation\\n\\n- Fixed iterator remove bug\\n\\n- Added more extensive real-world unit tests\\n\\n- Added unit test details that match the example in the Ahn et al. paper\\n\\n- Added more tests\\n   \n",
       "\n",
       "       category  \\\n",
       "400      bugfix   \n",
       "833      bugfix   \n",
       "243  functional   \n",
       "878      bugfix   \n",
       "50       bugfix   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              commit_message_clean  \n",
       "400  changes based keiths review tweaks edgeset help tracking edge removal modified srceduuclasspacecommonsimilarityjava updated use vectormathdotproduct tanimoto coefficient deleted srceduuclasspacecommonwordcomparatorjava moved simplenearestneighborfinder modified srceduuclasspacedependencysimpledependencypathjava removed println modified srceduuclasspacegraphabstractgraphjava added missing implementation subgraph class unit tests pass modified srceduuclasspacegraphdirectedmultigraphjava added missing implementation subgraph class unit tests pass fixed bug reporting correct edge types removal removed dead code modified srceduuclasspacegraphedgesetjava updated disconnect returns number edges removed modified srceduuclasspacegraphgenericedgesetjava modified srceduuclasspacegraphsparsedirectededgesetjava modified srceduuclasspacegraphsparsedirectedtypededgesetjava modified srceduuclasspacegraphsparsetypededgesetjava modified srceduuclasspacegraphsparseundirectededgesetjava modified srceduuclasspacegraphsparseweightededgesetjava updated support edgeset interface change deleted srceduuclasspacegraphgraphrandomizerjava removed dead class functionality graphsjava modified srceduuclasspacegraphsimpleweightededgejava fixed hashcode deleted srceduuclasspacegraphsparsesymmetricedgesetjava removed dead class modified srceduuclasspacegraphundirectedmultigraphjava added missing implementation subgraph class unit tests pass fixed bug reporting correct edge types removal removed dead code modified srceduuclasspacemainsfixeddurationtemporalrandomindexingmainjava updated replace wordcomparator simplenearestneighborfinder modified srceduuclasspacemainslexsubwordsimainjava updated replace wordcomparator simplenearestneighborfinder modified srceduuclasspacetextlabeledparsedstringdocumentjava updated new parseddocument interface modified srceduuclasspacetextparseddocumentjava updated specify format text tokens white space delimiters added new prettyprinttext attempt nicely format tokens would originally modified srceduuclasspacetextpukwacdocumentiteratorjava fixed javadoc modified srceduuclasspacetextukwacdocumentiteratorjava added class javadoc modified srceduuclasspacetoolsnearestneighborfindertooljava updated use class instances instead interface modified srceduuclasspacetoolssemanticspaceexplorerjava updated replace wordcomparator partitioningnearestneighborfinder modified srceduuclasspacetoolssimilaritylistgeneratorjava updated replace wordcomparator partitioningnearestneighborfinder modified srceduuclasspaceutilhashindexerjava fixed javadoc modified srceduuclasspaceutilpaircounterjava fixed javadoc renamed srceduuclasspaceutilnearestneighborfinderjava srceduuclasspaceutilpartitioningnearestneighborfinderjava moved nearestneighborfinder interface modified srceduuclasspaceutilreflectionutiljava removed dead code modified srceduuclasspaceutilprimitiveintinthashmultimapjava added javadoc modified srceduuclasspaceutilprimitiveintintmultimapjava added javadoc modified testeduuclasspacegraphdirectedmultigraphtestsjava uncommented unit tests modified testeduuclasspacedependencybreadthfirstpathiteratortestjava modified testeduuclasspacedependencyconlldependencyextractortestjava modified testeduuclasspacedependencywackydependencyextractortestjava modified testeduuclasspacetextcorporapukwacdependencycorpusreadertestjava modified testeduuclasspacewordsidependencycontextextractortestjava modified testeduuclasspacewordsioccurrencedependencycontextgeneratortestjava modified testeduuclasspacewordsiorderingdependencycontextgeneratortestjava modified testeduuclasspacewordsipartofspeechdependencycontextgeneratortestjava modified testeduuclasspacewordsipsdpseudoworddependencycontextextractortestjava modified testeduuclasspacewordsisemevalsemevaldependencycontextextractortestjava fixed unit tests support proper tabdelimiting conll format  \n",
       "833                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     lots lots bug fixes minor functionality enhancements modified srcmainjavaeduuclasspacecommonsimilarityjava added warnings invalid kldivergence computations added kruskalgoodman gamma discovered spearmans rho kendalls tau wrong fixed modified srcmainjavaeduuclasspacecommonstatisticsloglikelihoodtestjava fixed implementation new file srcmainjavaeduuclasspacegraphchinesewhispersclusteringjava added cw clustering appear produce results existing code needs investigation modified srcmainjavaeduuclasspacegraphgraphiojava tweaked logging modified srcmainjavaeduuclasspacegraphlinkclusteringjava made thread count based processors instead fixed new file srcmainjavaeduuclasspacegraphsimpleweighteddirectedtypededgejava new file srcmainjavaeduuclasspacegraphsimpleweightedtypededgejava new file srcmainjavaeduuclasspacegraphsparseweighteddirectededgesetjava new file srcmainjavaeduuclasspacegraphsparseweighteddirectedtypededgesetjava new file srcmainjavaeduuclasspacegraphweighteddirectedmultigraphjava modified srcmainjavaeduuclasspacegraphweighteddirectedtypededgejava added partial support weighted multigraphs features probably needed eventually modified srcmainjavaeduuclasspacegraphioedgelistreaderjava added better logging instead printf new file srcmainjavaeduuclasspacegraphiographmlreaderjava added initial graphml implementation reading large graphml files partial support place modified srcmainjavaeduuclasspaceindexdefaultpermutationfunctionjava fixed outstanding bug sure bug first place code currently broken odd way new file srcmainjavaeduuclasspacetextannotateddocumentjava added support new document creation date label new file srcmainjavaeduuclasspacetextbufferedfilelistdocumentiteratorjava added new iterator precaches contents files file list using separate thread cut disk io modified srcmainjavaeduuclasspacetextfiledocumentjava added support document back file whose contents loaded memory demand new file srcmainjavaeduuclasspacetoolsiterativebigramextractorjava added tool finding statistical associations terms iterative pairwise manner new file srcmainjavaeduuclasspacetoolslinkclusteringtooljava copied code svn branch running link clustering jar modified srcmainjavaeduuclasspaceutilcombinediteratorjava corrected exception thrown remove modified srcmainjavaeduuclasspaceutilhashmultimapjava correct errors removing keys iterator fixed bug null returned instead empty set new file srcmainjavaeduuclasspaceutilkrippendorffsalphajava added partial implementation krippendorffs alpha ordinalvalued data modified srcmainjavaeduuclasspaceutilmultimapjava clarified javadoc modified srcmainjavaeduuclasspaceutilobjectcounterjava implemented max min modified srcmainjavaeduuclasspaceutilpairjava made serializable modified srcmainjavaeduuclasspaceutilsetdecoratorjava clarified javadoc new file srctestjavaeduuclasspacegraphchinesewhisperstestjava new file srctestjavaeduuclasspacegraphsparseweighteddirectedtypededgesettestjava new file srctestjavaeduuclasspacegraphweighteddirectedmultigraphtestjava unit tests modified srctestjavaeduuclasspaceindexdefaultpermutationfunctiontestjava added debugging output  \n",
       "243                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              added support jdbc driver build jdbc ie java concludes changes restructured code support jdbc jdbc unit tests also resturctured allow different tests jdbc jdbc although currently make check aka ant test jdbc runs jdbc tests special note largeobjectpgblob pgclob classes moved jdbcjdbc specific directories differ jdbc version also note checkin removes postgresqldatasource files xa directory recent checkin added new datasource support replaces functionality provided classes modified files jdbcbuildxml jdbcorgpostgresqljdbcabstractjdbcdatabasemetadatajava jdbcorgpostgresqljdbcabstractjdbcresultsetjava jdbcorgpostgresqljdbcabstractjdbcresultsetmetadatajava jdbcorgpostgresqljdbcabstractjdbcstatementjava jdbcorgpostgresqljdbcabstractjdbcconnectionjava jdbcorgpostgresqljdbcabstractjdbcdatabasemetadatajava jdbcorgpostgresqljdbcabstractjdbcresultsetjava jdbcorgpostgresqljdbcabstractjdbcresultsetmetadatajava jdbcorgpostgresqljdbcabstractjdbcstatementjava jdbcorgpostgresqljdbcarrayjava jdbcorgpostgresqljdbcjdbccallablestatementjava jdbcorgpostgresqljdbcjdbcconnectionjava jdbcorgpostgresqljdbcjdbcdatabasemetadatajava jdbcorgpostgresqljdbcjdbcpreparedstatementjava jdbcorgpostgresqljdbcjdbcresultsetjava jdbcorgpostgresqljdbcjdbcresultsetmetadatajava jdbcorgpostgresqljdbcjdbcstatementjava jdbcorgpostgresqltestjdbcbatchexecutetestjava jdbcorgpostgresqltestjdbcblobtestjava jdbcorgpostgresqltestjdbccallablestmttestjava jdbcorgpostgresqltestjdbcconnectiontestjava jdbcorgpostgresqltestjdbcdatabasemetadatatestjava jdbcorgpostgresqltestjdbcdatetestjava jdbcorgpostgresqltestjdbcdrivertestjava jdbcorgpostgresqltestjdbcjbuildertestjava jdbcorgpostgresqltestjdbcmisctestjava jdbcorgpostgresqltestjdbcresultsettestjava jdbcorgpostgresqltestjdbctimetestjava jdbcorgpostgresqltestjdbctimestamptestjava jdbcorgpostgresqltestjdbcupdateableresulttestjava added files jdbcorgpostgresqljdbcabstractjdbcblobjava jdbcorgpostgresqljdbcabstractjdbcclobjava jdbcorgpostgresqljdbcjdbcblobjava jdbcorgpostgresqljdbcjdbcclobjava jdbcorgpostgresqljdbcabstractjdbcblobjava jdbcorgpostgresqljdbcabstractjdbcclobjava jdbcorgpostgresqljdbcabstractjdbcconnectionjava jdbcorgpostgresqljdbcabstractjdbcdatabasemetadatajava jdbcorgpostgresqljdbcabstractjdbcresultsetjava jdbcorgpostgresqljdbcabstractjdbcstatementjava jdbcorgpostgresqljdbcjdbcblobjava jdbcorgpostgresqljdbcjdbccallablestatementjava jdbcorgpostgresqljdbcjdbcclobjava jdbcorgpostgresqljdbcjdbcconnectionjava jdbcorgpostgresqljdbcjdbcdatabasemetadatajava jdbcorgpostgresqljdbcjdbcpreparedstatementjava jdbcorgpostgresqljdbcjdbcresultsetjava jdbcorgpostgresqljdbcjdbcresultsetmetadatajava jdbcorgpostgresqljdbcjdbcstatementjava jdbcorgpostgresqltesttestutiljava jdbcorgpostgresqltestjdbcjdbctestsuitejava jdbcorgpostgresqltestjdbcjdbctestsuitejava removed files jdbcorgpostgresqlpostgresqldatasourcejava jdbcorgpostgresqllargeobjectpgblobjava jdbcorgpostgresqllargeobjectpgclobjava jdbcorgpostgresqltestjdbctestsjava jdbcorgpostgresqlxaclientconnectionjava jdbcorgpostgresqlxatwophaseconnectionjava jdbcorgpostgresqlxatxconnectionjava jdbcorgpostgresqlxaxaconnectionimpljava jdbcorgpostgresqlxaxadatasourceimpljava  \n",
       "878                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               merged revisions via svnmerge r steve sat dec line broke splitting lines little r steve sat dec line remove inline line splitting code r steve sat dec line create filter infrastructure r steve sun dec lines working implementation although break filters need add functionality r steve sun dec line rename filter chain r steve sun dec line rename line splitting filter r steve mon dec line rename line splitting filter add polygon splitter r steve mon dec line make sure lines always copied changing points would change levels r steve mon dec line add copy constructors mapshape class r steve mon dec line add filtering polygons add line filter lines polygon filters polygons r steve mon dec line tidying r steve mon dec line split files general package actual generalgarmin conversion r steve mon dec line useful amount smothing applied r steve mon dec line fix returning chaining filter r steve mon dec line polygon splitter polygons many points split r steve mon dec lines remove printlns r steve mon dec line smoothing filter remove old code remove duplicate points gitsvnid dfeeadfeeeb  \n",
       "50                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     added target nearest neighbor finder tool reduced default timeout longrunning tests added jaccardindex overload two sets elements fixed javadoc made class serializable added support maximum path length reworked use new simpledependencypath class revised error message clarity updated use new simpledependencypath features updated use new simpledependencypath features major rewrite clarity fixed tostring added static methods testing category particular pos tag implemented missing methods added imports sure added logging added support shuffling edges graph using fixed random reproducability multithreaded edge similarity comparison probably bug fixes updated use intpair instead pairinteger updated use intset major overhaul bring performance line earlier primitive collection enhancements probably needs lot clean still updates use new primitive collections updates use new primitive collections added support clustering fixed number clusters added limited support writing gexf format added limited support writing pajek format made default output verbose remove extra temporary file hanging around unneeded added support getting string backs document added new class testing association two terms already partially supported bigramextractor class supports limiting number items associated enables better scaling iterative association testing class needs lot work added iterator documents wackypedia fixed html bug javadoc added new tool running nearestneighborfinder command line fixed javadoc added support changing loging level logger namespace added new tool speeding repeated nearestneighbor computations partitioning semanticspace clusters using kmeans searching subset added support reading writing streams byte arrays updated intset added pair implementation fixed iterator remove bug added extensive realworld unit tests added unit test details match example ahn et al paper added tests  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.loc[[400, 833, 243, 878, 50]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "df['tokens'] = df['commit_message_clean'].apply(word_tokenize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import pos_tag\n",
    "\n",
    "df['pos_tags'] = df['tokens'].apply(pos_tag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Function to map NLTK position tags\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN  # Default to noun if unknown\n",
    "\n",
    "# Lemmatize a sentence with the appropriate POS tag\n",
    "def lemmatize_with_pos(sentence):\n",
    "    return [lemmatizer.lemmatize(word, get_wordnet_pos(pos_tag)) for word, pos_tag in sentence]\n",
    "\n",
    "# Apply the lemmatization function to the pos tags\n",
    "df['lemmatized'] = df['pos_tags'].apply(lemmatize_with_pos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lemmatized_text'] = df['lemmatized'].apply(' '.join)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>commit_message</th>\n",
       "      <th>category</th>\n",
       "      <th>commit_message_clean</th>\n",
       "      <th>tokens</th>\n",
       "      <th>pos_tags</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>lemmatized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\tNIO Reads writes are completed in the caller thered;\\n\\t100% compatible with old interface and functionality.\\n\\tEach connection has an instance of this object to\\n\\treceive data for a message in multiple OP_READ events.\\n</td>\n",
       "      <td>functional</td>\n",
       "      <td>nio reads writes completed caller would compatible old interface functionality connection instance object receive data message multiple opread events</td>\n",
       "      <td>[nio, reads, writes, completed, caller, would, compatible, old, interface, functionality, connection, instance, object, receive, data, message, multiple, opread, events]</td>\n",
       "      <td>[(nio, JJ), (reads, NNS), (writes, VBZ), (completed, VBN), (caller, NN), (would, MD), (compatible, VB), (old, JJ), (interface, NN), (functionality, NN), (connection, NN), (instance, NN), (object, VBP), (receive, JJ), (data, NNS), (message, NN), (multiple, JJ), (opread, JJ), (events, NNS)]</td>\n",
       "      <td>[nio, read, write, complete, caller, would, compatible, old, interface, functionality, connection, instance, object, receive, data, message, multiple, opread, event]</td>\n",
       "      <td>nio read write complete caller would compatible old interface functionality connection instance object receive data message multiple opread event</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>* temporary fix for non-shared JArray objects\\n  * added generic unittests to check jcc/lucene/solr/montysolr functionality\\n  * wrote unittest for newseman (it does a complete processing from python side)\\n    - now what remains is to call it from java\\n    - decide on proper behaviour for cases when tokens are added/grouped\\n</td>\n",
       "      <td>bugfix</td>\n",
       "      <td>temporary fix nonshared jarray objects added generic unittests check jcclucenesolrmontysolr functionality wrote unittest newseman complete processing python side remains call java decide proper behaviour cases tokens addedgrouped</td>\n",
       "      <td>[temporary, fix, nonshared, jarray, objects, added, generic, unittests, check, jcclucenesolrmontysolr, functionality, wrote, unittest, newseman, complete, processing, python, side, remains, call, java, decide, proper, behaviour, cases, tokens, addedgrouped]</td>\n",
       "      <td>[(temporary, JJ), (fix, NN), (nonshared, VBD), (jarray, JJ), (objects, NNS), (added, VBD), (generic, JJ), (unittests, NNS), (check, VBP), (jcclucenesolrmontysolr, JJ), (functionality, NN), (wrote, VBD), (unittest, JJ), (newseman, JJ), (complete, JJ), (processing, NN), (python, JJ), (side, NN), (remains, VBZ), (call, JJ), (java, NN), (decide, NN), (proper, IN), (behaviour, JJ), (cases, NNS), (tokens, NNS), (addedgrouped, VBD)]</td>\n",
       "      <td>[temporary, fix, nonshared, jarray, object, add, generic, unittests, check, jcclucenesolrmontysolr, functionality, write, unittest, newseman, complete, processing, python, side, remain, call, java, decide, proper, behaviour, case, token, addedgrouped]</td>\n",
       "      <td>temporary fix nonshared jarray object add generic unittests check jcclucenesolrmontysolr functionality write unittest newseman complete processing python side remain call java decide proper behaviour case token addedgrouped</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>* Java:\\n   * Added RCON functionality for Source servers:\\n     * Added steamcondenser.steam.packets.rcon package\\n     * Added RCONAuthRequestPacket\\n     * Added RCONAuthResponsePacket\\n     * Added RCONExecRequestPacket\\n     * Added RCONExecResponsePacket\\n     * Added RCONPacket\\n     * Added RCONNoAuthException\\n   * Split SteamSocket into QuerySocket and RCONSocket\\n   * Stub functionality for GoldSrc servers\\n     * GoldSrc uses UDP and needs a special implementation\\n   * Added tests\\n</td>\n",
       "      <td>functional</td>\n",
       "      <td>java added rcon functionality source servers added steamcondensersteampacketsrcon package added rconauthrequestpacket added rconauthresponsepacket added rconexecrequestpacket added rconexecresponsepacket added rconpacket added rconnoauthexception split steamsocket querysocket rconsocket stub functionality goldsrc servers goldsrc uses udp needs special implementation added tests</td>\n",
       "      <td>[java, added, rcon, functionality, source, servers, added, steamcondensersteampacketsrcon, package, added, rconauthrequestpacket, added, rconauthresponsepacket, added, rconexecrequestpacket, added, rconexecresponsepacket, added, rconpacket, added, rconnoauthexception, split, steamsocket, querysocket, rconsocket, stub, functionality, goldsrc, servers, goldsrc, uses, udp, needs, special, implementation, added, tests]</td>\n",
       "      <td>[(java, NN), (added, VBD), (rcon, NN), (functionality, NN), (source, NN), (servers, NNS), (added, VBD), (steamcondensersteampacketsrcon, JJ), (package, NN), (added, VBD), (rconauthrequestpacket, NN), (added, VBD), (rconauthresponsepacket, NN), (added, VBD), (rconexecrequestpacket, NN), (added, VBD), (rconexecresponsepacket, NN), (added, VBD), (rconpacket, NN), (added, JJ), (rconnoauthexception, NN), (split, NN), (steamsocket, NN), (querysocket, NN), (rconsocket, NN), (stub, NN), (functionality, NN), (goldsrc, NN), (servers, NNS), (goldsrc, VBP), (uses, VBZ), (udp, JJ), (needs, NNS), (special, JJ), (implementation, NN), (added, VBD), (tests, NNS)]</td>\n",
       "      <td>[java, add, rcon, functionality, source, server, add, steamcondensersteampacketsrcon, package, add, rconauthrequestpacket, add, rconauthresponsepacket, add, rconexecrequestpacket, add, rconexecresponsepacket, add, rconpacket, added, rconnoauthexception, split, steamsocket, querysocket, rconsocket, stub, functionality, goldsrc, server, goldsrc, use, udp, need, special, implementation, add, test]</td>\n",
       "      <td>java add rcon functionality source server add steamcondensersteampacketsrcon package add rconauthrequestpacket add rconauthresponsepacket add rconexecrequestpacket add rconexecresponsepacket add rconpacket added rconnoauthexception split steamsocket querysocket rconsocket stub functionality goldsrc server goldsrc use udp need special implementation add test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>- Merge changes from Pull-Request #6 \\t - Fix aggregation generation and cleanup dead code  - Update dependencies versions</td>\n",
       "      <td>code smell</td>\n",
       "      <td>merge changes pullrequest fix aggregation generation cleanup dead code update dependencies versions</td>\n",
       "      <td>[merge, changes, pullrequest, fix, aggregation, generation, cleanup, dead, code, update, dependencies, versions]</td>\n",
       "      <td>[(merge, NN), (changes, NNS), (pullrequest, VBP), (fix, JJ), (aggregation, NN), (generation, NN), (cleanup, NN), (dead, JJ), (code, NN), (update, JJ), (dependencies, NNS), (versions, NNS)]</td>\n",
       "      <td>[merge, change, pullrequest, fix, aggregation, generation, cleanup, dead, code, update, dependency, version]</td>\n",
       "      <td>merge change pullrequest fix aggregation generation cleanup dead code update dependency version</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bug 233643 -  API builder performance bad for incremental build</td>\n",
       "      <td>external</td>\n",
       "      <td>bug api builder performance bad incremental build</td>\n",
       "      <td>[bug, api, builder, performance, bad, incremental, build]</td>\n",
       "      <td>[(bug, NN), (api, JJ), (builder, NN), (performance, NN), (bad, JJ), (incremental, JJ), (build, NN)]</td>\n",
       "      <td>[bug, api, builder, performance, bad, incremental, build]</td>\n",
       "      <td>bug api builder performance bad incremental build</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          commit_message  \\\n",
       "0                                                                                                                                                                                                                                                                                       \\tNIO Reads writes are completed in the caller thered;\\n\\t100% compatible with old interface and functionality.\\n\\tEach connection has an instance of this object to\\n\\treceive data for a message in multiple OP_READ events.\\n   \n",
       "1                                                                                                                                                                              * temporary fix for non-shared JArray objects\\n  * added generic unittests to check jcc/lucene/solr/montysolr functionality\\n  * wrote unittest for newseman (it does a complete processing from python side)\\n    - now what remains is to call it from java\\n    - decide on proper behaviour for cases when tokens are added/grouped\\n   \n",
       "2   * Java:\\n   * Added RCON functionality for Source servers:\\n     * Added steamcondenser.steam.packets.rcon package\\n     * Added RCONAuthRequestPacket\\n     * Added RCONAuthResponsePacket\\n     * Added RCONExecRequestPacket\\n     * Added RCONExecResponsePacket\\n     * Added RCONPacket\\n     * Added RCONNoAuthException\\n   * Split SteamSocket into QuerySocket and RCONSocket\\n   * Stub functionality for GoldSrc servers\\n     * GoldSrc uses UDP and needs a special implementation\\n   * Added tests\\n   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                             - Merge changes from Pull-Request #6 \\t - Fix aggregation generation and cleanup dead code  - Update dependencies versions   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                        Bug 233643 -  API builder performance bad for incremental build   \n",
       "\n",
       "     category  \\\n",
       "0  functional   \n",
       "1      bugfix   \n",
       "2  functional   \n",
       "3  code smell   \n",
       "4    external   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                           commit_message_clean  \\\n",
       "0                                                                                                                                                                                                                                         nio reads writes completed caller would compatible old interface functionality connection instance object receive data message multiple opread events   \n",
       "1                                                                                                                                                         temporary fix nonshared jarray objects added generic unittests check jcclucenesolrmontysolr functionality wrote unittest newseman complete processing python side remains call java decide proper behaviour cases tokens addedgrouped   \n",
       "2  java added rcon functionality source servers added steamcondensersteampacketsrcon package added rconauthrequestpacket added rconauthresponsepacket added rconexecrequestpacket added rconexecresponsepacket added rconpacket added rconnoauthexception split steamsocket querysocket rconsocket stub functionality goldsrc servers goldsrc uses udp needs special implementation added tests   \n",
       "3                                                                                                                                                                                                                                                                                           merge changes pullrequest fix aggregation generation cleanup dead code update dependencies versions   \n",
       "4                                                                                                                                                                                                                                                                                                                                             bug api builder performance bad incremental build   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                               tokens  \\\n",
       "0                                                                                                                                                                                                                                                           [nio, reads, writes, completed, caller, would, compatible, old, interface, functionality, connection, instance, object, receive, data, message, multiple, opread, events]   \n",
       "1                                                                                                                                                                   [temporary, fix, nonshared, jarray, objects, added, generic, unittests, check, jcclucenesolrmontysolr, functionality, wrote, unittest, newseman, complete, processing, python, side, remains, call, java, decide, proper, behaviour, cases, tokens, addedgrouped]   \n",
       "2  [java, added, rcon, functionality, source, servers, added, steamcondensersteampacketsrcon, package, added, rconauthrequestpacket, added, rconauthresponsepacket, added, rconexecrequestpacket, added, rconexecresponsepacket, added, rconpacket, added, rconnoauthexception, split, steamsocket, querysocket, rconsocket, stub, functionality, goldsrc, servers, goldsrc, uses, udp, needs, special, implementation, added, tests]   \n",
       "3                                                                                                                                                                                                                                                                                                                    [merge, changes, pullrequest, fix, aggregation, generation, cleanup, dead, code, update, dependencies, versions]   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                           [bug, api, builder, performance, bad, incremental, build]   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         pos_tags  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                               [(nio, JJ), (reads, NNS), (writes, VBZ), (completed, VBN), (caller, NN), (would, MD), (compatible, VB), (old, JJ), (interface, NN), (functionality, NN), (connection, NN), (instance, NN), (object, VBP), (receive, JJ), (data, NNS), (message, NN), (multiple, JJ), (opread, JJ), (events, NNS)]   \n",
       "1                                                                                                                                                                                                                                   [(temporary, JJ), (fix, NN), (nonshared, VBD), (jarray, JJ), (objects, NNS), (added, VBD), (generic, JJ), (unittests, NNS), (check, VBP), (jcclucenesolrmontysolr, JJ), (functionality, NN), (wrote, VBD), (unittest, JJ), (newseman, JJ), (complete, JJ), (processing, NN), (python, JJ), (side, NN), (remains, VBZ), (call, JJ), (java, NN), (decide, NN), (proper, IN), (behaviour, JJ), (cases, NNS), (tokens, NNS), (addedgrouped, VBD)]   \n",
       "2  [(java, NN), (added, VBD), (rcon, NN), (functionality, NN), (source, NN), (servers, NNS), (added, VBD), (steamcondensersteampacketsrcon, JJ), (package, NN), (added, VBD), (rconauthrequestpacket, NN), (added, VBD), (rconauthresponsepacket, NN), (added, VBD), (rconexecrequestpacket, NN), (added, VBD), (rconexecresponsepacket, NN), (added, VBD), (rconpacket, NN), (added, JJ), (rconnoauthexception, NN), (split, NN), (steamsocket, NN), (querysocket, NN), (rconsocket, NN), (stub, NN), (functionality, NN), (goldsrc, NN), (servers, NNS), (goldsrc, VBP), (uses, VBZ), (udp, JJ), (needs, NNS), (special, JJ), (implementation, NN), (added, VBD), (tests, NNS)]   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    [(merge, NN), (changes, NNS), (pullrequest, VBP), (fix, JJ), (aggregation, NN), (generation, NN), (cleanup, NN), (dead, JJ), (code, NN), (update, JJ), (dependencies, NNS), (versions, NNS)]   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             [(bug, NN), (api, JJ), (builder, NN), (performance, NN), (bad, JJ), (incremental, JJ), (build, NN)]   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                      lemmatized  \\\n",
       "0                                                                                                                                                                                                                                          [nio, read, write, complete, caller, would, compatible, old, interface, functionality, connection, instance, object, receive, data, message, multiple, opread, event]   \n",
       "1                                                                                                                                                    [temporary, fix, nonshared, jarray, object, add, generic, unittests, check, jcclucenesolrmontysolr, functionality, write, unittest, newseman, complete, processing, python, side, remain, call, java, decide, proper, behaviour, case, token, addedgrouped]   \n",
       "2  [java, add, rcon, functionality, source, server, add, steamcondensersteampacketsrcon, package, add, rconauthrequestpacket, add, rconauthresponsepacket, add, rconexecrequestpacket, add, rconexecresponsepacket, add, rconpacket, added, rconnoauthexception, split, steamsocket, querysocket, rconsocket, stub, functionality, goldsrc, server, goldsrc, use, udp, need, special, implementation, add, test]   \n",
       "3                                                                                                                                                                                                                                                                                                   [merge, change, pullrequest, fix, aggregation, generation, cleanup, dead, code, update, dependency, version]   \n",
       "4                                                                                                                                                                                                                                                                                                                                                      [bug, api, builder, performance, bad, incremental, build]   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                           lemmatized_text  \n",
       "0                                                                                                                                                                                                                        nio read write complete caller would compatible old interface functionality connection instance object receive data message multiple opread event  \n",
       "1                                                                                                                                          temporary fix nonshared jarray object add generic unittests check jcclucenesolrmontysolr functionality write unittest newseman complete processing python side remain call java decide proper behaviour case token addedgrouped  \n",
       "2  java add rcon functionality source server add steamcondensersteampacketsrcon package add rconauthrequestpacket add rconauthresponsepacket add rconexecrequestpacket add rconexecresponsepacket add rconpacket added rconnoauthexception split steamsocket querysocket rconsocket stub functionality goldsrc server goldsrc use udp need special implementation add test  \n",
       "3                                                                                                                                                                                                                                                                          merge change pullrequest fix aggregation generation cleanup dead code update dependency version  \n",
       "4                                                                                                                                                                                                                                                                                                                        bug api builder performance bad incremental build  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemmatized_text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nio read write complete caller would compatible old interface functionality connection instance object receive data message multiple opread event</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>temporary fix nonshared jarray object add generic unittests check jcclucenesolrmontysolr functionality write unittest newseman complete processing python side remain call java decide proper behaviour case token addedgrouped</td>\n",
       "      <td>bugfix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>java add rcon functionality source server add steamcondensersteampacketsrcon package add rconauthrequestpacket add rconauthresponsepacket add rconexecrequestpacket add rconexecresponsepacket add rconpacket added rconnoauthexception split steamsocket querysocket rconsocket stub functionality goldsrc server goldsrc use udp need special implementation add test</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>merge change pullrequest fix aggregation generation cleanup dead code update dependency version</td>\n",
       "      <td>code smell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bug api builder performance bad incremental build</td>\n",
       "      <td>external</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1735</th>\n",
       "      <td>work introduce getspecialfeaturecollection method general way get printtemplatefeatures improve number</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1736</th>\n",
       "      <td>work next step move calculation handle printtemplatefeature handle multiple templateprinting creation still basic though</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1737</th>\n",
       "      <td>work generalize adjustmapforprintingtemplates ensurevisibilityofprintingtemplates method adjustmapforspecialfeatureclasses ensurevisibilityofspecialfeatures</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1738</th>\n",
       "      <td>work test coverage minor tweak remove dead code fix minor bug add test</td>\n",
       "      <td>code smell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1739</th>\n",
       "      <td>change render routine text field add tabbing ability customscreen various modification customscreen match new textfield requirement change size packetsky</td>\n",
       "      <td>internal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1716 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                              lemmatized_text  \\\n",
       "0                                                                                                                                                                                                                           nio read write complete caller would compatible old interface functionality connection instance object receive data message multiple opread event   \n",
       "1                                                                                                                                             temporary fix nonshared jarray object add generic unittests check jcclucenesolrmontysolr functionality write unittest newseman complete processing python side remain call java decide proper behaviour case token addedgrouped   \n",
       "2     java add rcon functionality source server add steamcondensersteampacketsrcon package add rconauthrequestpacket add rconauthresponsepacket add rconexecrequestpacket add rconexecresponsepacket add rconpacket added rconnoauthexception split steamsocket querysocket rconsocket stub functionality goldsrc server goldsrc use udp need special implementation add test   \n",
       "3                                                                                                                                                                                                                                                                             merge change pullrequest fix aggregation generation cleanup dead code update dependency version   \n",
       "4                                                                                                                                                                                                                                                                                                                           bug api builder performance bad incremental build   \n",
       "...                                                                                                                                                                                                                                                                                                                                                                       ...   \n",
       "1735                                                                                                                                                                                                                                                                   work introduce getspecialfeaturecollection method general way get printtemplatefeatures improve number   \n",
       "1736                                                                                                                                                                                                                                                 work next step move calculation handle printtemplatefeature handle multiple templateprinting creation still basic though   \n",
       "1737                                                                                                                                                                                                             work generalize adjustmapforprintingtemplates ensurevisibilityofprintingtemplates method adjustmapforspecialfeatureclasses ensurevisibilityofspecialfeatures   \n",
       "1738                                                                                                                                                                                                                                                                                                   work test coverage minor tweak remove dead code fix minor bug add test   \n",
       "1739                                                                                                                                                                                                                change render routine text field add tabbing ability customscreen various modification customscreen match new textfield requirement change size packetsky   \n",
       "\n",
       "        category  \n",
       "0     functional  \n",
       "1         bugfix  \n",
       "2     functional  \n",
       "3     code smell  \n",
       "4       external  \n",
       "...          ...  \n",
       "1735  functional  \n",
       "1736  functional  \n",
       "1737  functional  \n",
       "1738  code smell  \n",
       "1739    internal  \n",
       "\n",
       "[1716 rows x 2 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[['lemmatized_text', 'category']]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lemmatized_text'] = df['lemmatized_text'].apply(clean_text)\n",
    "df['lemmatized_text'] = df['lemmatized_text'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lemmatized_text    1702\n",
       "category           1702\n",
       "dtype: int64"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For rows\n",
    "df = df.dropna(how='all')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemmatized_text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>change base keiths review tweak edgeset help track edge removal modify srceduuclasspacecommonsimilarityjava update use vectormathdotproduct tanimoto coefficient delete srceduuclasspacecommonwordcomparatorjava move simplenearestneighborfinder modify srceduuclasspacedependencysimpledependencypathjava remove println modify srceduuclasspacegraphabstractgraphjava add miss implementation subgraph class unit test pass modify srceduuclasspacegraphdirectedmultigraphjava add miss implementation subgraph class unit test pass fix bug report correct edge type removal remove dead code modify srceduuclasspacegraphedgesetjava update disconnect return number edge remove modified srceduuclasspacegraphgenericedgesetjava modify srceduuclasspacegraphsparsedirectededgesetjava modify srceduuclasspacegraphsparsedirectedtypededgesetjava modify srceduuclasspacegraphsparsetypededgesetjava modify srceduuclasspacegraphsparseundirectededgesetjava modify srceduuclasspacegraphsparseweightededgesetjava updated support edgeset interface change delete srceduuclasspacegraphgraphrandomizerjava remove dead class functionality graphsjava modify srceduuclasspacegraphsimpleweightededgejava fixed hashcode delete srceduuclasspacegraphsparsesymmetricedgesetjava remove dead class modify srceduuclasspacegraphundirectedmultigraphjava add miss implementation subgraph class unit test pass fix bug report correct edge type removal remove dead code modify srceduuclasspacemainsfixeddurationtemporalrandomindexingmainjava updated replace wordcomparator simplenearestneighborfinder modify srceduuclasspacemainslexsubwordsimainjava updated replace wordcomparator simplenearestneighborfinder modify srceduuclasspacetextlabeledparsedstringdocumentjava updated new parseddocument interface modify srceduuclasspacetextparseddocumentjava update specify format text tokens white space delimiters add new prettyprinttext attempt nicely format token would originally modify srceduuclasspacetextpukwacdocumentiteratorjava fix javadoc modify srceduuclasspacetextukwacdocumentiteratorjava add class javadoc modify srceduuclasspacetoolsnearestneighborfindertooljava update use class instance instead interface modified srceduuclasspacetoolssemanticspaceexplorerjava update replace wordcomparator partitioningnearestneighborfinder modify srceduuclasspacetoolssimilaritylistgeneratorjava updated replace wordcomparator partitioningnearestneighborfinder modify srceduuclasspaceutilhashindexerjava fix javadoc modify srceduuclasspaceutilpaircounterjava fix javadoc rename srceduuclasspaceutilnearestneighborfinderjava srceduuclasspaceutilpartitioningnearestneighborfinderjava move nearestneighborfinder interface modify srceduuclasspaceutilreflectionutiljava remove dead code modify srceduuclasspaceutilprimitiveintinthashmultimapjava add javadoc modify srceduuclasspaceutilprimitiveintintmultimapjava add javadoc modify testeduuclasspacegraphdirectedmultigraphtestsjava uncommented unit test modify testeduuclasspacedependencybreadthfirstpathiteratortestjava modify testeduuclasspacedependencyconlldependencyextractortestjava modify testeduuclasspacedependencywackydependencyextractortestjava modify testeduuclasspacetextcorporapukwacdependencycorpusreadertestjava modify testeduuclasspacewordsidependencycontextextractortestjava modify testeduuclasspacewordsioccurrencedependencycontextgeneratortestjava modify testeduuclasspacewordsiorderingdependencycontextgeneratortestjava modify testeduuclasspacewordsipartofspeechdependencycontextgeneratortestjava modify testeduuclasspacewordsipsdpseudoworddependencycontextextractortestjava modify testeduuclasspacewordsisemevalsemevaldependencycontextextractortestjava fix unit test support proper tabdelimiting conll format</td>\n",
       "      <td>bugfix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>833</th>\n",
       "      <td>lot lot bug fix minor functionality enhancement modify srcmainjavaeduuclasspacecommonsimilarityjava add warning invalid kldivergence computation add kruskalgoodman gamma discover spearmans rho kendall tau wrong fix modify srcmainjavaeduuclasspacecommonstatisticsloglikelihoodtestjava fix implementation new file srcmainjavaeduuclasspacegraphchinesewhispersclusteringjava add cw cluster appear produce result exist code need investigation modify srcmainjavaeduuclasspacegraphgraphiojava tweak log modify srcmainjavaeduuclasspacegraphlinkclusteringjava make thread count base processor instead fix new file srcmainjavaeduuclasspacegraphsimpleweighteddirectedtypededgejava new file srcmainjavaeduuclasspacegraphsimpleweightedtypededgejava new file srcmainjavaeduuclasspacegraphsparseweighteddirectededgesetjava new file srcmainjavaeduuclasspacegraphsparseweighteddirectedtypededgesetjava new file srcmainjavaeduuclasspacegraphweighteddirectedmultigraphjava modify srcmainjavaeduuclasspacegraphweighteddirectedtypededgejava add partial support weight multigraphs feature probably need eventually modify srcmainjavaeduuclasspacegraphioedgelistreaderjava add well log instead printf new file srcmainjavaeduuclasspacegraphiographmlreaderjava add initial graphml implementation read large graphml file partial support place modify srcmainjavaeduuclasspaceindexdefaultpermutationfunctionjava fix outstanding bug sure bug first place code currently break odd way new file srcmainjavaeduuclasspacetextannotateddocumentjava add support new document creation date label new file srcmainjavaeduuclasspacetextbufferedfilelistdocumentiteratorjava add new iterator precaches content file file list use separate thread cut disk io modify srcmainjavaeduuclasspacetextfiledocumentjava add support document back file whose content load memory demand new file srcmainjavaeduuclasspacetoolsiterativebigramextractorjava add tool find statistical association term iterative pairwise manner new file srcmainjavaeduuclasspacetoolslinkclusteringtooljava copy code svn branch run link cluster jar modify srcmainjavaeduuclasspaceutilcombinediteratorjava correct exception throw remove modify srcmainjavaeduuclasspaceutilhashmultimapjava correct error remove key iterator fix bug null return instead empty set new file srcmainjavaeduuclasspaceutilkrippendorffsalphajava add partial implementation krippendorffs alpha ordinalvalued data modify srcmainjavaeduuclasspaceutilmultimapjava clarified javadoc modify srcmainjavaeduuclasspaceutilobjectcounterjava implement max min modify srcmainjavaeduuclasspaceutilpairjava make serializable modified srcmainjavaeduuclasspaceutilsetdecoratorjava clarify javadoc new file srctestjavaeduuclasspacegraphchinesewhisperstestjava new file srctestjavaeduuclasspacegraphsparseweighteddirectedtypededgesettestjava new file srctestjavaeduuclasspacegraphweighteddirectedmultigraphtestjava unit test modify srctestjavaeduuclasspaceindexdefaultpermutationfunctiontestjava add debugging output</td>\n",
       "      <td>bugfix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>added support jdbc driver build jdbc ie java conclude change restructure code support jdbc jdbc unit test also resturctured allow different test jdbc jdbc although currently make check aka ant test jdbc run jdbc test special note largeobjectpgblob pgclob class move jdbcjdbc specific directory differ jdbc version also note checkin remove postgresqldatasource file xa directory recent checkin add new datasource support replaces functionality provide class modify file jdbcbuildxml jdbcorgpostgresqljdbcabstractjdbcdatabasemetadatajava jdbcorgpostgresqljdbcabstractjdbcresultsetjava jdbcorgpostgresqljdbcabstractjdbcresultsetmetadatajava jdbcorgpostgresqljdbcabstractjdbcstatementjava jdbcorgpostgresqljdbcabstractjdbcconnectionjava jdbcorgpostgresqljdbcabstractjdbcdatabasemetadatajava jdbcorgpostgresqljdbcabstractjdbcresultsetjava jdbcorgpostgresqljdbcabstractjdbcresultsetmetadatajava jdbcorgpostgresqljdbcabstractjdbcstatementjava jdbcorgpostgresqljdbcarrayjava jdbcorgpostgresqljdbcjdbccallablestatementjava jdbcorgpostgresqljdbcjdbcconnectionjava jdbcorgpostgresqljdbcjdbcdatabasemetadatajava jdbcorgpostgresqljdbcjdbcpreparedstatementjava jdbcorgpostgresqljdbcjdbcresultsetjava jdbcorgpostgresqljdbcjdbcresultsetmetadatajava jdbcorgpostgresqljdbcjdbcstatementjava jdbcorgpostgresqltestjdbcbatchexecutetestjava jdbcorgpostgresqltestjdbcblobtestjava jdbcorgpostgresqltestjdbccallablestmttestjava jdbcorgpostgresqltestjdbcconnectiontestjava jdbcorgpostgresqltestjdbcdatabasemetadatatestjava jdbcorgpostgresqltestjdbcdatetestjava jdbcorgpostgresqltestjdbcdrivertestjava jdbcorgpostgresqltestjdbcjbuildertestjava jdbcorgpostgresqltestjdbcmisctestjava jdbcorgpostgresqltestjdbcresultsettestjava jdbcorgpostgresqltestjdbctimetestjava jdbcorgpostgresqltestjdbctimestamptestjava jdbcorgpostgresqltestjdbcupdateableresulttestjava add file jdbcorgpostgresqljdbcabstractjdbcblobjava jdbcorgpostgresqljdbcabstractjdbcclobjava jdbcorgpostgresqljdbcjdbcblobjava jdbcorgpostgresqljdbcjdbcclobjava jdbcorgpostgresqljdbcabstractjdbcblobjava jdbcorgpostgresqljdbcabstractjdbcclobjava jdbcorgpostgresqljdbcabstractjdbcconnectionjava jdbcorgpostgresqljdbcabstractjdbcdatabasemetadatajava jdbcorgpostgresqljdbcabstractjdbcresultsetjava jdbcorgpostgresqljdbcabstractjdbcstatementjava jdbcorgpostgresqljdbcjdbcblobjava jdbcorgpostgresqljdbcjdbccallablestatementjava jdbcorgpostgresqljdbcjdbcclobjava jdbcorgpostgresqljdbcjdbcconnectionjava jdbcorgpostgresqljdbcjdbcdatabasemetadatajava jdbcorgpostgresqljdbcjdbcpreparedstatementjava jdbcorgpostgresqljdbcjdbcresultsetjava jdbcorgpostgresqljdbcjdbcresultsetmetadatajava jdbcorgpostgresqljdbcjdbcstatementjava jdbcorgpostgresqltesttestutiljava jdbcorgpostgresqltestjdbcjdbctestsuitejava jdbcorgpostgresqltestjdbcjdbctestsuitejava remove file jdbcorgpostgresqlpostgresqldatasourcejava jdbcorgpostgresqllargeobjectpgblobjava jdbcorgpostgresqllargeobjectpgclobjava jdbcorgpostgresqltestjdbctestsjava jdbcorgpostgresqlxaclientconnectionjava jdbcorgpostgresqlxatwophaseconnectionjava jdbcorgpostgresqlxatxconnectionjava jdbcorgpostgresqlxaxaconnectionimpljava jdbcorgpostgresqlxaxadatasourceimpljava</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>merge revision via svnmerge steve sit dec line break split line little steve sit dec line remove inline line split code steve sit dec line create filter infrastructure steve sun dec line work implementation although break filter need add functionality steve sun dec line rename filter chain steve sun dec line rename line split filter steve mon dec line rename line split filter add polygon splitter steve mon dec line make sure line always copy change point would change level steve mon dec line add copy constructor mapshape class steve mon dec line add filter polygon add line filter line polygon filter polygon steve mon dec line tidy steve mon dec line split file general package actual generalgarmin conversion steve mon dec line useful amount smothing apply steve mon dec line fix return chain filter steve mon dec line polygon splitter polygon many point split steve mon dec line remove printlns steve mon dec line smooth filter remove old code remove duplicate point gitsvnid dfeeadfeeeb</td>\n",
       "      <td>bugfix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>add target near neighbor finder tool reduce default timeout longrunning test add jaccardindex overload two set element fix javadoc make class serializable add support maximum path length rework use new simpledependencypath class revise error message clarity update use new simpledependencypath feature update use new simpledependencypath feature major rewrite clarity fix tostring add static method test category particular po tag implement miss method add import sure add logging added support shuffle edge graph use fix random reproducability multithreaded edge similarity comparison probably bug fix update use intpair instead pairinteger updated use intset major overhaul bring performance line earlier primitive collection enhancement probably need lot clean still update use new primitive collection update use new primitive collection add support cluster fix number cluster add limited support write gexf format add limited support write pajek format make default output verbose remove extra temporary file hang around unneeded added support get string back document add new class test association two term already partially support bigramextractor class support limit number item associate enables well scale iterative association test class need lot work add iterator document wackypedia fix html bug javadoc add new tool run nearestneighborfinder command line fix javadoc add support change log level logger namespace add new tool speeding repeat nearestneighbor computation partition semanticspace cluster use kmeans search subset add support read write stream byte array update intset add pair implementation fix iterator remove bug added extensive realworld unit test add unit test detail match example ahn et al paper add test</td>\n",
       "      <td>bugfix</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               lemmatized_text  \\\n",
       "400  change base keiths review tweak edgeset help track edge removal modify srceduuclasspacecommonsimilarityjava update use vectormathdotproduct tanimoto coefficient delete srceduuclasspacecommonwordcomparatorjava move simplenearestneighborfinder modify srceduuclasspacedependencysimpledependencypathjava remove println modify srceduuclasspacegraphabstractgraphjava add miss implementation subgraph class unit test pass modify srceduuclasspacegraphdirectedmultigraphjava add miss implementation subgraph class unit test pass fix bug report correct edge type removal remove dead code modify srceduuclasspacegraphedgesetjava update disconnect return number edge remove modified srceduuclasspacegraphgenericedgesetjava modify srceduuclasspacegraphsparsedirectededgesetjava modify srceduuclasspacegraphsparsedirectedtypededgesetjava modify srceduuclasspacegraphsparsetypededgesetjava modify srceduuclasspacegraphsparseundirectededgesetjava modify srceduuclasspacegraphsparseweightededgesetjava updated support edgeset interface change delete srceduuclasspacegraphgraphrandomizerjava remove dead class functionality graphsjava modify srceduuclasspacegraphsimpleweightededgejava fixed hashcode delete srceduuclasspacegraphsparsesymmetricedgesetjava remove dead class modify srceduuclasspacegraphundirectedmultigraphjava add miss implementation subgraph class unit test pass fix bug report correct edge type removal remove dead code modify srceduuclasspacemainsfixeddurationtemporalrandomindexingmainjava updated replace wordcomparator simplenearestneighborfinder modify srceduuclasspacemainslexsubwordsimainjava updated replace wordcomparator simplenearestneighborfinder modify srceduuclasspacetextlabeledparsedstringdocumentjava updated new parseddocument interface modify srceduuclasspacetextparseddocumentjava update specify format text tokens white space delimiters add new prettyprinttext attempt nicely format token would originally modify srceduuclasspacetextpukwacdocumentiteratorjava fix javadoc modify srceduuclasspacetextukwacdocumentiteratorjava add class javadoc modify srceduuclasspacetoolsnearestneighborfindertooljava update use class instance instead interface modified srceduuclasspacetoolssemanticspaceexplorerjava update replace wordcomparator partitioningnearestneighborfinder modify srceduuclasspacetoolssimilaritylistgeneratorjava updated replace wordcomparator partitioningnearestneighborfinder modify srceduuclasspaceutilhashindexerjava fix javadoc modify srceduuclasspaceutilpaircounterjava fix javadoc rename srceduuclasspaceutilnearestneighborfinderjava srceduuclasspaceutilpartitioningnearestneighborfinderjava move nearestneighborfinder interface modify srceduuclasspaceutilreflectionutiljava remove dead code modify srceduuclasspaceutilprimitiveintinthashmultimapjava add javadoc modify srceduuclasspaceutilprimitiveintintmultimapjava add javadoc modify testeduuclasspacegraphdirectedmultigraphtestsjava uncommented unit test modify testeduuclasspacedependencybreadthfirstpathiteratortestjava modify testeduuclasspacedependencyconlldependencyextractortestjava modify testeduuclasspacedependencywackydependencyextractortestjava modify testeduuclasspacetextcorporapukwacdependencycorpusreadertestjava modify testeduuclasspacewordsidependencycontextextractortestjava modify testeduuclasspacewordsioccurrencedependencycontextgeneratortestjava modify testeduuclasspacewordsiorderingdependencycontextgeneratortestjava modify testeduuclasspacewordsipartofspeechdependencycontextgeneratortestjava modify testeduuclasspacewordsipsdpseudoworddependencycontextextractortestjava modify testeduuclasspacewordsisemevalsemevaldependencycontextextractortestjava fix unit test support proper tabdelimiting conll format   \n",
       "833                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            lot lot bug fix minor functionality enhancement modify srcmainjavaeduuclasspacecommonsimilarityjava add warning invalid kldivergence computation add kruskalgoodman gamma discover spearmans rho kendall tau wrong fix modify srcmainjavaeduuclasspacecommonstatisticsloglikelihoodtestjava fix implementation new file srcmainjavaeduuclasspacegraphchinesewhispersclusteringjava add cw cluster appear produce result exist code need investigation modify srcmainjavaeduuclasspacegraphgraphiojava tweak log modify srcmainjavaeduuclasspacegraphlinkclusteringjava make thread count base processor instead fix new file srcmainjavaeduuclasspacegraphsimpleweighteddirectedtypededgejava new file srcmainjavaeduuclasspacegraphsimpleweightedtypededgejava new file srcmainjavaeduuclasspacegraphsparseweighteddirectededgesetjava new file srcmainjavaeduuclasspacegraphsparseweighteddirectedtypededgesetjava new file srcmainjavaeduuclasspacegraphweighteddirectedmultigraphjava modify srcmainjavaeduuclasspacegraphweighteddirectedtypededgejava add partial support weight multigraphs feature probably need eventually modify srcmainjavaeduuclasspacegraphioedgelistreaderjava add well log instead printf new file srcmainjavaeduuclasspacegraphiographmlreaderjava add initial graphml implementation read large graphml file partial support place modify srcmainjavaeduuclasspaceindexdefaultpermutationfunctionjava fix outstanding bug sure bug first place code currently break odd way new file srcmainjavaeduuclasspacetextannotateddocumentjava add support new document creation date label new file srcmainjavaeduuclasspacetextbufferedfilelistdocumentiteratorjava add new iterator precaches content file file list use separate thread cut disk io modify srcmainjavaeduuclasspacetextfiledocumentjava add support document back file whose content load memory demand new file srcmainjavaeduuclasspacetoolsiterativebigramextractorjava add tool find statistical association term iterative pairwise manner new file srcmainjavaeduuclasspacetoolslinkclusteringtooljava copy code svn branch run link cluster jar modify srcmainjavaeduuclasspaceutilcombinediteratorjava correct exception throw remove modify srcmainjavaeduuclasspaceutilhashmultimapjava correct error remove key iterator fix bug null return instead empty set new file srcmainjavaeduuclasspaceutilkrippendorffsalphajava add partial implementation krippendorffs alpha ordinalvalued data modify srcmainjavaeduuclasspaceutilmultimapjava clarified javadoc modify srcmainjavaeduuclasspaceutilobjectcounterjava implement max min modify srcmainjavaeduuclasspaceutilpairjava make serializable modified srcmainjavaeduuclasspaceutilsetdecoratorjava clarify javadoc new file srctestjavaeduuclasspacegraphchinesewhisperstestjava new file srctestjavaeduuclasspacegraphsparseweighteddirectedtypededgesettestjava new file srctestjavaeduuclasspacegraphweighteddirectedmultigraphtestjava unit test modify srctestjavaeduuclasspaceindexdefaultpermutationfunctiontestjava add debugging output   \n",
       "243                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     added support jdbc driver build jdbc ie java conclude change restructure code support jdbc jdbc unit test also resturctured allow different test jdbc jdbc although currently make check aka ant test jdbc run jdbc test special note largeobjectpgblob pgclob class move jdbcjdbc specific directory differ jdbc version also note checkin remove postgresqldatasource file xa directory recent checkin add new datasource support replaces functionality provide class modify file jdbcbuildxml jdbcorgpostgresqljdbcabstractjdbcdatabasemetadatajava jdbcorgpostgresqljdbcabstractjdbcresultsetjava jdbcorgpostgresqljdbcabstractjdbcresultsetmetadatajava jdbcorgpostgresqljdbcabstractjdbcstatementjava jdbcorgpostgresqljdbcabstractjdbcconnectionjava jdbcorgpostgresqljdbcabstractjdbcdatabasemetadatajava jdbcorgpostgresqljdbcabstractjdbcresultsetjava jdbcorgpostgresqljdbcabstractjdbcresultsetmetadatajava jdbcorgpostgresqljdbcabstractjdbcstatementjava jdbcorgpostgresqljdbcarrayjava jdbcorgpostgresqljdbcjdbccallablestatementjava jdbcorgpostgresqljdbcjdbcconnectionjava jdbcorgpostgresqljdbcjdbcdatabasemetadatajava jdbcorgpostgresqljdbcjdbcpreparedstatementjava jdbcorgpostgresqljdbcjdbcresultsetjava jdbcorgpostgresqljdbcjdbcresultsetmetadatajava jdbcorgpostgresqljdbcjdbcstatementjava jdbcorgpostgresqltestjdbcbatchexecutetestjava jdbcorgpostgresqltestjdbcblobtestjava jdbcorgpostgresqltestjdbccallablestmttestjava jdbcorgpostgresqltestjdbcconnectiontestjava jdbcorgpostgresqltestjdbcdatabasemetadatatestjava jdbcorgpostgresqltestjdbcdatetestjava jdbcorgpostgresqltestjdbcdrivertestjava jdbcorgpostgresqltestjdbcjbuildertestjava jdbcorgpostgresqltestjdbcmisctestjava jdbcorgpostgresqltestjdbcresultsettestjava jdbcorgpostgresqltestjdbctimetestjava jdbcorgpostgresqltestjdbctimestamptestjava jdbcorgpostgresqltestjdbcupdateableresulttestjava add file jdbcorgpostgresqljdbcabstractjdbcblobjava jdbcorgpostgresqljdbcabstractjdbcclobjava jdbcorgpostgresqljdbcjdbcblobjava jdbcorgpostgresqljdbcjdbcclobjava jdbcorgpostgresqljdbcabstractjdbcblobjava jdbcorgpostgresqljdbcabstractjdbcclobjava jdbcorgpostgresqljdbcabstractjdbcconnectionjava jdbcorgpostgresqljdbcabstractjdbcdatabasemetadatajava jdbcorgpostgresqljdbcabstractjdbcresultsetjava jdbcorgpostgresqljdbcabstractjdbcstatementjava jdbcorgpostgresqljdbcjdbcblobjava jdbcorgpostgresqljdbcjdbccallablestatementjava jdbcorgpostgresqljdbcjdbcclobjava jdbcorgpostgresqljdbcjdbcconnectionjava jdbcorgpostgresqljdbcjdbcdatabasemetadatajava jdbcorgpostgresqljdbcjdbcpreparedstatementjava jdbcorgpostgresqljdbcjdbcresultsetjava jdbcorgpostgresqljdbcjdbcresultsetmetadatajava jdbcorgpostgresqljdbcjdbcstatementjava jdbcorgpostgresqltesttestutiljava jdbcorgpostgresqltestjdbcjdbctestsuitejava jdbcorgpostgresqltestjdbcjdbctestsuitejava remove file jdbcorgpostgresqlpostgresqldatasourcejava jdbcorgpostgresqllargeobjectpgblobjava jdbcorgpostgresqllargeobjectpgclobjava jdbcorgpostgresqltestjdbctestsjava jdbcorgpostgresqlxaclientconnectionjava jdbcorgpostgresqlxatwophaseconnectionjava jdbcorgpostgresqlxatxconnectionjava jdbcorgpostgresqlxaxaconnectionimpljava jdbcorgpostgresqlxaxadatasourceimpljava   \n",
       "878                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       merge revision via svnmerge steve sit dec line break split line little steve sit dec line remove inline line split code steve sit dec line create filter infrastructure steve sun dec line work implementation although break filter need add functionality steve sun dec line rename filter chain steve sun dec line rename line split filter steve mon dec line rename line split filter add polygon splitter steve mon dec line make sure line always copy change point would change level steve mon dec line add copy constructor mapshape class steve mon dec line add filter polygon add line filter line polygon filter polygon steve mon dec line tidy steve mon dec line split file general package actual generalgarmin conversion steve mon dec line useful amount smothing apply steve mon dec line fix return chain filter steve mon dec line polygon splitter polygon many point split steve mon dec line remove printlns steve mon dec line smooth filter remove old code remove duplicate point gitsvnid dfeeadfeeeb   \n",
       "50                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                add target near neighbor finder tool reduce default timeout longrunning test add jaccardindex overload two set element fix javadoc make class serializable add support maximum path length rework use new simpledependencypath class revise error message clarity update use new simpledependencypath feature update use new simpledependencypath feature major rewrite clarity fix tostring add static method test category particular po tag implement miss method add import sure add logging added support shuffle edge graph use fix random reproducability multithreaded edge similarity comparison probably bug fix update use intpair instead pairinteger updated use intset major overhaul bring performance line earlier primitive collection enhancement probably need lot clean still update use new primitive collection update use new primitive collection add support cluster fix number cluster add limited support write gexf format add limited support write pajek format make default output verbose remove extra temporary file hang around unneeded added support get string back document add new class test association two term already partially support bigramextractor class support limit number item associate enables well scale iterative association test class need lot work add iterator document wackypedia fix html bug javadoc add new tool run nearestneighborfinder command line fix javadoc add support change log level logger namespace add new tool speeding repeat nearestneighbor computation partition semanticspace cluster use kmeans search subset add support read write stream byte array update intset add pair implementation fix iterator remove bug added extensive realworld unit test add unit test detail match example ahn et al paper add test   \n",
       "\n",
       "       category  \n",
       "400      bugfix  \n",
       "833      bugfix  \n",
       "243  functional  \n",
       "878      bugfix  \n",
       "50       bugfix  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.loc[[400, 833, 243, 878, 50]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lemmatized_text    1702\n",
       "category           1702\n",
       "dtype: int64"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['lemmatized_text'].duplicated().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemmatized_text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>fix performance regresssion introduce use inetsocketaddress gethostname patch provide scott harrington improve upon kris jurka</td>\n",
       "      <td>bugfix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>fix performance regresssion introduce use inetsocketaddress gethostname patch provide scott harrington improve upon kris jurka</td>\n",
       "      <td>external</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                    lemmatized_text  \\\n",
       "577  fix performance regresssion introduce use inetsocketaddress gethostname patch provide scott harrington improve upon kris jurka   \n",
       "578  fix performance regresssion introduce use inetsocketaddress gethostname patch provide scott harrington improve upon kris jurka   \n",
       "\n",
       "     category  \n",
       "577    bugfix  \n",
       "578  external  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicate_records = df[df['lemmatized_text'].duplicated(keep=False)]\n",
    "\n",
    "duplicate_records "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemmatized_text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>fix pb image interpretation header footer work docx see</td>\n",
       "      <td>bugfix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>fix performance regresssion introduce use inetsocketaddress gethostname patch provide scott harrington improve upon kris jurka</td>\n",
       "      <td>bugfix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>fix performance regresssion introduce use inetsocketaddress gethostname patch provide scott harrington improve upon kris jurka</td>\n",
       "      <td>external</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>fix really lot bug rewrite performance</td>\n",
       "      <td>external</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                    lemmatized_text  \\\n",
       "576                                                                         fix pb image interpretation header footer work docx see   \n",
       "577  fix performance regresssion introduce use inetsocketaddress gethostname patch provide scott harrington improve upon kris jurka   \n",
       "578  fix performance regresssion introduce use inetsocketaddress gethostname patch provide scott harrington improve upon kris jurka   \n",
       "579                                                                                          fix really lot bug rewrite performance   \n",
       "\n",
       "     category  \n",
       "576    bugfix  \n",
       "577    bugfix  \n",
       "578  external  \n",
       "579  external  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.iloc[[567, 568, 569, 570]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**577, 578**: use of the word \"Fix\" suggests that it is **bugfix** entry, as it address a performance issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(labels=[578], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemmatized_text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>fix issue join team player longer silently kick team try join nonexistant team join fix inconsistency format team join notification message</td>\n",
       "      <td>bugfix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>fix pb image interpretation header footer work docx see</td>\n",
       "      <td>bugfix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>fix performance regresssion introduce use inetsocketaddress gethostname patch provide scott harrington improve upon kris jurka</td>\n",
       "      <td>bugfix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>fix really lot bug rewrite performance</td>\n",
       "      <td>external</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>fix reload functionality reload break miss cache invalidation reload flush function repository cache library also global function cache local code library reload though want</td>\n",
       "      <td>bugfix</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                   lemmatized_text  \\\n",
       "575                                    fix issue join team player longer silently kick team try join nonexistant team join fix inconsistency format team join notification message   \n",
       "576                                                                                                                        fix pb image interpretation header footer work docx see   \n",
       "577                                                 fix performance regresssion introduce use inetsocketaddress gethostname patch provide scott harrington improve upon kris jurka   \n",
       "579                                                                                                                                         fix really lot bug rewrite performance   \n",
       "580  fix reload functionality reload break miss cache invalidation reload flush function repository cache library also global function cache local code library reload though want   \n",
       "\n",
       "     category  \n",
       "575    bugfix  \n",
       "576    bugfix  \n",
       "577    bugfix  \n",
       "579  external  \n",
       "580    bugfix  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.iloc[[566, 567, 568, 569, 570]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lemmatized_text    False\n",
      "category           False\n",
      "dtype: bool\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t8/nrzsz40n223cvd6fg23stq9m0000gn/T/ipykernel_21722/1045824558.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  spaces_mask = df.applymap(is_only_spaces)\n"
     ]
    }
   ],
   "source": [
    "# function that checks if a cell is only space characters\n",
    "def is_only_spaces(x):\n",
    "    return isinstance(x, str) and x.strip() == ''\n",
    "\n",
    "# Apply the function to each element of the DataFrame\n",
    "spaces_mask = df.applymap(is_only_spaces)\n",
    "\n",
    "# all() to check if all values in each column are True (only spaces)\n",
    "columns_only_spaces = spaces_mask.all()\n",
    "\n",
    "print(columns_only_spaces)\n",
    "\n",
    "columns_with_only_spaces = columns_only_spaces[columns_only_spaces].index.tolist()\n",
    "print(columns_with_only_spaces)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lemmatized_text    1701\n",
       "category           1701\n",
       "dtype: int64"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training/Testing Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /Users/onkars/Documents/AIProjects/Automated-Software-Refactoring-Commit-Classifier/myenv/lib/python3.12/site-packages (1.4.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /Users/onkars/Documents/AIProjects/Automated-Software-Refactoring-Commit-Classifier/myenv/lib/python3.12/site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Users/onkars/Documents/AIProjects/Automated-Software-Refactoring-Commit-Classifier/myenv/lib/python3.12/site-packages (from scikit-learn) (1.13.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/onkars/Documents/AIProjects/Automated-Software-Refactoring-Commit-Classifier/myenv/lib/python3.12/site-packages (from scikit-learn) (1.4.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/onkars/Documents/AIProjects/Automated-Software-Refactoring-Commit-Classifier/myenv/lib/python3.12/site-packages (from scikit-learn) (3.4.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df['lemmatized_text']  \n",
    "y = df['category']    \n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.25,       # 25% of the data will be allocated to the test set\n",
    "    stratify=y,           # Stratify based on the labels to maintain distribution\n",
    "    random_state=1234       \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "755                                                                                                                                      improve performance messagesource condition\n",
       "672                                                                                                                       full support xelemental injection htmltemplate inheritance\n",
       "660     fix brokennullcheck also catch problem equality expression offend code rule also match array literal expression slightly great accuracy comment cleanups gitsvnid bafdacfced\n",
       "1393                                                                                           sshd reame listfiles listsshfiles allow implementation use ftpserver file abstraction\n",
       "625                                                                     fix dimension properly reduce imagepluscontianers always break eg gaussian convolution handle dimension size\n",
       "                                                                                            ...                                                                                     \n",
       "1355                                                                                                                                            core add random functionality filter\n",
       "134                                                                                       add googreflectobjectproperty first class primitive functionality jscompilerrenameproperty\n",
       "1486                                                                                                               continued cleanup make table join inheritance match nullablesizes\n",
       "456                                                                                                                                              dao abstraction update npc sql file\n",
       "634                                                                                                              fix miss validation error message value conversion fail eclipse bug\n",
       "Name: lemmatized_text, Length: 1275, dtype: object"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category\n",
      "functional    87\n",
      "bugfix        87\n",
      "internal      86\n",
      "external      85\n",
      "code smell    81\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "category_counts = y_test.value_counts()\n",
    "\n",
    "print(category_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category\n",
      "bugfix        261\n",
      "functional    259\n",
      "internal      256\n",
      "external      255\n",
      "code smell    244\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "category_counts = y_train.value_counts()\n",
    "print(category_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1275"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_path = r\"../dataset/x_train.csv\"\n",
    "\n",
    "x_train.to_csv(x_train_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_path = r\"../dataset/y_train.csv\"\n",
    "\n",
    "y_train.to_csv(y_train_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_path = r\"../dataset/x_test.csv\"\n",
    "\n",
    "x_test.to_csv(x_test_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_path = r\"../dataset/y_test.csv\"\n",
    "\n",
    "y_test.to_csv(y_test_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 3), max_features=10000)\n",
    "\n",
    "# Fit and transform the training data\n",
    "x_train_tfidf = vectorizer.fit_transform(x_train)\n",
    "\n",
    "# Only transform the testing data\n",
    "x_test_tfidf = vectorizer.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.8661971830985915\n",
      "Logistic Regression Accuracy: 0.8849765258215962\n",
      "Multinomial Naive Bayes Accuracy: 0.8028169014084507\n",
      "K-Nearest Neighbors Accuracy: 0.6784037558685446\n",
      "Support Vector Classification Accuracy: 0.8732394366197183\n",
      "Decision Tree Accuracy: 0.8215962441314554\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize classifiers\n",
    "classifiers = {\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Multinomial Naive Bayes\": MultinomialNB(),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
    "    \"Support Vector Classification\": SVC(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier()\n",
    "}\n",
    "\n",
    "# Dictionary to store the accuracy of each classifier\n",
    "accuracy_results = {}\n",
    "\n",
    "# Train and evaluate each classifier\n",
    "for classifier_name, classifier in classifiers.items():\n",
    "    # Train the classifier\n",
    "    classifier.fit(x_train_tfidf, y_train)\n",
    "    \n",
    "    # Predict on the test set\n",
    "    y_pred = classifier.predict(x_test_tfidf)\n",
    "    \n",
    "    # Evaluate the accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracy_results[classifier_name] = accuracy\n",
    "    print(f\"{classifier_name} Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.8802816901408451\n",
      "Support Vector Classification Accuracy: 0.8732394366197183\n",
      "Decision Tree Accuracy: 0.8169014084507042\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize classifiers with specified hyperparameters\n",
    "classifiers = {\n",
    "    \"Random Forest\": RandomForestClassifier(max_depth=70, n_estimators=58, criterion='gini', bootstrap=False),\n",
    "    \"Support Vector Classification\": SVC(gamma=1.9, kernel='linear', C=1.0),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(max_depth=75, criterion='gini'),\n",
    "    \"Logistic Regression\": LogisticRegression(penalty='l2', C=1.0, solver='liblinear'),\n",
    "    \"Multinomial Naive Bayes\": MultinomialNB(alpha=0.63),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(n_neighbors=69, weights='uniform')\n",
    "}\n",
    "\n",
    "# Train and evaluate each classifier\n",
    "for classifier_name, classifier in classifiers.items():\n",
    "    # Train the classifier\n",
    "    classifier.fit(x_train_tfidf, y_train)\n",
    "    \n",
    "    # Predict on the test set\n",
    "    y_pred = classifier.predict(x_test_tfidf)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"{classifier_name} Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Random Forest...\n",
      "Random Forest Accuracy: 0.8967136150234741\n",
      "Random Forest Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      bugfix       0.91      0.83      0.87        87\n",
      "  code smell       0.99      0.98      0.98        81\n",
      "    external       0.81      0.89      0.85        85\n",
      "  functional       0.88      0.83      0.85        87\n",
      "    internal       0.91      0.97      0.94        86\n",
      "\n",
      "    accuracy                           0.90       426\n",
      "   macro avg       0.90      0.90      0.90       426\n",
      "weighted avg       0.90      0.90      0.90       426\n",
      "\n",
      "Training Support Vector Classification...\n",
      "Support Vector Classification Accuracy: 0.863849765258216\n",
      "Support Vector Classification Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      bugfix       0.77      0.87      0.82        87\n",
      "  code smell       0.95      0.95      0.95        81\n",
      "    external       0.89      0.84      0.86        85\n",
      "  functional       0.80      0.78      0.79        87\n",
      "    internal       0.94      0.88      0.91        86\n",
      "\n",
      "    accuracy                           0.86       426\n",
      "   macro avg       0.87      0.86      0.87       426\n",
      "weighted avg       0.87      0.86      0.86       426\n",
      "\n",
      "Training Decision Tree...\n",
      "Decision Tree Accuracy: 0.812206572769953\n",
      "Decision Tree Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      bugfix       0.82      0.78      0.80        87\n",
      "  code smell       0.84      0.91      0.88        81\n",
      "    external       0.80      0.78      0.79        85\n",
      "  functional       0.79      0.79      0.79        87\n",
      "    internal       0.80      0.80      0.80        86\n",
      "\n",
      "    accuracy                           0.81       426\n",
      "   macro avg       0.81      0.81      0.81       426\n",
      "weighted avg       0.81      0.81      0.81       426\n",
      "\n",
      "Training Logistic Regression...\n",
      "Logistic Regression Accuracy: 0.8544600938967136\n",
      "Logistic Regression Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      bugfix       0.86      0.75      0.80        87\n",
      "  code smell       0.96      0.96      0.96        81\n",
      "    external       0.78      0.85      0.81        85\n",
      "  functional       0.76      0.80      0.78        87\n",
      "    internal       0.93      0.92      0.92        86\n",
      "\n",
      "    accuracy                           0.85       426\n",
      "   macro avg       0.86      0.86      0.86       426\n",
      "weighted avg       0.86      0.85      0.85       426\n",
      "\n",
      "Training Multinomial Naive Bayes...\n",
      "Multinomial Naive Bayes Accuracy: 0.8333333333333334\n",
      "Multinomial Naive Bayes Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      bugfix       0.71      0.92      0.80        87\n",
      "  code smell       0.95      0.96      0.96        81\n",
      "    external       0.96      0.62      0.76        85\n",
      "  functional       0.71      0.83      0.76        87\n",
      "    internal       0.96      0.84      0.89        86\n",
      "\n",
      "    accuracy                           0.83       426\n",
      "   macro avg       0.86      0.83      0.83       426\n",
      "weighted avg       0.86      0.83      0.83       426\n",
      "\n",
      "Training K-Nearest Neighbors...\n",
      "K-Nearest Neighbors Accuracy: 0.8028169014084507\n",
      "K-Nearest Neighbors Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      bugfix       0.72      0.76      0.74        87\n",
      "  code smell       0.78      0.95      0.86        81\n",
      "    external       0.88      0.71      0.78        85\n",
      "  functional       0.74      0.77      0.76        87\n",
      "    internal       0.94      0.84      0.88        86\n",
      "\n",
      "    accuracy                           0.80       426\n",
      "   macro avg       0.81      0.80      0.80       426\n",
      "weighted avg       0.81      0.80      0.80       426\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "classifiers = {\n",
    "    \"Random Forest\": RandomForestClassifier(max_depth=78, n_estimators=500, criterion='gini', bootstrap=False),\n",
    "    \"Support Vector Classification\": SVC(gamma='scale', kernel='linear', C=1.99),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(max_depth=75, criterion='gini'),\n",
    "    \"Logistic Regression\": LogisticRegression(penalty='l1', C=1.0, solver='liblinear'),\n",
    "    \"Multinomial Naive Bayes\": MultinomialNB(alpha=2.63),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(n_neighbors=69, weights='uniform')\n",
    "}\n",
    "\n",
    "evaluation_reports = {}\n",
    "\n",
    "# Train, predict, and evaluate each classifier separately\n",
    "for classifier_name, classifier in classifiers.items():\n",
    "    print(f\"Training {classifier_name}...\")\n",
    "    \n",
    "    # Train the classifier\n",
    "    classifier.fit(x_train_tfidf, y_train)\n",
    "    \n",
    "    # Predict on the test set\n",
    "    y_pred = classifier.predict(x_test_tfidf)\n",
    "    \n",
    "    # Generate a classification report\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    \n",
    "    # Print accuracy and store the report for further analysis\n",
    "    print(f\"{classifier_name} Accuracy: {report['accuracy']}\")\n",
    "    evaluation_reports[classifier_name] = report\n",
    "    \n",
    "    # Detailed report\n",
    "    print(f\"{classifier_name} Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def fit(self, X, y):\n",
    "        \n",
    "#         X_preprocessed = preprocess(X.copy())\n",
    "        \n",
    "#         # Separating text data for TF-IDF transformation\n",
    "#         text_data = X_preprocessed.pop('combined_text')\n",
    "        \n",
    "#         text_features = self.tfidf_vectorizer.fit_transform(text_data)\n",
    "        \n",
    "#         # Combining text features with other features\n",
    "#         X_combined = np.hstack((text_features.toarray(), X_preprocessed.values))\n",
    "        \n",
    "#         self.classifier.fit(X_combined, y)\n",
    "        \n",
    "#         # Define a broad range of parameters for RandomizedSearchCV\n",
    "#         rf_random_params = {\n",
    "#             'n_estimators': np.arange(100, 1001, 100),\n",
    "#             'max_depth': np.arange(10, 101, 10),\n",
    "#             'min_samples_split': np.arange(2, 11, 1),\n",
    "#             'criterion': ['gini', 'entropy']\n",
    "#         }\n",
    "        \n",
    "#         # Randomized Search with Cross-Validation\n",
    "#         self.rfc = RandomForestClassifier(class_weight=\"balanced\", random_state=42)\n",
    "#         random_search = RandomizedSearchCV(self.rfc, rf_random_params, n_iter=100, cv=5, scoring='f1', n_jobs=-1, random_state=42)\n",
    "#         random_search.fit(X_combined, y)\n",
    "#         print(\"Best parameters from RandomizedSearch: \", random_search.best_params_)\n",
    "\n",
    "#         # Refine search with GridSearchCV around the best parameters found\n",
    "#         best_params = random_search.best_params_\n",
    "#         rf_grid_params = {\n",
    "#             'n_estimators': [best_params['n_estimators'] - 50, best_params['n_estimators'], best_params['n_estimators'] + 50],\n",
    "#             'max_depth': [best_params['max_depth'] - 10, best_params['max_depth'], best_params['max_depth'] + 10],\n",
    "#             'min_samples_split': [best_params['min_samples_split'] - 1, best_params['min_samples_split'], best_params['min_samples_split'] + 1],\n",
    "#             'criterion': [best_params['criterion']]\n",
    "#         }\n",
    "#         self.rscv = GridSearchCV(self.rfc, rf_grid_params, cv=5, scoring='f1', n_jobs=-1)\n",
    "#         self.rscv.fit(X_combined, y)\n",
    "#         print(\"Refined best parameters from GridSearchCV: \", self.rscv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 101 candidates, totalling 303 fits\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=21, n_estimators=101; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=21, n_estimators=101; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=21, n_estimators=101; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=41, n_estimators=101; total time=   0.4s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=41, n_estimators=101; total time=   0.4s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=41, n_estimators=101; total time=   0.4s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=31, n_estimators=101; total time=   0.4s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=31, n_estimators=101; total time=   0.4s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=61, n_estimators=101; total time=   0.5s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=31, n_estimators=101; total time=   0.5s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=61, n_estimators=101; total time=   0.5s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=61, n_estimators=101; total time=   0.5s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=81, n_estimators=101; total time=   0.5s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=71, n_estimators=301; total time=   1.4s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=71, n_estimators=301; total time=   1.5s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=71, n_estimators=301; total time=   1.6s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=81, n_estimators=101; total time=   0.5s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=81, n_estimators=101; total time=   0.5s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=11, n_estimators=301; total time=   0.5s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=11, n_estimators=301; total time=   0.5s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=71, n_estimators=401; total time=   2.8s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=61, n_estimators=701; total time=   3.3s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=31, n_estimators=601; total time=   2.8s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=71, n_estimators=401; total time=   2.9s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=31, n_estimators=601; total time=   2.9s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=71, n_estimators=401; total time=   3.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=61, n_estimators=701; total time=   3.4s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=61, n_estimators=701; total time=   3.5s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=31, n_estimators=601; total time=   2.9s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=11, n_estimators=301; total time=   0.6s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=21, n_estimators=901; total time=   2.9s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=21, n_estimators=901; total time=   2.9s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=81, n_estimators=201; total time=   1.5s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=41, n_estimators=801; total time=   4.3s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=21, n_estimators=901; total time=   2.9s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=81, n_estimators=201; total time=   1.5s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=81, n_estimators=201; total time=   1.5s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=41, n_estimators=801; total time=   4.3s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=41, n_estimators=801; total time=   4.3s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=31, n_estimators=701; total time=   3.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=31, n_estimators=701; total time=   3.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=31, n_estimators=701; total time=   3.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=51, n_estimators=801; total time=   3.5s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=51, n_estimators=801; total time=   3.5s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=51, n_estimators=801; total time=   3.6s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=31, n_estimators=801; total time=   2.5s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=11, n_estimators=601; total time=   0.8s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=11, n_estimators=601; total time=   0.8s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=11, n_estimators=601; total time=   0.9s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=71, n_estimators=601; total time=   4.5s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=41, n_estimators=901; total time=   3.7s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=41, n_estimators=901; total time=   3.7s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=41, n_estimators=901; total time=   3.7s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=71, n_estimators=601; total time=   4.6s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=31, n_estimators=801; total time=   2.7s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=71, n_estimators=601; total time=   4.7s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=11, n_estimators=201; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=61, n_estimators=201; total time=   0.9s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=31, n_estimators=801; total time=   2.8s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=61, n_estimators=201; total time=   0.9s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=61, n_estimators=201; total time=   0.9s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=11, n_estimators=201; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=11, n_estimators=201; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=41, n_estimators=301; total time=   1.9s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=41, n_estimators=301; total time=   1.8s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=41, n_estimators=301; total time=   1.8s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=21, n_estimators=401; total time=   1.0s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=21, n_estimators=401; total time=   1.0s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=21, n_estimators=401; total time=   1.0s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=81, n_estimators=101; total time=   0.5s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=61, n_estimators=901; total time=   6.5s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=61, n_estimators=901; total time=   6.5s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=61, n_estimators=901; total time=   6.7s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=81, n_estimators=101; total time=   0.5s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=61, n_estimators=301; total time=   2.0s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=61, n_estimators=301; total time=   2.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=61, n_estimators=301; total time=   2.0s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=81, n_estimators=101; total time=   0.5s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=21, n_estimators=101; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=21, n_estimators=101; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=21, n_estimators=101; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=91, n_estimators=501; total time=   2.6s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=91, n_estimators=501; total time=   2.6s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=91, n_estimators=501; total time=   2.7s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=11, n_estimators=701; total time=   5.8s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=11, n_estimators=701; total time=   8.4s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=11, n_estimators=701; total time=   9.8s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=91, n_estimators=701; total time=  13.8s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=81, n_estimators=801; total time=  19.0s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=81, n_estimators=801; total time=  19.8s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=81, n_estimators=801; total time=  20.8s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=21, n_estimators=501; total time=  16.2s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=91, n_estimators=701; total time=  19.9s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=91, n_estimators=701; total time=  21.4s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=21, n_estimators=301; total time=  19.6s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=21, n_estimators=301; total time=  19.4s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=21, n_estimators=301; total time=  20.5s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=71, n_estimators=201; total time=  19.3s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=71, n_estimators=201; total time=  18.3s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=21, n_estimators=501; total time=  33.5s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=21, n_estimators=501; total time=  33.7s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=91, n_estimators=501; total time=  47.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=91, n_estimators=501; total time=  48.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=91, n_estimators=501; total time=  49.0s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=71, n_estimators=201; total time=  19.8s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=31, n_estimators=301; total time=  21.9s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=31, n_estimators=301; total time=  22.7s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=11, n_estimators=401; total time=  14.7s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=11, n_estimators=401; total time=  16.7s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=31, n_estimators=301; total time=  22.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=11, n_estimators=401; total time=  16.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=71, n_estimators=401; total time= 1.0min\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=71, n_estimators=401; total time= 1.0min\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=71, n_estimators=401; total time= 1.0min\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=51, n_estimators=901; total time= 1.4min\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=51, n_estimators=901; total time= 1.5min\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=41, n_estimators=701; total time=  52.4s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=51, n_estimators=901; total time= 1.5min\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=41, n_estimators=701; total time=  54.8s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=41, n_estimators=701; total time=  56.7s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=61, n_estimators=101; total time=  10.4s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=61, n_estimators=101; total time=  11.0s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=61, n_estimators=101; total time=  12.6s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=21, n_estimators=701; total time=  52.6s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=21, n_estimators=701; total time=  51.2s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=21, n_estimators=701; total time=  53.7s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=21, n_estimators=201; total time=  19.6s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=21, n_estimators=201; total time=  18.9s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=21, n_estimators=201; total time=  19.1s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=51, n_estimators=701; total time= 1.3min\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=51, n_estimators=701; total time= 1.3min\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=51, n_estimators=701; total time= 1.3min\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=21, n_estimators=701; total time= 1.1min\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=21, n_estimators=701; total time= 1.3min\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=21, n_estimators=701; total time= 1.4min\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=71, n_estimators=401; total time= 1.2min\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=71, n_estimators=401; total time= 1.2min\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=71, n_estimators=401; total time= 1.2min\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[70], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m rf_random \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(estimator\u001b[38;5;241m=\u001b[39mrf_classifier, param_distributions\u001b[38;5;241m=\u001b[39mrandom_grid, n_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m101\u001b[39m, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Fit the random search model\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m \u001b[43mrf_random\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train_tfidf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Output the best parameters from RandomizedSearchCV\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest parameters found by RandomizedSearchCV:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/AIProjects/Automated-Software-Refactoring-Commit-Classifier/myenv/lib/python3.12/site-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/AIProjects/Automated-Software-Refactoring-Commit-Classifier/myenv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    964\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    965\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    966\u001b[0m     )\n\u001b[1;32m    968\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 970\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    974\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Documents/AIProjects/Automated-Software-Refactoring-Commit-Classifier/myenv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1914\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1912\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1913\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1914\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1915\u001b[0m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1916\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\n\u001b[1;32m   1917\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1918\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/AIProjects/Automated-Software-Refactoring-Commit-Classifier/myenv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:916\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    909\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    910\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    911\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    912\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    913\u001b[0m         )\n\u001b[1;32m    914\u001b[0m     )\n\u001b[0;32m--> 916\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    922\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    924\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    925\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    928\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    929\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    930\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    931\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    932\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    934\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    935\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    936\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    937\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    938\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    939\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/AIProjects/Automated-Software-Refactoring-Commit-Classifier/myenv/lib/python3.12/site-packages/sklearn/utils/parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     66\u001b[0m )\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/AIProjects/Automated-Software-Refactoring-Commit-Classifier/myenv/lib/python3.12/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/AIProjects/Automated-Software-Refactoring-Commit-Classifier/myenv/lib/python3.12/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/AIProjects/Automated-Software-Refactoring-Commit-Classifier/myenv/lib/python3.12/site-packages/joblib/parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# import numpy as np\n",
    "\n",
    "# # Assuming x_train_tfidf and y_train are already defined as your training dataset and labels\n",
    "\n",
    "# # Initialize RandomForestClassifier\n",
    "# rf_classifier = RandomForestClassifier(class_weight=\"balanced\", random_state=43)\n",
    "\n",
    "# # Define the parameter space for RandomizedSearchCV\n",
    "# random_grid = {\n",
    "#     'n_estimators': np.arange(101, 1001, 100),  # Number of trees in the forest\n",
    "#     'max_depth': np.arange(11, 101, 10),  # Maximum depth of the tree\n",
    "#     'bootstrap': [True, False],  # Method of selecting samples for training each tree\n",
    "#     'criterion': ['gini', 'entropy']  # The function to measure the quality of a split\n",
    "# }\n",
    "\n",
    "# # Random search of parameters, using 4 fold cross validation,\n",
    "# # search across 101 different combinations, and use all available cores\n",
    "# rf_random = RandomizedSearchCV(estimator=rf_classifier, param_distributions=random_grid, n_iter=101, cv=3, verbose=2, random_state=42, n_jobs=-1)\n",
    "\n",
    "# # Fit the random search model\n",
    "# rf_random.fit(x_train_tfidf, y_train)\n",
    "\n",
    "# # Output the best parameters from RandomizedSearchCV\n",
    "# print(\"Best parameters found by RandomizedSearchCV:\")\n",
    "# print(rf_random.best_params_)\n",
    "\n",
    "# # You can now take the best parameters from the random search and use them to\n",
    "# # create a more focused search with GridSearchCV (if necessary). This might involve\n",
    "# # narrower ranges of parameters or specific combinations that you want to test exhaustively.\n",
    "\n",
    "# # Refine search with GridSearchCV around the best parameters found\n",
    "# best_params = rf_random.best_params_\n",
    "# rf_grid_params = {\n",
    "#             'n_estimators': [best_params['n_estimators'] - 50, best_params['n_estimators'], best_params['n_estimators'] + 50],\n",
    "#             'max_depth': [best_params['max_depth'] - 10, best_params['max_depth'], best_params['max_depth'] + 10],            \n",
    "#             'criterion': [best_params['criterion']],\n",
    "#             'bootstrap': [best_params['bootstrap']]\n",
    "# }\n",
    "# rscv = GridSearchCV(rf_classifier, rf_grid_params, cv=5, scoring='f1', n_jobs=-1)\n",
    "# rscv.fit(x_train_tfidf, y_train)\n",
    "# print(\"Refined best parameters from GridSearchCV: \", rscv.best_params_)\n",
    "\n",
    "\n",
    "# # {'n_estimators': 1000, 'min_samples_split': 8, 'max_depth': 90, 'criterion': 'gini', 'bootstrap': False}\n",
    "# # Refined best parameters from GridSearchCV:  {'criterion': 'gini', 'max_depth': 80, 'min_samples_split': 7, 'n_estimators': 950}\n",
    "\n",
    "# # {'n_estimators': 200, 'max_depth': 40, 'criterion': 'gini', 'bootstrap': False}\n",
    "# # Refined best parameters from GridSearchCV:  {'bootstrap': False, 'criterion': 'gini', 'max_depth': 30, 'n_estimators': 150}\n",
    "\n",
    "# # {'bootstrap': False, 'criterion': 'gini', 'max_depth': 80, 'n_estimators': 950}\n",
    "# # {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 41, 'n_estimators': 551}\n",
    "# # {'bootstrap': False, 'criterion': 'gini', 'max_depth': 41, 'n_estimators': 151}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "# from sklearn.svm import SVC\n",
    "# import numpy as np\n",
    "\n",
    "# # Assuming x_train_tfidf and y_train are already defined\n",
    "\n",
    "# # Initialize the SVC model\n",
    "# svc = SVC(random_state=42)\n",
    "\n",
    "# # Define a parameter space for RandomizedSearchCV\n",
    "# param_distributions = {\n",
    "#     'C': np.logspace(-4, 4, 20),  # Regularization parameter\n",
    "#     'gamma': ['scale', 'auto'],  # Kernel coefficient for 'rbf', 'poly' and 'sigmoid'\n",
    "#     'kernel': ['linear', 'poly', 'rbf', 'sigmoid']  # Specifies the kernel type to be used in the algorithm\n",
    "# }\n",
    "\n",
    "# # Random search of parameters, using 3 fold cross validation,\n",
    "# # search across a wide range of combinations, and use all available cores\n",
    "# svm_random = RandomizedSearchCV(estimator=svc, param_distributions=param_distributions, n_iter=100, cv=3, verbose=2, random_state=42, n_jobs=-1)\n",
    "\n",
    "# # Fit the random search model\n",
    "# svm_random.fit(x_train_tfidf, y_train)\n",
    "\n",
    "# # Output the best parameters from RandomizedSearchCV\n",
    "# print(\"Best parameters found by RandomizedSearchCV for SVM:\")\n",
    "# print(svm_random.best_params_)\n",
    "\n",
    "\n",
    "# # Extract the best parameters found by RandomizedSearchCV\n",
    "# best_params = svm_random.best_params_\n",
    "\n",
    "# # Create a parameter grid focused around the best parameters found\n",
    "# param_grid = {\n",
    "#     'C': [best_params['C'] * 0.5, best_params['C'], best_params['C'] * 2],\n",
    "#     'gamma': [best_params['gamma']],\n",
    "#     'kernel': [best_params['kernel']]\n",
    "# }\n",
    "\n",
    "# # Create a GridSearchCV for a more focused search\n",
    "# svm_grid = GridSearchCV(estimator=SVC(random_state=42), param_grid=param_grid, cv=5, verbose=2, n_jobs=-1)\n",
    "\n",
    "# # Fit GridSearchCV\n",
    "# svm_grid.fit(x_train_tfidf, y_train)\n",
    "\n",
    "# # Output the best parameters from GridSearchCV\n",
    "# print(\"Refined best parameters from GridSearchCV for SVM:\")\n",
    "# print(svm_grid.best_params_)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
    "# # Best parameters found by RandomizedSearchCV for SVM:\n",
    "# # {'kernel': 'rbf', 'gamma': 0.001, 'C': 545.5594781168514}\n",
    "# # Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
    "# # Refined best parameters from GridSearchCV for SVM:\n",
    "# # {'C': 272.7797390584257, 'gamma': 0.002, 'kernel': 'rbf'}\n",
    "# # {'C': 5000.0, 'gamma': 'auto', 'kernel': 'rbf'}\n",
    "# # {'C': 14.881757208156566, 'gamma': 'auto', 'kernel': 'linear'\n",
    "# # {'C': 0.8118883695943605, 'gamma': 'auto', 'kernel': 'linear'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# import numpy as np\n",
    "\n",
    "# # Assuming x_train_tfidf and y_train are defined\n",
    "\n",
    "# # Initialize DecisionTreeClassifier\n",
    "# dt_classifier = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# # Define the parameter space for RandomizedSearchCV\n",
    "# param_distributions = {\n",
    "#     'max_depth': np.arange(10, 101, 10),  # Maximum depth of the tree\n",
    "#     'criterion': ['gini', 'entropy']  # The function to measure the quality of a split\n",
    "# }\n",
    "\n",
    "# # Random search of parameters, using 3 fold cross validation,\n",
    "# # search across a wide range of combinations, and use all available cores\n",
    "# dt_random = RandomizedSearchCV(estimator=dt_classifier, param_distributions=param_distributions, n_iter=100, cv=3, verbose=2, random_state=42, n_jobs=-1)\n",
    "\n",
    "# # Fit the random search model\n",
    "# dt_random.fit(x_train_tfidf, y_train)\n",
    "\n",
    "# # Output the best parameters from RandomizedSearchCV\n",
    "# print(\"Best parameters found by RandomizedSearchCV for Decision Tree:\")\n",
    "# print(dt_random.best_params_)\n",
    "\n",
    "# # Extract the best parameters found by RandomizedSearchCV\n",
    "# best_params = dt_random.best_params_\n",
    "\n",
    "# # Create a parameter grid focused around the best parameters found\n",
    "# param_grid = {\n",
    "#     'max_depth': [best_params['max_depth'] - 10, best_params['max_depth'], best_params['max_depth'] + 10] if best_params['max_depth'] is not None else np.arange(5, 16, 5),\n",
    "#     'criterion': [best_params['criterion']]\n",
    "# }\n",
    "\n",
    "# # Create a GridSearchCV for a more focused search\n",
    "# dt_grid = GridSearchCV(estimator=DecisionTreeClassifier(random_state=42), param_grid=param_grid, cv=5, verbose=2, n_jobs=-1)\n",
    "\n",
    "# # Fit GridSearchCV\n",
    "# dt_grid.fit(x_train_tfidf, y_train)\n",
    "\n",
    "# # Output the best parameters from GridSearchCV\n",
    "# print(\"Refined best parameters from GridSearchCV for Decision Tree:\")\n",
    "# print(dt_grid.best_params_)\n",
    "\n",
    "# # {'criterion': 'gini', 'max_depth': 30}\n",
    "# # # {'criterion': 'gini', 'max_depth': 20\n",
    "# # {'criterion': 'gini', 'max_depth': 20}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# import numpy as np\n",
    "\n",
    "# # Assuming x_train_tfidf and y_train are defined\n",
    "\n",
    "# # # Initialize LogisticRegression\n",
    "# # logistic_regression = LogisticRegression(random_state=42, max_iter=10000)\n",
    "\n",
    "# # # Define the parameter space for RandomizedSearchCV\n",
    "# param_distributions = {\n",
    "#     'C': np.logspace(-4, 4, 20),  # Regularization strength\n",
    "#     'penalty': ['l1', 'l2', 'elasticnet', 'none'],  # Type of regularization\n",
    "#     'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']  # Algorithm to use in the optimization problem\n",
    "# }\n",
    "\n",
    "# # Random search of parameters, using 3 fold cross validation,\n",
    "# # search across a wide range of combinations, and use all available cores\n",
    "# lr_random = RandomizedSearchCV(estimator=logistic_regression, param_distributions=param_distributions, n_iter=100, cv=3, verbose=2, random_state=42, n_jobs=-1)\n",
    "\n",
    "# # Fit the random search model\n",
    "# lr_random.fit(x_train_tfidf, y_train)\n",
    "\n",
    "# # Output the best parameters from RandomizedSearchCV\n",
    "# print(\"Best parameters found by RandomizedSearchCV for Logistic Regression:\")\n",
    "# print(lr_random.best_params_)\n",
    "\n",
    "# # Extract the best parameters found by RandomizedSearchCV\n",
    "# best_params = lr_random.best_params_\n",
    "\n",
    "# # Create a parameter grid focused around the best parameters found\n",
    "# param_grid = {\n",
    "#     'C': [best_params['C'] * 0.5, best_params['C'], best_params['C'] * 2],\n",
    "#     'penalty': [best_params['penalty']] if best_params['penalty'] != 'elasticnet' else ['l1', 'l2'],\n",
    "#     'solver': ['liblinear', 'saga'] if best_params['penalty'] == 'l1' else ['newton-cg', 'lbfgs', 'sag', 'saga']\n",
    "# }\n",
    "\n",
    "# # Some combinations might not be compatible, adjust the grid as needed\n",
    "# # Create a GridSearchCV for a more focused search\n",
    "# lr_grid = GridSearchCV(estimator=LogisticRegression(random_state=42, max_iter=10000), param_grid=param_grid, cv=5, verbose=2, n_jobs=-1)\n",
    "\n",
    "# # Fit GridSearchCV\n",
    "# lr_grid.fit(x_train_tfidf, y_train)\n",
    "\n",
    "# # Output the best parameters from GridSearchCV\n",
    "# print(\"Refined best parameters from GridSearchCV for Logistic Regression:\")\n",
    "# print(lr_grid.best_params_)\n",
    "\n",
    "# # {'C': 2.140666199359698, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
    "# # {'C': 3.247553478377442, 'penalty': 'l1', 'solver': 'liblinear'\n",
    "# # {'C': 3.247553478377442, 'penalty': 'l1', 'solver': 'saga'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "# from sklearn.naive_bayes import MultinomialNB\n",
    "# import numpy as np\n",
    "\n",
    "# # Assuming x_train_tfidf and y_train are defined\n",
    "\n",
    "# # Initialize MultinomialNB\n",
    "# mnb = MultinomialNB()\n",
    "\n",
    "# # Define the parameter space for RandomizedSearchCV\n",
    "# param_distributions = {\n",
    "#     'alpha': np.linspace(0, 1, 10)  # Additive (Laplace/Lidstone) smoothing parameter\n",
    "# }\n",
    "\n",
    "# # Since it's just one parameter, we're technically not \"randomizing\" much here\n",
    "# mnb_random = RandomizedSearchCV(estimator=mnb, param_distributions=param_distributions, n_iter=10, cv=3, verbose=2, random_state=42, n_jobs=-1)\n",
    "\n",
    "# # Fit the random search model\n",
    "# mnb_random.fit(x_train_tfidf, y_train)\n",
    "\n",
    "# # Output the best parameters from RandomizedSearchCV\n",
    "# print(\"Best parameters found by RandomizedSearchCV for Multinomial Naive Bayes:\")\n",
    "# print(mnb_random.best_params_)\n",
    "\n",
    "# # Extract the best alpha found by RandomizedSearchCV\n",
    "# best_alpha = mnb_random.best_params_['alpha']\n",
    "\n",
    "# # Create a parameter grid focused around the best alpha found\n",
    "# param_grid = {\n",
    "#     'alpha': [max(0, best_alpha - 0.1), best_alpha, best_alpha + 0.1]\n",
    "# }\n",
    "\n",
    "# # Create a GridSearchCV for a more focused search\n",
    "# mnb_grid = GridSearchCV(estimator=MultinomialNB(), param_grid=param_grid, cv=5, verbose=2, n_jobs=-1)\n",
    "\n",
    "# # Fit GridSearchCV\n",
    "# mnb_grid.fit(x_train_tfidf, y_train)\n",
    "\n",
    "# # Output the best parameters from GridSearchCV\n",
    "# print(\"Refined best parameters from GridSearchCV for Multinomial Naive Bayes:\")\n",
    "# print(mnb_grid.best_params_)\n",
    "\n",
    "# # {'alpha': 1.1}\n",
    "# # # {'alpha': 0.9\n",
    "# #{'alpha': 1.1} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# import numpy as np\n",
    "\n",
    "# # Assuming x_train_tfidf and y_train are defined\n",
    "\n",
    "# # Initialize KNeighborsClassifier\n",
    "# knn = KNeighborsClassifier()\n",
    "\n",
    "# # Define the parameter space for RandomizedSearchCV\n",
    "# param_distributions = {\n",
    "#     'n_neighbors': np.arange(1, 50),  # Number of neighbors to use\n",
    "#     'weights': ['uniform', 'distance'],  # Weight function used in prediction\n",
    "# }\n",
    "\n",
    "# # Random search of parameters, using 3 fold cross validation,\n",
    "# # search across a wide range of combinations, and use all available cores\n",
    "# knn_random = RandomizedSearchCV(estimator=knn, param_distributions=param_distributions, n_iter=100, cv=3, verbose=2, random_state=42, n_jobs=-1)\n",
    "\n",
    "# # Fit the random search model\n",
    "# knn_random.fit(x_train_tfidf, y_train)\n",
    "\n",
    "# # Output the best parameters from RandomizedSearchCV\n",
    "# print(\"Best parameters found by RandomizedSearchCV for KNN:\")\n",
    "# print(knn_random.best_params_)\n",
    "\n",
    "# # Extract the best parameters found by RandomizedSearchCV\n",
    "# best_params = knn_random.best_params_\n",
    "\n",
    "# # Create a parameter grid focused around the best parameters found\n",
    "# param_grid = {\n",
    "#     'n_neighbors': [best_params['n_neighbors'] - 2, best_params['n_neighbors'] - 1, best_params['n_neighbors'], best_params['n_neighbors'] + 1, best_params['n_neighbors'] + 2],\n",
    "#     'weights': [best_params['weights']],\n",
    "# }\n",
    "\n",
    "# # Ensure values are within valid ranges\n",
    "# param_grid['n_neighbors'] = [n for n in param_grid['n_neighbors'] if n > 0]\n",
    "\n",
    "# # Create a GridSearchCV for a more focused search\n",
    "# knn_grid = GridSearchCV(estimator=KNeighborsClassifier(), param_grid=param_grid, cv=5, verbose=2, n_jobs=-1)\n",
    "\n",
    "# # Fit GridSearchCV\n",
    "# knn_grid.fit(x_train_tfidf, y_train)\n",
    "\n",
    "# # Output the best parameters from GridSearchCV\n",
    "# print(\"Refined best parameters from GridSearchCV for KNN:\")\n",
    "# print(knn_grid.best_params_)\n",
    "\n",
    "# # {'n_neighbors': 43, 'weights': 'distance'}\n",
    "# # {'n_neighbors': 46, 'weights': 'distance'\n",
    "# # {'n_neighbors': 42, 'weights': 'distance'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# \"Random Forest\": RandomForestClassifier(max_depth=80, n_estimators=950, criterion='gini', bootstrap=False)\n",
    "#     \"Support Vector Classification\": SVC(gamma='auto', kernel='rbf', C=5000.0),\n",
    "#     \"Decision Tree\": DecisionTreeClassifier(max_depth=30, criterion='gini'),\n",
    "#     \"Logistic Regression\": LogisticRegression(penalty='l2', C=2.14, solver='newton-cg'),\n",
    "#     \"Multinomial Naive Bayes\": MultinomialNB(alpha=1.1),\n",
    "#     \"K-Nearest Neighbors\": KNeighborsClassifier(n_neighbors=43, weights='distance')\n",
    "    \n",
    "classifiers = {\n",
    "    \"Random Forest\": RandomForestClassifier(max_depth=41, n_estimators=151, criterion='gini', bootstrap=False),\n",
    "    \"Support Vector Classification\": SVC(gamma='auto', kernel='linear', C=0.8119),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(max_depth=20, criterion='gini'),\n",
    "    \"Logistic Regression\": LogisticRegression(penalty='l1', C=3.246, solver='saga'),\n",
    "    \"Multinomial Naive Bayes\": MultinomialNB(alpha=1.1),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(n_neighbors=42, weights='distance')\n",
    "}\n",
    "\n",
    "evaluation_reports = {}\n",
    "\n",
    "# Train, predict, and evaluate each classifier separately\n",
    "for classifier_name, classifier in classifiers.items():\n",
    "    print(f\"Training {classifier_name}...\")\n",
    "    \n",
    "    # Train the classifier\n",
    "    classifier.fit(x_train_tfidf, y_train)\n",
    "    \n",
    "    # Predict on the test set\n",
    "    y_pred = classifier.predict(x_test_tfidf)\n",
    "    \n",
    "    # Generate a classification report\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    \n",
    "    # Print accuracy and store the report for further analysis\n",
    "    print(f\"{classifier_name} Accuracy: {report['accuracy']}\")\n",
    "    evaluation_reports[classifier_name] = report\n",
    "    \n",
    "    # Detailed report\n",
    "    print(f\"{classifier_name} Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "class_names = ['internal', 'bugfix', 'external', 'functional', 'code smell']\n",
    "\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix with Class Names')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install deap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from deap import base, creator, tools, algorithms\n",
    "# import numpy as np\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def evalModel(individual):\n",
    "#     # Unpack individual parameters\n",
    "#     n_estimators, max_depth, criterion, bootstrap = individual\n",
    "    \n",
    "#     # Convert binary to boolean for bootstrap\n",
    "#     bootstrap = True if bootstrap == 1 else False\n",
    "    \n",
    "#     # Convert criterion to proper format\n",
    "#     criterion = \"gini\" if criterion == 1 else \"entropy\"\n",
    "    \n",
    "#     # Initialize the model with the individual's parameters\n",
    "#     model = RandomForestClassifier(n_estimators=n_estimators, \n",
    "#                                    max_depth=max_depth, \n",
    "#                                    criterion=criterion, \n",
    "#                                    bootstrap=bootstrap, \n",
    "#                                    random_state=42)\n",
    "\n",
    "#     # Perform 3-fold cross-validation\n",
    "#     scores = cross_val_score(model, x_train_tfidf, y_train, cv=3)\n",
    "    \n",
    "#     # Return the average accuracy\n",
    "#     return (np.mean(scores),)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define fitness and individual\n",
    "# creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "# creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "\n",
    "# toolbox = base.Toolbox()\n",
    "\n",
    "# # Attribute generators for our individual components\n",
    "# toolbox.register(\"attr_n_estimators\", random.randint, 100, 1000)\n",
    "# toolbox.register(\"attr_max_depth\", random.randint, 10, 100)\n",
    "# toolbox.register(\"attr_criterion\", random.randint, 1, 2)  # 1 for gini, 2 for entropy\n",
    "# toolbox.register(\"attr_bootstrap\", random.randint, 0, 1)  # 0 for False, 1 for True\n",
    "\n",
    "# # Structure initializers for individuals and the population\n",
    "# toolbox.register(\"individual\", tools.initCycle, creator.Individual,\n",
    "#                  (toolbox.attr_n_estimators, toolbox.attr_max_depth, toolbox.attr_criterion, toolbox.attr_bootstrap), n=1)\n",
    "\n",
    "# toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "# # Genetic operators\n",
    "# toolbox.register(\"evaluate\", evalModel)\n",
    "# toolbox.register(\"mate\", tools.cxTwoPoint)\n",
    "# toolbox.register(\"mutate\", tools.mutUniformInt, low=[100, 10, 1, 0], up=[1000, 100, 2, 1], indpb=0.2)\n",
    "# toolbox.register(\"select\", tools.selTournament, tournsize=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def main():\n",
    "#     random.seed(42)\n",
    "#     pop = toolbox.population(n=50)\n",
    "#     hof = tools.HallOfFame(1)\n",
    "    \n",
    "#     stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "#     stats.register(\"avg\", np.mean)\n",
    "#     stats.register(\"std\", np.std)\n",
    "#     stats.register(\"min\", np.min)\n",
    "#     stats.register(\"max\", np.max)\n",
    "    \n",
    "#     algorithms.eaSimple(pop, toolbox, cxpb=0.5, mutpb=0.2, ngen=40, \n",
    "#                         stats=stats, halloffame=hof, verbose=True)\n",
    "    \n",
    "#     return pop, stats, hof\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     population, stats, hof = main()\n",
    "#     print(\"Best individual is:\", hof[0], \"with fitness:\", hof[0].fitness)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
